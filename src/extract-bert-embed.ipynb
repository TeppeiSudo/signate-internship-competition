{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T13:41:05.346520Z",
     "iopub.status.busy": "2021-01-26T13:41:05.345821Z",
     "iopub.status.idle": "2021-01-26T13:41:16.986831Z",
     "shell.execute_reply": "2021-01-26T13:41:16.986274Z"
    },
    "papermill": {
     "duration": 11.658965,
     "end_time": "2021-01-26T13:41:16.986945",
     "exception": false,
     "start_time": "2021-01-26T13:41:05.327980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "#import re\n",
    "#import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#import nltk\n",
    "#from bs4 import BeautifulSoup\n",
    "import transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "import torch.optim as optimizers\n",
    "#from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T13:41:17.009134Z",
     "iopub.status.busy": "2021-01-26T13:41:17.008327Z",
     "iopub.status.idle": "2021-01-26T13:41:17.010852Z",
     "shell.execute_reply": "2021-01-26T13:41:17.011221Z"
    },
    "papermill": {
     "duration": 0.015641,
     "end_time": "2021-01-26T13:41:17.011320",
     "exception": false,
     "start_time": "2021-01-26T13:41:16.995679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T13:41:17.033898Z",
     "iopub.status.busy": "2021-01-26T13:41:17.033235Z",
     "iopub.status.idle": "2021-01-26T13:41:17.038356Z",
     "shell.execute_reply": "2021-01-26T13:41:17.037815Z"
    },
    "papermill": {
     "duration": 0.019538,
     "end_time": "2021-01-26T13:41:17.038472",
     "exception": false,
     "start_time": "2021-01-26T13:41:17.018934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set random seed\n",
    "def set_seed(seed: int = 123):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "    \n",
    "set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T13:41:17.069309Z",
     "iopub.status.busy": "2021-01-26T13:41:17.068817Z",
     "iopub.status.idle": "2021-01-26T13:41:20.966649Z",
     "shell.execute_reply": "2021-01-26T13:41:20.967493Z"
    },
    "papermill": {
     "duration": 3.92072,
     "end_time": "2021-01-26T13:41:20.967662",
     "exception": false,
     "start_time": "2021-01-26T13:41:17.046942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('data/nlp_prepared_bert.csv')\n",
    "\n",
    "# pd.read_csvでDataFrameを読み込むとデータ内の「””」が「nan」に置換されるバグ？があったので、再び[\"\"]に戻す\n",
    "all_data.html_raw = all_data.html_raw.fillna(\"\").astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T13:41:21.002027Z",
     "iopub.status.busy": "2021-01-26T13:41:21.001203Z",
     "iopub.status.idle": "2021-01-26T13:41:21.030054Z",
     "shell.execute_reply": "2021-01-26T13:41:21.031230Z"
    },
    "papermill": {
     "duration": 0.050558,
     "end_time": "2021-01-26T13:41:21.031426",
     "exception": false,
     "start_time": "2021-01-26T13:41:20.980868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>goal</th>\n",
       "      <th>country</th>\n",
       "      <th>duration</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>html_content</th>\n",
       "      <th>state</th>\n",
       "      <th>data_type</th>\n",
       "      <th>html_compiled</th>\n",
       "      <th>html_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4001-5000</td>\n",
       "      <td>CH</td>\n",
       "      <td>29</td>\n",
       "      <td>publishing</td>\n",
       "      <td>young adult</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;span class=\"bold\"&gt;...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;span&gt;Mark Saggia&lt;/span&gt; is an Itali...</td>\n",
       "      <td>Mark Saggia is an Italian writer who emigrated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3001-4000</td>\n",
       "      <td>NL</td>\n",
       "      <td>34</td>\n",
       "      <td>fashion</td>\n",
       "      <td>ready-to-wear</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;h1 class=\"page-anc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;h1&gt;Hello, I am Augustinas. I am a g...</td>\n",
       "      <td>Hello, I am Augustinas. I am a graphic designe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19001-20000</td>\n",
       "      <td>US</td>\n",
       "      <td>30</td>\n",
       "      <td>food</td>\n",
       "      <td>spaces</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt; As our society ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;p&gt; As our society begins to wake up...</td>\n",
       "      <td>As our society begins to wake up from the han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2001-3000</td>\n",
       "      <td>US</td>\n",
       "      <td>41</td>\n",
       "      <td>technology</td>\n",
       "      <td>3d printing</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt;My name is Donal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;p&gt;My name is Donald Osborne and I a...</td>\n",
       "      <td>My name is Donald Osborne and I am an entrepre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2001-3000</td>\n",
       "      <td>GB</td>\n",
       "      <td>29</td>\n",
       "      <td>technology</td>\n",
       "      <td>diy electronics</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;div class=\"templat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;div&gt; &lt;figure&gt; &lt;img&gt; &lt;/figure&gt; &lt;/div...</td>\n",
       "      <td>We all love to play, don't we! No matter the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         goal country  duration   category1        category2  \\\n",
       "0   0    4001-5000      CH        29  publishing      young adult   \n",
       "1   1    3001-4000      NL        34     fashion    ready-to-wear   \n",
       "2   2  19001-20000      US        30        food           spaces   \n",
       "3   3    2001-3000      US        41  technology      3d printing   \n",
       "4   4    2001-3000      GB        29  technology  diy electronics   \n",
       "\n",
       "                                        html_content  state data_type  \\\n",
       "0  <div class=\"contents\"><div><span class=\"bold\">...    0.0     train   \n",
       "1  <div class=\"contents\"><div><h1 class=\"page-anc...    0.0     train   \n",
       "2  <div class=\"contents\"><div><p> As our society ...    0.0     train   \n",
       "3  <div class=\"contents\"><div><p>My name is Donal...    0.0     train   \n",
       "4  <div class=\"contents\"><div><div class=\"templat...    1.0     train   \n",
       "\n",
       "                                       html_compiled  \\\n",
       "0  <div><div><span>Mark Saggia</span> is an Itali...   \n",
       "1  <div><div><h1>Hello, I am Augustinas. I am a g...   \n",
       "2  <div><div><p> As our society begins to wake up...   \n",
       "3  <div><div><p>My name is Donald Osborne and I a...   \n",
       "4  <div><div><div> <figure> <img> </figure> </div...   \n",
       "\n",
       "                                            html_raw  \n",
       "0  Mark Saggia is an Italian writer who emigrated...  \n",
       "1  Hello, I am Augustinas. I am a graphic designe...  \n",
       "2   As our society begins to wake up from the han...  \n",
       "3  My name is Donald Osborne and I am an entrepre...  \n",
       "4   We all love to play, don't we! No matter the ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T13:41:21.075935Z",
     "iopub.status.busy": "2021-01-26T13:41:21.075159Z",
     "iopub.status.idle": "2021-01-26T13:41:21.078638Z",
     "shell.execute_reply": "2021-01-26T13:41:21.077881Z"
    },
    "papermill": {
     "duration": 0.032521,
     "end_time": "2021-01-26T13:41:21.078818",
     "exception": false,
     "start_time": "2021-01-26T13:41:21.046297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HtmlDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform, stage):\n",
    "        self.csv_file = csv_file\n",
    "        self.transform = transform\n",
    "        self.stage = stage\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        html_text = self.csv_file.html_raw.iloc[idx]\n",
    "        html_text = str(html_text)\n",
    "        if self.stage == \"train\":\n",
    "            label = self.csv_file.state.iloc[idx]\n",
    "        elif self.stage == \"eval\":\n",
    "            label = self.csv_file.id.iloc[idx]\n",
    "            \n",
    "        if self.transform:\n",
    "            html_text = self.transform(html_text)\n",
    "            \n",
    "        return html_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T13:41:21.124595Z",
     "iopub.status.busy": "2021-01-26T13:41:21.123715Z",
     "iopub.status.idle": "2021-01-26T13:41:21.133016Z",
     "shell.execute_reply": "2021-01-26T13:41:21.132609Z"
    },
    "papermill": {
     "duration": 0.035831,
     "end_time": "2021-01-26T13:41:21.133136",
     "exception": false,
     "start_time": "2021-01-26T13:41:21.097305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define transform\n",
    "class BERT_Tokenize(object):\n",
    "    def __init__(self, model_type, max_len):\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        if model_type == \"BERT\":\n",
    "            from transformers import BertTokenizer\n",
    "            self.bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "            \n",
    "        elif model_type == \"ALBERT\":\n",
    "            from transformers import AlbertTokenizer\n",
    "            self.bert_tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "            \n",
    "        elif model_type == \"XLNET\":\n",
    "            from transformers import XLNetTokenizer\n",
    "            self.bert_tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "        \n",
    "        elif model_type == \"ROBERTA\":\n",
    "            from transformers import RobertaTokenizer\n",
    "            self.bert_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "        \n",
    "        elif model_type == \"XLMROBERTA\":\n",
    "            from transformers import XLMRobertaTokenizer\n",
    "            self.bert_tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "            \n",
    "        elif model_type == \"ELECTRA\":\n",
    "            from transformers import ElectraTokenizer\n",
    "            self.bert_tokenizer = ElectraTokenizer.from_pretrained(\"google/electra-base-discriminator\")\n",
    "            \n",
    "    \n",
    "    def __call__(self,text):\n",
    "        inputs = self.bert_tokenizer.encode_plus(\n",
    "                        text,                       # Sentence to encode.\n",
    "                        add_special_tokens = True,  # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = self.max_len,  # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,  # Construct attn. masks.\n",
    "                        return_tensors = \"pt\"\n",
    "                   )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        del text, inputs\n",
    "        return ids, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T13:41:21.197923Z",
     "iopub.status.busy": "2021-01-26T13:41:21.191876Z",
     "iopub.status.idle": "2021-01-26T13:41:21.200091Z",
     "shell.execute_reply": "2021-01-26T13:41:21.200489Z"
    },
    "papermill": {
     "duration": 0.030283,
     "end_time": "2021-01-26T13:41:21.200595",
     "exception": false,
     "start_time": "2021-01-26T13:41:21.170312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertHead(nn.Module):\n",
    "    def __init__(self, model_type, out_dim, stage):\n",
    "        super(BertHead, self).__init__()\n",
    "        if model_type == \"ALBERT\":\n",
    "            from transformers import AlbertTokenizer, AlbertModel\n",
    "            self.base_model = AlbertModel.from_pretrained(\"albert-base-v2\")\n",
    "            \n",
    "        elif model_type == \"BERT\":\n",
    "            from transformers import BertTokenizer, BertModel\n",
    "            self.base_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "            \n",
    "        elif model_type == \"XLNET\":\n",
    "            from transformers import XLNetTokenizer, XLNetModel\n",
    "            self.base_model = XLNetModel.from_pretrained(\"xlnet-base-cased\")\n",
    "            \n",
    "        elif model_type == \"ROBERTA\":\n",
    "            from transformers import RobertaTokenizer, RobertaModel\n",
    "            self.base_model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "        \n",
    "        elif model_type == \"XLMROBERTA\":\n",
    "            from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
    "            self.base_model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n",
    "        \n",
    "        elif model_type == \"ELECTRA\":\n",
    "            from transformers import ElectraTokenizer, ElectraModel\n",
    "            self.base_model = ElectraModel.from_pretrained(\"google/electra-base-discriminator\")\n",
    "            \n",
    "        \n",
    "        self.stage = stage\n",
    "        dropout = 0.2\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768, 768), nn.ReLU(), nn.Dropout(p=dropout),\n",
    "            nn.Linear(768, 768), nn.ReLU(), nn.Dropout(p=dropout),\n",
    "            nn.Linear(768, out_dim))\n",
    "         \n",
    "        \"\"\"\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = True\n",
    "        \"\"\"\n",
    "        \n",
    "        # for pooler function\n",
    "        self.dense = nn.Linear(768, 768)\n",
    "        self.activation = nn.Tanh()\n",
    "        \n",
    "    def pooler(self, hidden_states):\n",
    "        first_token_tensor = hidden_states[0][:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ids, mask = x\n",
    "        x = self.base_model(input_ids=torch.squeeze(ids,dim=1), attention_mask=torch.squeeze(mask, dim=1))\n",
    "        if self.stage == \"train\":\n",
    "            x = self.classifier(x[1])\n",
    "            preds = torch.sigmoid(x)\n",
    "        else:\n",
    "            try:\n",
    "                preds = torch.tensor(x[1])\n",
    "            except:\n",
    "                preds = torch.tensor(self.pooler(x[1]))\n",
    "            \n",
    "        del ids, mask\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T13:41:21.231181Z",
     "iopub.status.busy": "2021-01-26T13:41:21.230661Z",
     "iopub.status.idle": "2021-01-26T13:41:21.234150Z",
     "shell.execute_reply": "2021-01-26T13:41:21.233747Z"
    },
    "papermill": {
     "duration": 0.02477,
     "end_time": "2021-01-26T13:41:21.234236",
     "exception": false,
     "start_time": "2021-01-26T13:41:21.209466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_embed_output(model_type=\"BERT\"):\n",
    "    # config\n",
    "    csv_file = all_data\n",
    "    max_length = 512\n",
    "    bert_tokenizer = BERT_Tokenize(model_type, max_length)\n",
    "    transform = bert_tokenizer\n",
    "    out_dim = 1\n",
    "    batch_size = 16\n",
    "    num_workers = 4\n",
    "    stage = \"eval\"\n",
    "    \n",
    "    train_dataset = HtmlDataset(csv_file=csv_file,\n",
    "                                transform=bert_tokenizer,\n",
    "                                stage=stage)\n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                 batch_size=batch_size,\n",
    "                                 num_workers=num_workers)\n",
    "    model = BertHead(model_type=model_type,\n",
    "                    out_dim=out_dim,\n",
    "                    stage=stage)\n",
    "    \n",
    "    preds = torch.tensor([])\n",
    "    ids = []\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for x, t in tqdm(train_dataloader):\n",
    "        x[0], x[1] = x[0].to(device), x[1].to(device)\n",
    "        x = model(x)\n",
    "        preds = torch.cat((preds, x.to(\"cpu\")), dim=0)\n",
    "        ids += list(map(int, t.to(\"cpu\")))\n",
    "        \n",
    "    preds = torch.squeeze(preds)\n",
    "    preds = preds.tolist()\n",
    "    prediction_df = pd.DataFrame(preds)\n",
    "    rename_dict = {}\n",
    "    for n in range(768):\n",
    "        rename_dict[n] = f\"{model_type}_{n}\"\n",
    "    prediction_df = prediction_df.rename(columns=rename_dict)\n",
    "    prediction_df[\"id\"] = ids\n",
    "    \n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T13:41:21.256873Z",
     "iopub.status.busy": "2021-01-26T13:41:21.256321Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2021-01-26T13:41:21.243409",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46290fe9d7ba49589a64a404e9315e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76700287bbf84ca0a21219e3d7bbed30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178224653fb54300b8c9e5761d318fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467042463.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1319 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|█████████▉| 1316/1319 [28:07<00:05,  1.86s/it]"
     ]
    }
   ],
   "source": [
    "model_list = [\"BERT\", \"ALBERT\", \"ROBERTA\", \"XLMROBERTA\", ]　　#　\"XLNET\"は最後の最後(tqdmで1319/1319)でフリーズするバグがあった \"ELECTORA\"未検証\n",
    "for model in model_list:\n",
    "    embed_out_df = extract_embed_output(model_type=model)\n",
    "    embed_out_df.to_csv(f'{model}_embeded.csv', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-26T13:41:01.111906",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
