{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import optuna.integration.lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_new = pd.read_csv('data/feature_df.csv')\n",
    "wordvec_df = pd.read_csv('sub_notebook/data/wordvectorized_df.csv')\n",
    "bert_embeded = pd.read_csv('kaggle-notebook/data/bert_embeded.csv')\n",
    "#tfidf_1000 = pd.read_csv('data/tfidf_1000.csv')\n",
    "tfidf_svd_raw_64 = pd.read_csv(\"data/tfidf_svd_raw_64.csv\")\n",
    "#tfidf_svd_content_64 = pd.read_csv(\"data/tfidf_svd_content_64.csv\")\n",
    "#tfidf_svd_compiled_64 = pd.read_csv(\"data/tfidf_svd_compiled_64.csv\")\n",
    "mfw_df = pd.read_csv('data/mfw.csv')\n",
    "miw_df = pd.read_csv('data/miw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_new = pd.merge(all_new, bert_embeded, on=\"id\", how=\"outer\")\n",
    "all_new = pd.merge(all_new, tfidf_svd_raw_64, on=\"id\", how=\"outer\")\n",
    "all_new = pd.merge(all_new, wordvec_df, on=\"id\", how=\"outer\")\n",
    "all_new = pd.merge(all_new, miw_df, on=\"id\", how=\"outer\")\n",
    "all_new = pd.merge(all_new, mfw_df.drop([\"mfw\", \"sfw\"], axis=1), on=\"id\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = all_new[all_new[\"data_type\"] == \"test\"]\n",
    "train_data = all_new[all_new[\"data_type\"] == \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    with open(path) as f:\n",
    "        json_dict = json.load(f)\n",
    "    return json_dict\n",
    "\n",
    "\n",
    "def get_trained_results(json_paths):\n",
    "    oofs = []\n",
    "    preds = []\n",
    "    for json_path in json_paths:\n",
    "        json_dict = read_json(json_path)\n",
    "        oof = json_dict[\"out_of_fold\"]\n",
    "        pred = json_dict[\"prediction\"]\n",
    "        oofs.append(oof)\n",
    "        preds.append(pred)\n",
    "        json_dict.clear()\n",
    "    return oofs, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "oofs, preds = get_trained_results(json_paths=[\n",
    "    \"data/nn_config_svd64_raw.json\",\n",
    "    \"data/lgbm_config_svd64_raw.json\",\n",
    "    \"data/lgbm_config_bert.json\",\n",
    "    \"data/rf_config_svd64_raw.json\",\n",
    "    \"data/lgbm_config_bert_svd64_raw.json\",\n",
    "    \"data/lgbm_config_bert128_svd64_raw.json\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_danger_vector(oofs, label):\n",
    "    \n",
    "    threshold = 0.4\n",
    "    oofs = np.array(oofs)\n",
    "    label = np.array(label)\n",
    "    diffs = []\n",
    "    for oof in oofs:\n",
    "        oof = np.where(oof < threshold, 0, 1)\n",
    "        diff = label - oof\n",
    "        diff = np.power(diff.astype(int), 2)\n",
    "        diffs.append(diff)\n",
    "    danger_vector = sum(diffs)\n",
    "    return danger_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dang_vec = get_danger_vector(oofs, train_data[\"state\"])\n",
    "dang_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dang_df = pd.DataFrame({\"danger\": dang_vec})\n",
    "dang_df.danger.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "danger_df = train_data[dang_df[\"danger\"] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_distribution(train):\n",
    "    plt.figure(figsize=(12,12))\n",
    "\n",
    "    plt.subplot(3,3,1)\n",
    "    plt.title('state(target)')\n",
    "    try:\n",
    "        train.state.value_counts().plot(kind='bar')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    plt.subplot(3,3,2)\n",
    "    plt.title('country')\n",
    "    train.country.value_counts().plot(kind='bar')\n",
    "\n",
    "    plt.subplot(3,3,3)\n",
    "    plt.title('duration(top20)')\n",
    "    train.duration.value_counts()[:20].plot(kind='bar')\n",
    "\n",
    "    plt.subplot(3,3,4)\n",
    "    plt.title('category1')\n",
    "    train.category1.value_counts().plot(kind='bar')\n",
    "\n",
    "    plt.subplot(3,3,5)\n",
    "    plt.title('category2(top20)')\n",
    "    train.category2.value_counts()[:20].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_distribution(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_distribution(danger_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optuna_lgbm(test, train, target_cols, feature_cols, categorical_cols, seed):\n",
    "    \"\"\"\n",
    "    import optuna.integration.lightgbm as lgb\n",
    "    \"\"\"\n",
    "    X_train = train[feature_cols]\n",
    "    y_train = train[target_cols]\n",
    "    X_test = test[feature_cols]\n",
    "    \n",
    "    y_preds = []\n",
    "    models = []\n",
    "    oof_train = np.zeros((len(X_train),))\n",
    "    importances = []\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    for fold_id, (train_index, valid_index) in enumerate(cv.split(X_train, y_train)):\n",
    "        X_tr = X_train.loc[train_index, :]\n",
    "        X_val = X_train.loc[valid_index, :]\n",
    "        y_tr = y_train.loc[train_index]\n",
    "        y_val = y_train.loc[valid_index]\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_tr,\n",
    "                                y_tr,\n",
    "                                categorical_feature=categorical_cols)\n",
    "\n",
    "        lgb_eval = lgb.Dataset(X_val,\n",
    "                               y_val,\n",
    "                               reference=lgb_train,\n",
    "                               categorical_feature=categorical_cols)\n",
    "        \n",
    "        model = lgb.train(params,\n",
    "                          lgb_train,\n",
    "                          valid_sets=[lgb_train, lgb_eval],\n",
    "                          verbose_eval=False,\n",
    "                          num_boost_round=1000,\n",
    "                          early_stopping_rounds=20,\n",
    "                          )\n",
    "        \n",
    "        oof_train[valid_index] = model.predict(X_val,\n",
    "                                               num_iteration=model.best_iteration)\n",
    "        y_pred = model.predict(X_test,\n",
    "                               num_iteration=model.best_iteration)\n",
    "\n",
    "        y_preds.append(y_pred)\n",
    "        models.append(model)\n",
    "        \n",
    "        \n",
    "        # display importance\n",
    "        importance = pd.DataFrame(model.feature_importance(), index=feature_cols, columns=['importance'])\n",
    "        display(importance)\n",
    "        importances.append(importance)\n",
    "\n",
    "    return oof_train, sum(y_preds) / len(y_preds), importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-27 00:11:59,182]\u001b[0m A new study created in memory with name: no-name-f007b02e-573c-4095-b4c4-1b466d1fcf4c\u001b[0m\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.879827:   0%|          | 0/7 [00:01<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  14%|#4        | 1/7 [00:01<00:07,  1.32s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:00,524]\u001b[0m Trial 0 finished with value: 1.8798268076921196 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 1.8798268076921196.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  14%|#4        | 1/7 [00:01<00:07,  1.32s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  14%|#4        | 1/7 [00:02<00:07,  1.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  29%|##8       | 2/7 [00:02<00:06,  1.31s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:01,808]\u001b[0m Trial 1 finished with value: 1.8948370764714773 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 1.8798268076921196.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  29%|##8       | 2/7 [00:02<00:06,  1.31s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  29%|##8       | 2/7 [00:04<00:06,  1.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  43%|####2     | 3/7 [00:04<00:05,  1.46s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:03,594]\u001b[0m Trial 2 finished with value: 1.901005807748436 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 1.8798268076921196.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  43%|####2     | 3/7 [00:04<00:05,  1.46s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  43%|####2     | 3/7 [00:06<00:05,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  57%|#####7    | 4/7 [00:06<00:05,  1.69s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:05,832]\u001b[0m Trial 3 finished with value: 1.8856604017304441 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 1.8798268076921196.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  57%|#####7    | 4/7 [00:06<00:05,  1.69s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  57%|#####7    | 4/7 [00:08<00:05,  1.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  71%|#######1  | 5/7 [00:08<00:03,  1.78s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:07,829]\u001b[0m Trial 4 finished with value: 1.8955761149585497 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 1.8798268076921196.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  71%|#######1  | 5/7 [00:08<00:03,  1.78s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  71%|#######1  | 5/7 [00:09<00:03,  1.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  86%|########5 | 6/7 [00:09<00:01,  1.64s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:09,125]\u001b[0m Trial 5 finished with value: 1.8909035864934975 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 1.8798268076921196.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.879827:  86%|########5 | 6/7 [00:09<00:01,  1.64s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.877535:  86%|########5 | 6/7 [00:11<00:01,  1.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.877535: 100%|##########| 7/7 [00:11<00:00,  1.50s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:10,323]\u001b[0m Trial 6 finished with value: 1.8775347729638836 and parameters: {'feature_fraction': 0.4}. Best is trial 6 with value: 1.8775347729638836.\u001b[0m\n",
      "feature_fraction, val_score: 1.877535: 100%|##########| 7/7 [00:11<00:00,  1.59s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:   0%|          | 0/20 [00:04<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:   5%|5         | 1/20 [00:04<01:28,  4.64s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:14,972]\u001b[0m Trial 7 finished with value: 1.887984726925151 and parameters: {'num_leaves': 120}. Best is trial 7 with value: 1.887984726925151.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:   5%|5         | 1/20 [00:04<01:28,  4.64s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:   5%|5         | 1/20 [00:09<01:28,  4.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:  10%|#         | 2/20 [00:09<01:26,  4.79s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:20,122]\u001b[0m Trial 8 finished with value: 1.8976472279576102 and parameters: {'num_leaves': 250}. Best is trial 7 with value: 1.887984726925151.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  10%|#         | 2/20 [00:09<01:26,  4.79s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  10%|#         | 2/20 [00:11<01:26,  4.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:  15%|#5        | 3/20 [00:11<01:03,  3.74s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:21,416]\u001b[0m Trial 9 finished with value: 1.8978313197816727 and parameters: {'num_leaves': 161}. Best is trial 7 with value: 1.887984726925151.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  15%|#5        | 3/20 [00:11<01:03,  3.74s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  15%|#5        | 3/20 [00:12<01:03,  3.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:  20%|##        | 4/20 [00:12<00:47,  2.98s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:22,633]\u001b[0m Trial 10 finished with value: 1.8820677213973944 and parameters: {'num_leaves': 19}. Best is trial 10 with value: 1.8820677213973944.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  20%|##        | 4/20 [00:12<00:47,  2.98s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  20%|##        | 4/20 [00:14<00:47,  2.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:  25%|##5       | 5/20 [00:14<00:41,  2.75s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:24,837]\u001b[0m Trial 11 finished with value: 1.880985915767475 and parameters: {'num_leaves': 27}. Best is trial 11 with value: 1.880985915767475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  25%|##5       | 5/20 [00:14<00:41,  2.75s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  25%|##5       | 5/20 [00:19<00:41,  2.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:  30%|###       | 6/20 [00:19<00:48,  3.49s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:30,039]\u001b[0m Trial 12 finished with value: 1.9023059207905229 and parameters: {'num_leaves': 253}. Best is trial 11 with value: 1.880985915767475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  30%|###       | 6/20 [00:19<00:48,  3.49s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  30%|###       | 6/20 [00:24<00:48,  3.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:  35%|###5      | 7/20 [00:24<00:49,  3.77s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:34,483]\u001b[0m Trial 13 finished with value: 1.9072109795129029 and parameters: {'num_leaves': 108}. Best is trial 11 with value: 1.880985915767475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  35%|###5      | 7/20 [00:24<00:49,  3.77s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  35%|###5      | 7/20 [00:38<00:49,  3.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:  40%|####      | 8/20 [00:38<01:21,  6.83s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:48,442]\u001b[0m Trial 14 finished with value: 1.890461554871733 and parameters: {'num_leaves': 187}. Best is trial 11 with value: 1.880985915767475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  40%|####      | 8/20 [00:38<01:21,  6.83s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  40%|####      | 8/20 [00:39<01:21,  6.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:  45%|####5     | 9/20 [00:39<00:56,  5.16s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:49,721]\u001b[0m Trial 15 finished with value: 1.8823725664020945 and parameters: {'num_leaves': 59}. Best is trial 11 with value: 1.880985915767475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  45%|####5     | 9/20 [00:39<00:56,  5.16s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  45%|####5     | 9/20 [00:43<00:56,  5.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:  50%|#####     | 10/20 [00:43<00:49,  4.90s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:54,020]\u001b[0m Trial 16 finished with value: 1.8976742425376827 and parameters: {'num_leaves': 201}. Best is trial 11 with value: 1.880985915767475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  50%|#####     | 10/20 [00:43<00:49,  4.90s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  50%|#####     | 10/20 [00:44<00:49,  4.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:  55%|#####5    | 11/20 [00:44<00:33,  3.68s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:54,848]\u001b[0m Trial 17 finished with value: 1.881084324772805 and parameters: {'num_leaves': 75}. Best is trial 11 with value: 1.880985915767475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  55%|#####5    | 11/20 [00:44<00:33,  3.68s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  55%|#####5    | 11/20 [00:49<00:33,  3.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:  60%|######    | 12/20 [00:49<00:32,  4.03s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:12:59,708]\u001b[0m Trial 18 finished with value: 1.8895329256354545 and parameters: {'num_leaves': 219}. Best is trial 11 with value: 1.880985915767475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  60%|######    | 12/20 [00:49<00:32,  4.03s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  60%|######    | 12/20 [00:50<00:32,  4.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:  65%|######5   | 13/20 [00:50<00:21,  3.05s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:00,449]\u001b[0m Trial 19 finished with value: 1.920327474201649 and parameters: {'num_leaves': 2}. Best is trial 11 with value: 1.880985915767475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  65%|######5   | 13/20 [00:50<00:21,  3.05s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  65%|######5   | 13/20 [00:56<00:21,  3.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:  70%|#######   | 14/20 [00:56<00:24,  4.15s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:07,171]\u001b[0m Trial 20 finished with value: 1.8856910549027663 and parameters: {'num_leaves': 159}. Best is trial 11 with value: 1.880985915767475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  70%|#######   | 14/20 [00:56<00:24,  4.15s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  70%|#######   | 14/20 [00:58<00:24,  4.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:  75%|#######5  | 15/20 [00:58<00:16,  3.36s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:08,700]\u001b[0m Trial 21 finished with value: 1.8917934969020376 and parameters: {'num_leaves': 33}. Best is trial 11 with value: 1.880985915767475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  75%|#######5  | 15/20 [00:58<00:16,  3.36s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  75%|#######5  | 15/20 [01:01<00:16,  3.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.877535:  80%|########  | 16/20 [01:01<00:13,  3.28s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:11,783]\u001b[0m Trial 22 finished with value: 1.8889115492811237 and parameters: {'num_leaves': 85}. Best is trial 11 with value: 1.880985915767475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.877535:  80%|########  | 16/20 [01:01<00:13,  3.28s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.873993:  80%|########  | 16/20 [01:02<00:13,  3.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.873993:  85%|########5 | 17/20 [01:02<00:07,  2.61s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:12,838]\u001b[0m Trial 23 finished with value: 1.8739932248554492 and parameters: {'num_leaves': 43}. Best is trial 23 with value: 1.8739932248554492.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.873993:  85%|########5 | 17/20 [01:02<00:07,  2.61s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.873993:  85%|########5 | 17/20 [01:03<00:07,  2.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.873993:  90%|######### | 18/20 [01:03<00:04,  2.01s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:13,442]\u001b[0m Trial 24 finished with value: 1.8876259098280428 and parameters: {'num_leaves': 48}. Best is trial 23 with value: 1.8739932248554492.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.873993:  90%|######### | 18/20 [01:03<00:04,  2.01s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.873993:  90%|######### | 18/20 [01:04<00:04,  2.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.873993:  95%|#########5| 19/20 [01:04<00:01,  1.71s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:14,450]\u001b[0m Trial 25 finished with value: 1.8900501857532699 and parameters: {'num_leaves': 94}. Best is trial 23 with value: 1.8739932248554492.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.873993:  95%|#########5| 19/20 [01:04<00:01,  1.71s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.873993:  95%|#########5| 19/20 [01:07<00:01,  1.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.873993: 100%|##########| 20/20 [01:07<00:00,  2.14s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:17,589]\u001b[0m Trial 26 finished with value: 1.881163385752621 and parameters: {'num_leaves': 144}. Best is trial 23 with value: 1.8739932248554492.\u001b[0m\n",
      "num_leaves, val_score: 1.873993: 100%|##########| 20/20 [01:07<00:00,  3.36s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.873993:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.873993:   0%|          | 0/10 [00:01<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.873993:  10%|#         | 1/10 [00:01<00:11,  1.31s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:18,914]\u001b[0m Trial 27 finished with value: 1.8918179024848905 and parameters: {'bagging_fraction': 0.7627287556168554, 'bagging_freq': 6}. Best is trial 27 with value: 1.8918179024848905.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  10%|#         | 1/10 [00:01<00:11,  1.31s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  10%|#         | 1/10 [00:02<00:11,  1.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.873993:  20%|##        | 2/10 [00:02<00:09,  1.14s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:19,655]\u001b[0m Trial 28 finished with value: 1.8999593498501803 and parameters: {'bagging_fraction': 0.407102789178354, 'bagging_freq': 1}. Best is trial 27 with value: 1.8918179024848905.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  20%|##        | 2/10 [00:02<00:09,  1.14s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  20%|##        | 2/10 [00:02<00:09,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.873993:  30%|###       | 3/10 [00:02<00:06,  1.02it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:20,261]\u001b[0m Trial 29 finished with value: 1.884444521627171 and parameters: {'bagging_fraction': 0.9954940283702287, 'bagging_freq': 1}. Best is trial 29 with value: 1.884444521627171.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  30%|###       | 3/10 [00:02<00:06,  1.02it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  30%|###       | 3/10 [00:03<00:06,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.873993:  40%|####      | 4/10 [00:03<00:04,  1.22it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:20,696]\u001b[0m Trial 30 finished with value: 1.9221313523275698 and parameters: {'bagging_fraction': 0.40096933846444527, 'bagging_freq': 7}. Best is trial 29 with value: 1.884444521627171.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  40%|####      | 4/10 [00:03<00:04,  1.22it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  40%|####      | 4/10 [00:04<00:04,  1.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.873993:  50%|#####     | 5/10 [00:04<00:05,  1.06s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:22,322]\u001b[0m Trial 31 finished with value: 1.8884311169601302 and parameters: {'bagging_fraction': 0.6656279442848676, 'bagging_freq': 4}. Best is trial 29 with value: 1.884444521627171.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  50%|#####     | 5/10 [00:04<00:05,  1.06s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  50%|#####     | 5/10 [00:06<00:05,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.873993:  60%|######    | 6/10 [00:06<00:05,  1.40s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:24,500]\u001b[0m Trial 32 finished with value: 1.879931050974171 and parameters: {'bagging_fraction': 0.9912849761189488, 'bagging_freq': 4}. Best is trial 32 with value: 1.879931050974171.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  60%|######    | 6/10 [00:06<00:05,  1.40s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  60%|######    | 6/10 [00:09<00:05,  1.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.873993:  70%|#######   | 7/10 [00:09<00:05,  1.80s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:27,231]\u001b[0m Trial 33 finished with value: 1.8892257655213656 and parameters: {'bagging_fraction': 0.9764966609696677, 'bagging_freq': 4}. Best is trial 32 with value: 1.879931050974171.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  70%|#######   | 7/10 [00:09<00:05,  1.80s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  70%|#######   | 7/10 [00:12<00:05,  1.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.873993:  80%|########  | 8/10 [00:12<00:04,  2.02s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:29,774]\u001b[0m Trial 34 finished with value: 1.8823775789974644 and parameters: {'bagging_fraction': 0.7945187401156063, 'bagging_freq': 3}. Best is trial 32 with value: 1.879931050974171.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  80%|########  | 8/10 [00:12<00:04,  2.02s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  80%|########  | 8/10 [00:13<00:04,  2.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.873993:  90%|######### | 9/10 [00:13<00:01,  1.90s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:31,397]\u001b[0m Trial 35 finished with value: 1.8987737274439809 and parameters: {'bagging_fraction': 0.5802594754760235, 'bagging_freq': 5}. Best is trial 32 with value: 1.879931050974171.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  90%|######### | 9/10 [00:13<00:01,  1.90s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.873993:  90%|######### | 9/10 [00:16<00:01,  1.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.873993: 100%|##########| 10/10 [00:16<00:00,  2.06s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:33,830]\u001b[0m Trial 36 finished with value: 1.878699071947248 and parameters: {'bagging_fraction': 0.8995581826395683, 'bagging_freq': 2}. Best is trial 36 with value: 1.878699071947248.\u001b[0m\n",
      "bagging, val_score: 1.873993: 100%|##########| 10/10 [00:16<00:00,  1.62s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.873993:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.873993:   0%|          | 0/3 [00:01<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.873993:  33%|###3      | 1/3 [00:01<00:03,  1.86s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:35,698]\u001b[0m Trial 37 finished with value: 1.8877395417471479 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 1.8877395417471479.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.873993:  33%|###3      | 1/3 [00:01<00:03,  1.86s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.873993:  33%|###3      | 1/3 [00:05<00:03,  1.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.873993:  67%|######6   | 2/3 [00:05<00:02,  2.36s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:39,228]\u001b[0m Trial 38 finished with value: 1.8755710025665646 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 38 with value: 1.8755710025665646.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.873993:  67%|######6   | 2/3 [00:05<00:02,  2.36s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.873993:  67%|######6   | 2/3 [00:06<00:02,  2.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.873993: 100%|##########| 3/3 [00:06<00:00,  1.97s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:40,271]\u001b[0m Trial 39 finished with value: 1.8885940392020781 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 38 with value: 1.8755710025665646.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.873993: 100%|##########| 3/3 [00:06<00:00,  2.15s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:   5%|5         | 1/20 [00:00<00:11,  1.66it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:40,881]\u001b[0m Trial 40 finished with value: 1.873993325285966 and parameters: {'lambda_l1': 0.0006175096057903686, 'lambda_l2': 6.455243290685916e-08}. Best is trial 40 with value: 1.873993325285966.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:   5%|5         | 1/20 [00:00<00:11,  1.66it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:   5%|5         | 1/20 [00:01<00:11,  1.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  10%|#         | 2/20 [00:01<00:10,  1.68it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:41,465]\u001b[0m Trial 41 finished with value: 1.873993345095586 and parameters: {'lambda_l1': 0.0007403984877827474, 'lambda_l2': 1.2833556493191379e-08}. Best is trial 40 with value: 1.873993325285966.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  10%|#         | 2/20 [00:01<00:10,  1.68it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  10%|#         | 2/20 [00:01<00:10,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  15%|#5        | 3/20 [00:01<00:10,  1.60it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:42,162]\u001b[0m Trial 42 finished with value: 1.8739933715811385 and parameters: {'lambda_l1': 0.0009030742875765497, 'lambda_l2': 1.0565722212898624e-08}. Best is trial 40 with value: 1.873993325285966.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  15%|#5        | 3/20 [00:01<00:10,  1.60it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  15%|#5        | 3/20 [00:02<00:10,  1.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  20%|##        | 4/20 [00:02<00:09,  1.65it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:42,723]\u001b[0m Trial 43 finished with value: 1.873993354352591 and parameters: {'lambda_l1': 0.0007973703533702753, 'lambda_l2': 1.0442183040392706e-08}. Best is trial 40 with value: 1.873993325285966.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  20%|##        | 4/20 [00:02<00:09,  1.65it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  20%|##        | 4/20 [00:05<00:09,  1.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  25%|##5       | 5/20 [00:05<00:18,  1.26s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:45,518]\u001b[0m Trial 44 finished with value: 1.8739933495884733 and parameters: {'lambda_l1': 0.0007685041566866522, 'lambda_l2': 1.0634465693033102e-08}. Best is trial 40 with value: 1.873993325285966.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  25%|##5       | 5/20 [00:05<00:18,  1.26s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  25%|##5       | 5/20 [00:05<00:18,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  30%|###       | 6/20 [00:05<00:14,  1.07s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:46,135]\u001b[0m Trial 45 finished with value: 1.8739933372951987 and parameters: {'lambda_l1': 0.0006920846555707981, 'lambda_l2': 1.230304708072944e-08}. Best is trial 40 with value: 1.873993325285966.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  30%|###       | 6/20 [00:05<00:14,  1.07s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  30%|###       | 6/20 [00:06<00:14,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  35%|###5      | 7/20 [00:06<00:12,  1.06it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:46,793]\u001b[0m Trial 46 finished with value: 1.8739933273302771 and parameters: {'lambda_l1': 0.00062980765827883, 'lambda_l2': 1.446548697428417e-08}. Best is trial 40 with value: 1.873993325285966.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  35%|###5      | 7/20 [00:06<00:12,  1.06it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  35%|###5      | 7/20 [00:07<00:12,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  40%|####      | 8/20 [00:07<00:10,  1.19it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:47,383]\u001b[0m Trial 47 finished with value: 1.8739933158498692 and parameters: {'lambda_l1': 0.0005590921698549725, 'lambda_l2': 2.18676570982257e-08}. Best is trial 47 with value: 1.8739933158498692.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  40%|####      | 8/20 [00:07<00:10,  1.19it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  40%|####      | 8/20 [00:08<00:10,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  45%|####5     | 9/20 [00:08<00:12,  1.12s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:49,160]\u001b[0m Trial 48 finished with value: 1.873993225657941 and parameters: {'lambda_l1': 6.560488303957012e-07, 'lambda_l2': 5.088583895699477e-06}. Best is trial 48 with value: 1.873993225657941.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  45%|####5     | 9/20 [00:08<00:12,  1.12s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  45%|####5     | 9/20 [00:10<00:12,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  50%|#####     | 10/20 [00:10<00:13,  1.35s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:51,034]\u001b[0m Trial 49 finished with value: 1.873993236128336 and parameters: {'lambda_l1': 3.6261515255281164e-08, 'lambda_l2': 8.98375649164441e-05}. Best is trial 48 with value: 1.873993225657941.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  50%|#####     | 10/20 [00:10<00:13,  1.35s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  50%|#####     | 10/20 [00:12<00:13,  1.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  55%|#####5    | 11/20 [00:12<00:13,  1.45s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:52,715]\u001b[0m Trial 50 finished with value: 1.873993243040137 and parameters: {'lambda_l1': 5.20507028133603e-08, 'lambda_l2': 0.00014442447908282453}. Best is trial 48 with value: 1.873993225657941.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  55%|#####5    | 11/20 [00:12<00:13,  1.45s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  55%|#####5    | 11/20 [00:13<00:13,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  60%|######    | 12/20 [00:13<00:11,  1.48s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:54,280]\u001b[0m Trial 51 finished with value: 1.8739932448821195 and parameters: {'lambda_l1': 4.090767962565985e-08, 'lambda_l2': 0.00015969364671711465}. Best is trial 48 with value: 1.873993225657941.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  60%|######    | 12/20 [00:14<00:11,  1.48s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  60%|######    | 12/20 [00:15<00:11,  1.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  65%|######5   | 13/20 [00:15<00:10,  1.47s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:55,722]\u001b[0m Trial 52 finished with value: 1.8739932483953905 and parameters: {'lambda_l1': 3.839355996427326e-08, 'lambda_l2': 0.0001873724891934016}. Best is trial 48 with value: 1.873993225657941.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  65%|######5   | 13/20 [00:15<00:10,  1.47s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  65%|######5   | 13/20 [00:16<00:10,  1.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  70%|#######   | 14/20 [00:16<00:08,  1.44s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:57,090]\u001b[0m Trial 53 finished with value: 1.8739932522844651 and parameters: {'lambda_l1': 3.934924808011702e-08, 'lambda_l2': 0.00021892630107648813}. Best is trial 48 with value: 1.873993225657941.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  70%|#######   | 14/20 [00:16<00:08,  1.44s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  70%|#######   | 14/20 [00:18<00:08,  1.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  75%|#######5  | 15/20 [00:18<00:07,  1.41s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:58,435]\u001b[0m Trial 54 finished with value: 1.8739932493993232 and parameters: {'lambda_l1': 3.820148689019892e-08, 'lambda_l2': 0.00019578419657815285}. Best is trial 48 with value: 1.873993225657941.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  75%|#######5  | 15/20 [00:18<00:07,  1.41s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  75%|#######5  | 15/20 [00:19<00:07,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  80%|########  | 16/20 [00:19<00:05,  1.37s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:13:59,719]\u001b[0m Trial 55 finished with value: 1.8739932261242658 and parameters: {'lambda_l1': 1.4574377490257522e-06, 'lambda_l2': 7.287723516246706e-06}. Best is trial 48 with value: 1.873993225657941.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  80%|########  | 16/20 [00:19<00:05,  1.37s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  80%|########  | 16/20 [00:20<00:05,  1.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  85%|########5 | 17/20 [00:20<00:04,  1.43s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:01,270]\u001b[0m Trial 56 finished with value: 1.8739932260434151 and parameters: {'lambda_l1': 5.132174128796277e-06, 'lambda_l2': 2.238861367445986e-06}. Best is trial 48 with value: 1.873993225657941.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  85%|########5 | 17/20 [00:20<00:04,  1.43s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  85%|########5 | 17/20 [00:22<00:04,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  90%|######### | 18/20 [00:22<00:03,  1.56s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:03,142]\u001b[0m Trial 57 finished with value: 1.8739932257205818 and parameters: {'lambda_l1': 2.647477576337922e-06, 'lambda_l2': 3.019470436098503e-06}. Best is trial 48 with value: 1.873993225657941.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  90%|######### | 18/20 [00:22<00:03,  1.56s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  90%|######### | 18/20 [00:24<00:03,  1.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  95%|#########5| 19/20 [00:24<00:01,  1.72s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:05,249]\u001b[0m Trial 58 finished with value: 1.8739932265375912 and parameters: {'lambda_l1': 8.039326079648133e-06, 'lambda_l2': 2.1778727856339264e-06}. Best is trial 48 with value: 1.873993225657941.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  95%|#########5| 19/20 [00:24<00:01,  1.72s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.873993:  95%|#########5| 19/20 [00:26<00:01,  1.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.873993: 100%|##########| 20/20 [00:26<00:00,  1.68s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:06,832]\u001b[0m Trial 59 finished with value: 1.873993225984488 and parameters: {'lambda_l1': 4.518203818533924e-06, 'lambda_l2': 2.5634449843037846e-06}. Best is trial 48 with value: 1.873993225657941.\u001b[0m\n",
      "regularization_factors, val_score: 1.873993: 100%|##########| 20/20 [00:26<00:00,  1.33s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.873993:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.873993:   0%|          | 0/5 [00:01<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.873993:  20%|##        | 1/5 [00:01<00:05,  1.44s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:08,281]\u001b[0m Trial 60 finished with value: 1.8877751522044846 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 1.8877751522044846.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.873993:  20%|##        | 1/5 [00:01<00:05,  1.44s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.873993:  20%|##        | 1/5 [00:02<00:05,  1.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.873993:  40%|####      | 2/5 [00:02<00:03,  1.18s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:08,866]\u001b[0m Trial 61 finished with value: 1.8763381285808232 and parameters: {'min_child_samples': 10}. Best is trial 61 with value: 1.8763381285808232.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.873993:  40%|####      | 2/5 [00:02<00:03,  1.18s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.873993:  40%|####      | 2/5 [00:02<00:03,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.873993:  60%|######    | 3/5 [00:02<00:02,  1.02s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:09,488]\u001b[0m Trial 62 finished with value: 1.8815208551852014 and parameters: {'min_child_samples': 100}. Best is trial 61 with value: 1.8763381285808232.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.873993:  60%|######    | 3/5 [00:02<00:02,  1.02s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.873993:  60%|######    | 3/5 [00:03<00:02,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.873993:  80%|########  | 4/5 [00:03<00:00,  1.09it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:10,176]\u001b[0m Trial 63 finished with value: 1.8933394411973223 and parameters: {'min_child_samples': 5}. Best is trial 61 with value: 1.8763381285808232.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.873993:  80%|########  | 4/5 [00:03<00:00,  1.09it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34646\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.873993:  80%|########  | 4/5 [00:04<00:00,  1.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.873993: 100%|##########| 5/5 [00:04<00:00,  1.16it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:10,911]\u001b[0m Trial 64 finished with value: 1.8819843123523206 and parameters: {'min_child_samples': 25}. Best is trial 61 with value: 1.8763381285808232.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.873993: 100%|##########| 5/5 [00:04<00:00,  1.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category2</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_&lt;h1&gt;</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_&lt;/i&gt;</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category1+category2</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country+category1</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_17_y</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_18_y</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_19_y</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_23_y</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_24_y</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importance\n",
       "category2                    62\n",
       "number_of_<h1>                6\n",
       "number_of_</i>                3\n",
       "category1+category2          46\n",
       "country+category1            14\n",
       "...                         ...\n",
       "wordvec_17_y                  1\n",
       "wordvec_18_y                  4\n",
       "wordvec_19_y                 12\n",
       "wordvec_23_y                  4\n",
       "wordvec_24_y                  8\n",
       "\n",
       "[148 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-27 00:14:11,006]\u001b[0m A new study created in memory with name: no-name-2989485d-52f9-4e2d-aea3-c286147fd227\u001b[0m\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.880506:   0%|          | 0/7 [00:02<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.880506:  14%|#4        | 1/7 [00:02<00:15,  2.53s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:13,538]\u001b[0m Trial 0 finished with value: 1.8805059682747591 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 1.8805059682747591.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.880506:  14%|#4        | 1/7 [00:02<00:15,  2.53s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.878511:  14%|#4        | 1/7 [00:03<00:15,  2.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.878511:  29%|##8       | 2/7 [00:03<00:09,  1.92s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:14,040]\u001b[0m Trial 1 finished with value: 1.87851113515091 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 1.87851113515091.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.878511:  29%|##8       | 2/7 [00:03<00:09,  1.92s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.875456:  29%|##8       | 2/7 [00:03<00:09,  1.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.875456:  43%|####2     | 3/7 [00:03<00:06,  1.61s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:14,930]\u001b[0m Trial 2 finished with value: 1.8754560251620338 and parameters: {'feature_fraction': 0.6}. Best is trial 2 with value: 1.8754560251620338.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.875456:  43%|####2     | 3/7 [00:03<00:06,  1.61s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.874861:  43%|####2     | 3/7 [00:04<00:06,  1.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.874861:  57%|#####7    | 4/7 [00:04<00:03,  1.29s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:15,475]\u001b[0m Trial 3 finished with value: 1.8748608762361583 and parameters: {'feature_fraction': 1.0}. Best is trial 3 with value: 1.8748608762361583.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.874861:  57%|#####7    | 4/7 [00:04<00:03,  1.29s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.868389:  57%|#####7    | 4/7 [00:06<00:03,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.868389:  71%|#######1  | 5/7 [00:06<00:02,  1.40s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:17,120]\u001b[0m Trial 4 finished with value: 1.868388727385619 and parameters: {'feature_fraction': 0.7}. Best is trial 4 with value: 1.868388727385619.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.868389:  71%|#######1  | 5/7 [00:06<00:02,  1.40s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.868389:  71%|#######1  | 5/7 [00:07<00:02,  1.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.868389:  86%|########5 | 6/7 [00:07<00:01,  1.33s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:18,307]\u001b[0m Trial 5 finished with value: 1.8903304701182522 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 4 with value: 1.868388727385619.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.868389:  86%|########5 | 6/7 [00:07<00:01,  1.33s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.868389:  86%|########5 | 6/7 [00:09<00:01,  1.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.868389: 100%|##########| 7/7 [00:09<00:00,  1.46s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:20,071]\u001b[0m Trial 6 finished with value: 1.8711539755838296 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 1.868388727385619.\u001b[0m\n",
      "feature_fraction, val_score: 1.868389: 100%|##########| 7/7 [00:09<00:00,  1.29s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.868389:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:   0%|          | 0/20 [00:03<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.868389:   5%|5         | 1/20 [00:03<01:14,  3.91s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:23,991]\u001b[0m Trial 7 finished with value: 1.8815276222910808 and parameters: {'num_leaves': 80}. Best is trial 7 with value: 1.8815276222910808.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:   5%|5         | 1/20 [00:03<01:14,  3.91s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:   5%|5         | 1/20 [00:09<01:14,  3.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.868389:  10%|#         | 2/20 [00:09<01:18,  4.34s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:29,339]\u001b[0m Trial 8 finished with value: 1.879475407361427 and parameters: {'num_leaves': 130}. Best is trial 8 with value: 1.879475407361427.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  10%|#         | 2/20 [00:09<01:18,  4.34s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  10%|#         | 2/20 [00:13<01:18,  4.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.868389:  15%|#5        | 3/20 [00:13<01:12,  4.25s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:33,361]\u001b[0m Trial 9 finished with value: 1.8906401262134254 and parameters: {'num_leaves': 111}. Best is trial 8 with value: 1.879475407361427.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  15%|#5        | 3/20 [00:13<01:12,  4.25s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  15%|#5        | 3/20 [00:16<01:12,  4.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.868389:  20%|##        | 4/20 [00:16<01:02,  3.92s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:36,504]\u001b[0m Trial 10 finished with value: 1.8870137049648021 and parameters: {'num_leaves': 253}. Best is trial 8 with value: 1.879475407361427.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  20%|##        | 4/20 [00:16<01:02,  3.92s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  20%|##        | 4/20 [00:16<01:02,  3.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.868389:  25%|##5       | 5/20 [00:16<00:42,  2.83s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:36,786]\u001b[0m Trial 11 finished with value: 1.879416291355776 and parameters: {'num_leaves': 6}. Best is trial 11 with value: 1.879416291355776.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  25%|##5       | 5/20 [00:16<00:42,  2.83s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  25%|##5       | 5/20 [00:20<00:42,  2.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.868389:  30%|###       | 6/20 [00:20<00:45,  3.23s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:40,950]\u001b[0m Trial 12 finished with value: 1.89696802730409 and parameters: {'num_leaves': 249}. Best is trial 11 with value: 1.879416291355776.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  30%|###       | 6/20 [00:20<00:45,  3.23s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  30%|###       | 6/20 [00:25<00:45,  3.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.868389:  35%|###5      | 7/20 [00:25<00:46,  3.57s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:45,317]\u001b[0m Trial 13 finished with value: 1.8803384987598932 and parameters: {'num_leaves': 189}. Best is trial 11 with value: 1.879416291355776.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  35%|###5      | 7/20 [00:25<00:46,  3.57s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  35%|###5      | 7/20 [00:25<00:46,  3.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.868389:  40%|####      | 8/20 [00:25<00:32,  2.72s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:46,071]\u001b[0m Trial 14 finished with value: 1.8960019555097571 and parameters: {'num_leaves': 2}. Best is trial 11 with value: 1.879416291355776.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  40%|####      | 8/20 [00:26<00:32,  2.72s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  40%|####      | 8/20 [00:28<00:32,  2.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.868389:  45%|####5     | 9/20 [00:28<00:29,  2.65s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:48,549]\u001b[0m Trial 15 finished with value: 1.8790093841446087 and parameters: {'num_leaves': 45}. Best is trial 15 with value: 1.8790093841446087.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  45%|####5     | 9/20 [00:28<00:29,  2.65s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  45%|####5     | 9/20 [00:35<00:29,  2.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.868389:  50%|#####     | 10/20 [00:35<00:38,  3.85s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:14:55,215]\u001b[0m Trial 16 finished with value: 1.8887547944025853 and parameters: {'num_leaves': 187}. Best is trial 15 with value: 1.8790093841446087.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  50%|#####     | 10/20 [00:35<00:38,  3.85s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  50%|#####     | 10/20 [00:40<00:38,  3.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.868389:  55%|#####5    | 11/20 [00:40<00:37,  4.17s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:00,131]\u001b[0m Trial 17 finished with value: 1.8887369176234134 and parameters: {'num_leaves': 198}. Best is trial 15 with value: 1.8790093841446087.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  55%|#####5    | 11/20 [00:40<00:37,  4.17s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  55%|#####5    | 11/20 [00:42<00:37,  4.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.868389:  60%|######    | 12/20 [00:42<00:30,  3.77s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:02,949]\u001b[0m Trial 18 finished with value: 1.8736152047372212 and parameters: {'num_leaves': 143}. Best is trial 18 with value: 1.8736152047372212.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  60%|######    | 12/20 [00:42<00:30,  3.77s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  60%|######    | 12/20 [00:43<00:30,  3.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.868389:  65%|######5   | 13/20 [00:43<00:19,  2.81s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:03,510]\u001b[0m Trial 19 finished with value: 1.8710343422423352 and parameters: {'num_leaves': 46}. Best is trial 19 with value: 1.8710343422423352.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  65%|######5   | 13/20 [00:43<00:19,  2.81s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  65%|######5   | 13/20 [00:44<00:19,  2.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.868389:  70%|#######   | 14/20 [00:44<00:12,  2.14s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:04,098]\u001b[0m Trial 20 finished with value: 1.879747707653261 and parameters: {'num_leaves': 39}. Best is trial 19 with value: 1.8710343422423352.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.868389:  70%|#######   | 14/20 [00:44<00:12,  2.14s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.866199:  70%|#######   | 14/20 [00:47<00:12,  2.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.866199:  75%|#######5  | 15/20 [00:47<00:12,  2.48s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:07,370]\u001b[0m Trial 21 finished with value: 1.866198829193506 and parameters: {'num_leaves': 70}. Best is trial 21 with value: 1.866198829193506.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.866199:  75%|#######5  | 15/20 [00:47<00:12,  2.48s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.866199:  75%|#######5  | 15/20 [00:48<00:12,  2.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.866199:  80%|########  | 16/20 [00:48<00:07,  1.96s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:08,117]\u001b[0m Trial 22 finished with value: 1.8852991576596256 and parameters: {'num_leaves': 67}. Best is trial 21 with value: 1.866198829193506.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.866199:  80%|########  | 16/20 [00:48<00:07,  1.96s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.866199:  80%|########  | 16/20 [00:49<00:07,  1.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.866199:  85%|########5 | 17/20 [00:49<00:05,  1.93s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:09,987]\u001b[0m Trial 23 finished with value: 1.8840312230033474 and parameters: {'num_leaves': 95}. Best is trial 21 with value: 1.866198829193506.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.866199:  85%|########5 | 17/20 [00:49<00:05,  1.93s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.866199:  85%|########5 | 17/20 [00:50<00:05,  1.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.866199:  90%|######### | 18/20 [00:50<00:03,  1.55s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:10,653]\u001b[0m Trial 24 finished with value: 1.8787621647908215 and parameters: {'num_leaves': 25}. Best is trial 21 with value: 1.866198829193506.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.866199:  90%|######### | 18/20 [00:50<00:03,  1.55s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.866199:  90%|######### | 18/20 [00:52<00:03,  1.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.866199:  95%|#########5| 19/20 [00:52<00:01,  1.69s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:12,649]\u001b[0m Trial 25 finished with value: 1.882427864279251 and parameters: {'num_leaves': 59}. Best is trial 21 with value: 1.866198829193506.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.866199:  95%|#########5| 19/20 [00:52<00:01,  1.69s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.866199:  95%|#########5| 19/20 [00:53<00:01,  1.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.866199: 100%|##########| 20/20 [00:53<00:00,  1.54s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:13,865]\u001b[0m Trial 26 finished with value: 1.8787621647908215 and parameters: {'num_leaves': 25}. Best is trial 21 with value: 1.866198829193506.\u001b[0m\n",
      "num_leaves, val_score: 1.866199: 100%|##########| 20/20 [00:53<00:00,  2.69s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866199:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866199:   0%|          | 0/10 [00:02<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866199:  10%|#         | 1/10 [00:02<00:19,  2.18s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:16,064]\u001b[0m Trial 27 finished with value: 1.8923453438011888 and parameters: {'bagging_fraction': 0.8184056223184413, 'bagging_freq': 7}. Best is trial 27 with value: 1.8923453438011888.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  10%|#         | 1/10 [00:02<00:19,  2.18s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  10%|#         | 1/10 [00:03<00:19,  2.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866199:  20%|##        | 2/10 [00:03<00:16,  2.07s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:17,873]\u001b[0m Trial 28 finished with value: 1.9231264296324833 and parameters: {'bagging_fraction': 0.4693277260505729, 'bagging_freq': 1}. Best is trial 27 with value: 1.8923453438011888.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  20%|##        | 2/10 [00:04<00:16,  2.07s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  20%|##        | 2/10 [00:06<00:16,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866199:  30%|###       | 3/10 [00:06<00:14,  2.11s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:20,083]\u001b[0m Trial 29 finished with value: 1.8815665611289507 and parameters: {'bagging_fraction': 0.410468058952408, 'bagging_freq': 4}. Best is trial 29 with value: 1.8815665611289507.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  30%|###       | 3/10 [00:06<00:14,  2.11s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  30%|###       | 3/10 [00:10<00:14,  2.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866199:  40%|####      | 4/10 [00:10<00:16,  2.80s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:24,498]\u001b[0m Trial 30 finished with value: 1.8860681128344936 and parameters: {'bagging_fraction': 0.9944517798156016, 'bagging_freq': 7}. Best is trial 29 with value: 1.8815665611289507.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  40%|####      | 4/10 [00:10<00:16,  2.80s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  40%|####      | 4/10 [00:13<00:16,  2.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866199:  50%|#####     | 5/10 [00:13<00:14,  2.94s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:27,749]\u001b[0m Trial 31 finished with value: 1.903238077391633 and parameters: {'bagging_fraction': 0.6442659982810317, 'bagging_freq': 1}. Best is trial 29 with value: 1.8815665611289507.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  50%|#####     | 5/10 [00:13<00:14,  2.94s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  50%|#####     | 5/10 [00:15<00:14,  2.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866199:  60%|######    | 6/10 [00:15<00:09,  2.42s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:28,951]\u001b[0m Trial 32 finished with value: 1.8836478635020975 and parameters: {'bagging_fraction': 0.9641356580376192, 'bagging_freq': 4}. Best is trial 29 with value: 1.8815665611289507.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  60%|######    | 6/10 [00:15<00:09,  2.42s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  60%|######    | 6/10 [00:15<00:09,  2.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866199:  70%|#######   | 7/10 [00:15<00:05,  1.88s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:29,586]\u001b[0m Trial 33 finished with value: 1.9039263012112695 and parameters: {'bagging_fraction': 0.598380742757695, 'bagging_freq': 6}. Best is trial 29 with value: 1.8815665611289507.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  70%|#######   | 7/10 [00:15<00:05,  1.88s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  70%|#######   | 7/10 [00:16<00:05,  1.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866199:  80%|########  | 8/10 [00:16<00:03,  1.60s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:30,524]\u001b[0m Trial 34 finished with value: 1.8819588062882286 and parameters: {'bagging_fraction': 0.7805612819797876, 'bagging_freq': 2}. Best is trial 29 with value: 1.8815665611289507.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  80%|########  | 8/10 [00:16<00:03,  1.60s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  80%|########  | 8/10 [00:17<00:03,  1.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866199:  90%|######### | 9/10 [00:17<00:01,  1.33s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:31,230]\u001b[0m Trial 35 finished with value: 1.9016255459344529 and parameters: {'bagging_fraction': 0.5212724294149703, 'bagging_freq': 3}. Best is trial 29 with value: 1.8815665611289507.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  90%|######### | 9/10 [00:17<00:01,  1.33s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866199:  90%|######### | 9/10 [00:20<00:01,  1.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866199: 100%|##########| 10/10 [00:20<00:00,  1.89s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:34,436]\u001b[0m Trial 36 finished with value: 1.8870558400847715 and parameters: {'bagging_fraction': 0.866713561652384, 'bagging_freq': 5}. Best is trial 29 with value: 1.8815665611289507.\u001b[0m\n",
      "bagging, val_score: 1.866199: 100%|##########| 10/10 [00:20<00:00,  2.06s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:   0%|          | 0/6 [00:01<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:  17%|#6        | 1/6 [00:01<00:05,  1.08s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:35,526]\u001b[0m Trial 37 finished with value: 1.8845243731394146 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 37 with value: 1.8845243731394146.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:  17%|#6        | 1/6 [00:01<00:05,  1.08s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:  17%|#6        | 1/6 [00:03<00:05,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:  33%|###3      | 2/6 [00:03<00:05,  1.46s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:37,849]\u001b[0m Trial 38 finished with value: 1.883404766285021 and parameters: {'feature_fraction': 0.716}. Best is trial 38 with value: 1.883404766285021.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:  33%|###3      | 2/6 [00:03<00:05,  1.46s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:  33%|###3      | 2/6 [00:06<00:05,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:  50%|#####     | 3/6 [00:06<00:05,  1.99s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:41,099]\u001b[0m Trial 39 finished with value: 1.8816117034439384 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 39 with value: 1.8816117034439384.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:  50%|#####     | 3/6 [00:06<00:05,  1.99s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:  50%|#####     | 3/6 [00:09<00:05,  1.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:  67%|######6   | 4/6 [00:09<00:04,  2.30s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:44,111]\u001b[0m Trial 40 finished with value: 1.879826789522526 and parameters: {'feature_fraction': 0.62}. Best is trial 40 with value: 1.879826789522526.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:  67%|######6   | 4/6 [00:09<00:04,  2.30s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:  67%|######6   | 4/6 [00:12<00:04,  2.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:  83%|########3 | 5/6 [00:12<00:02,  2.42s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:46,821]\u001b[0m Trial 41 finished with value: 1.889683264495897 and parameters: {'feature_fraction': 0.652}. Best is trial 40 with value: 1.879826789522526.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:  83%|########3 | 5/6 [00:12<00:02,  2.42s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199:  83%|########3 | 5/6 [00:15<00:02,  2.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866199: 100%|##########| 6/6 [00:15<00:00,  2.71s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:50,195]\u001b[0m Trial 42 finished with value: 1.8845819932599726 and parameters: {'feature_fraction': 0.748}. Best is trial 40 with value: 1.879826789522526.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.866199: 100%|##########| 6/6 [00:15<00:00,  2.63s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:   0%|          | 0/20 [00:03<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:   5%|5         | 1/20 [00:03<00:57,  3.02s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:53,221]\u001b[0m Trial 43 finished with value: 1.8793026963212525 and parameters: {'lambda_l1': 6.0823770671151194e-05, 'lambda_l2': 2.4602927343020973}. Best is trial 43 with value: 1.8793026963212525.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:   5%|5         | 1/20 [00:03<00:57,  3.02s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:   5%|5         | 1/20 [00:04<00:57,  3.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  10%|#         | 2/20 [00:04<00:43,  2.44s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:54,331]\u001b[0m Trial 44 finished with value: 1.8815734910470112 and parameters: {'lambda_l1': 1.5076042026151073, 'lambda_l2': 1.1546804930271971e-08}. Best is trial 43 with value: 1.8793026963212525.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  10%|#         | 2/20 [00:04<00:43,  2.44s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  10%|#         | 2/20 [00:05<00:43,  2.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  15%|#5        | 3/20 [00:05<00:33,  1.99s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:55,263]\u001b[0m Trial 45 finished with value: 1.8661988284169555 and parameters: {'lambda_l1': 1.8589444027976537e-08, 'lambda_l2': 1.109435731739561e-06}. Best is trial 45 with value: 1.8661988284169555.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  15%|#5        | 3/20 [00:05<00:33,  1.99s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  15%|#5        | 3/20 [00:07<00:33,  1.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  20%|##        | 4/20 [00:07<00:32,  2.03s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:57,376]\u001b[0m Trial 46 finished with value: 1.8661988286246913 and parameters: {'lambda_l1': 2.1099672921341604e-08, 'lambda_l2': 7.690448358397687e-07}. Best is trial 45 with value: 1.8661988284169555.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  20%|##        | 4/20 [00:07<00:32,  2.03s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  20%|##        | 4/20 [00:09<00:32,  2.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  25%|##5       | 5/20 [00:09<00:30,  2.05s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:15:59,472]\u001b[0m Trial 47 finished with value: 1.8661988285958788 and parameters: {'lambda_l1': 1.4919069908972756e-08, 'lambda_l2': 8.341358809986503e-07}. Best is trial 45 with value: 1.8661988284169555.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  25%|##5       | 5/20 [00:09<00:30,  2.05s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  25%|##5       | 5/20 [00:10<00:30,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  30%|###       | 6/20 [00:10<00:24,  1.73s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:00,448]\u001b[0m Trial 48 finished with value: 1.8661988287697517 and parameters: {'lambda_l1': 1.9891258549423526e-08, 'lambda_l2': 5.782984416201898e-07}. Best is trial 45 with value: 1.8661988284169555.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  30%|###       | 6/20 [00:10<00:24,  1.73s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  30%|###       | 6/20 [00:12<00:24,  1.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  35%|###5      | 7/20 [00:12<00:24,  1.89s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:02,728]\u001b[0m Trial 49 finished with value: 1.8661988287393678 and parameters: {'lambda_l1': 1.455687234789777e-08, 'lambda_l2': 6.156126127965899e-07}. Best is trial 45 with value: 1.8661988284169555.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  35%|###5      | 7/20 [00:12<00:24,  1.89s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  35%|###5      | 7/20 [00:15<00:24,  1.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  40%|####      | 8/20 [00:15<00:25,  2.14s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:05,445]\u001b[0m Trial 50 finished with value: 1.8661988287526843 and parameters: {'lambda_l1': 1.0502005704198162e-08, 'lambda_l2': 5.962217656780601e-07}. Best is trial 45 with value: 1.8661988284169555.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  40%|####      | 8/20 [00:15<00:25,  2.14s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  40%|####      | 8/20 [00:17<00:25,  2.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  45%|####5     | 9/20 [00:17<00:24,  2.25s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:07,947]\u001b[0m Trial 51 finished with value: 1.86619882867381 and parameters: {'lambda_l1': 1.0073943068258621e-08, 'lambda_l2': 7.230136363884832e-07}. Best is trial 45 with value: 1.8661988284169555.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  45%|####5     | 9/20 [00:17<00:24,  2.25s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  45%|####5     | 9/20 [00:20<00:24,  2.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  50%|#####     | 10/20 [00:20<00:22,  2.26s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:10,224]\u001b[0m Trial 52 finished with value: 1.8661988281995834 and parameters: {'lambda_l1': 1.1187483352373526e-08, 'lambda_l2': 1.4173508559082996e-06}. Best is trial 52 with value: 1.8661988281995834.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  50%|#####     | 10/20 [00:20<00:22,  2.26s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  50%|#####     | 10/20 [00:22<00:22,  2.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  55%|#####5    | 11/20 [00:22<00:21,  2.36s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:12,836]\u001b[0m Trial 53 finished with value: 1.866198828044018 and parameters: {'lambda_l1': 1.3335641073332737e-08, 'lambda_l2': 1.6056428263839588e-06}. Best is trial 53 with value: 1.866198828044018.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  55%|#####5    | 11/20 [00:22<00:21,  2.36s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  55%|#####5    | 11/20 [00:24<00:21,  2.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  60%|######    | 12/20 [00:24<00:18,  2.36s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:15,182]\u001b[0m Trial 54 finished with value: 1.8661988279407649 and parameters: {'lambda_l1': 1.0978271756983764e-08, 'lambda_l2': 1.7361084921737293e-06}. Best is trial 54 with value: 1.8661988279407649.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  60%|######    | 12/20 [00:24<00:18,  2.36s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  60%|######    | 12/20 [00:27<00:18,  2.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  65%|######5   | 13/20 [00:27<00:17,  2.51s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:18,059]\u001b[0m Trial 55 finished with value: 1.866198823080275 and parameters: {'lambda_l1': 3.2384217502899125e-08, 'lambda_l2': 8.801274571787669e-06}. Best is trial 55 with value: 1.866198823080275.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  65%|######5   | 13/20 [00:27<00:17,  2.51s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  65%|######5   | 13/20 [00:30<00:17,  2.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  70%|#######   | 14/20 [00:30<00:14,  2.43s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:20,290]\u001b[0m Trial 56 finished with value: 1.8661988030144199 and parameters: {'lambda_l1': 3.352737336654252e-07, 'lambda_l2': 3.736720106814793e-05}. Best is trial 56 with value: 1.8661988030144199.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  70%|#######   | 14/20 [00:30<00:14,  2.43s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  70%|#######   | 14/20 [00:31<00:14,  2.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  75%|#######5  | 15/20 [00:31<00:09,  1.99s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:21,260]\u001b[0m Trial 57 finished with value: 1.8661987898918428 and parameters: {'lambda_l1': 9.296368740743422e-07, 'lambda_l2': 5.580924661160061e-05}. Best is trial 57 with value: 1.8661987898918428.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  75%|#######5  | 15/20 [00:31<00:09,  1.99s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  75%|#######5  | 15/20 [00:32<00:09,  1.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  80%|########  | 16/20 [00:32<00:07,  1.75s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:22,448]\u001b[0m Trial 58 finished with value: 1.8661986550433038 and parameters: {'lambda_l1': 1.259301694292148e-06, 'lambda_l2': 0.0002481533681107543}. Best is trial 58 with value: 1.8661986550433038.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  80%|########  | 16/20 [00:32<00:07,  1.75s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  80%|########  | 16/20 [00:33<00:07,  1.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  85%|########5 | 17/20 [00:33<00:04,  1.64s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:23,820]\u001b[0m Trial 59 finished with value: 1.8661986768394985 and parameters: {'lambda_l1': 2.9212882721719575e-06, 'lambda_l2': 0.00021651351035680547}. Best is trial 58 with value: 1.8661986550433038.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  85%|########5 | 17/20 [00:33<00:04,  1.64s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  85%|########5 | 17/20 [00:36<00:04,  1.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  90%|######### | 18/20 [00:36<00:04,  2.14s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:27,133]\u001b[0m Trial 60 finished with value: 1.8661986492473899 and parameters: {'lambda_l1': 2.0999070777658725e-06, 'lambda_l2': 0.0002563076210751466}. Best is trial 60 with value: 1.8661986492473899.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  90%|######### | 18/20 [00:36<00:04,  2.14s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  90%|######### | 18/20 [00:37<00:04,  2.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  95%|#########5| 19/20 [00:37<00:01,  1.78s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:28,071]\u001b[0m Trial 61 finished with value: 1.866198667196235 and parameters: {'lambda_l1': 2.9300372067293644e-06, 'lambda_l2': 0.00023036832325259882}. Best is trial 60 with value: 1.8661986492473899.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  95%|#########5| 19/20 [00:37<00:01,  1.78s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866199:  95%|#########5| 19/20 [00:41<00:01,  1.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866199: 100%|##########| 20/20 [00:41<00:00,  2.19s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:31,226]\u001b[0m Trial 62 finished with value: 1.8661986423217796 and parameters: {'lambda_l1': 2.0870873589111648e-06, 'lambda_l2': 0.0002660604554949879}. Best is trial 62 with value: 1.8661986423217796.\u001b[0m\n",
      "regularization_factors, val_score: 1.866199: 100%|##########| 20/20 [00:41<00:00,  2.05s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.866199:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.859805:   0%|          | 0/5 [00:03<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.859805:  20%|##        | 1/5 [00:03<00:14,  3.61s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:34,849]\u001b[0m Trial 63 finished with value: 1.859805438810019 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 1.859805438810019.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.859805:  20%|##        | 1/5 [00:03<00:14,  3.61s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.859805:  20%|##        | 1/5 [00:06<00:14,  3.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.859805:  40%|####      | 2/5 [00:06<00:10,  3.52s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:38,178]\u001b[0m Trial 64 finished with value: 1.872222589874986 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 1.859805438810019.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.859805:  40%|####      | 2/5 [00:06<00:10,  3.52s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.859805:  40%|####      | 2/5 [00:09<00:10,  3.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.859805:  60%|######    | 3/5 [00:09<00:06,  3.13s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:40,392]\u001b[0m Trial 65 finished with value: 1.8926821819062176 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 1.859805438810019.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.859805:  60%|######    | 3/5 [00:09<00:06,  3.13s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.859805:  60%|######    | 3/5 [00:10<00:06,  3.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.859805:  80%|########  | 4/5 [00:10<00:02,  2.47s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:41,318]\u001b[0m Trial 66 finished with value: 1.8799042243994761 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 1.859805438810019.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.859805:  80%|########  | 4/5 [00:10<00:02,  2.47s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.859805:  80%|########  | 4/5 [00:11<00:02,  2.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.859805: 100%|##########| 5/5 [00:11<00:00,  2.11s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:42,597]\u001b[0m Trial 67 finished with value: 1.887641045282316 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 1.859805438810019.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.859805: 100%|##########| 5/5 [00:11<00:00,  2.27s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category2</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_&lt;h1&gt;</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_&lt;/i&gt;</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category1+category2</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country+category1</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_17_y</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_18_y</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_19_y</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_23_y</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_24_y</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importance\n",
       "category2                   108\n",
       "number_of_<h1>                4\n",
       "number_of_</i>                4\n",
       "category1+category2          51\n",
       "country+category1            20\n",
       "...                         ...\n",
       "wordvec_17_y                 15\n",
       "wordvec_18_y                 14\n",
       "wordvec_19_y                 14\n",
       "wordvec_23_y                 10\n",
       "wordvec_24_y                 13\n",
       "\n",
       "[148 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-27 00:16:42,629]\u001b[0m A new study created in memory with name: no-name-ae786fe3-2e7a-4f63-bbdf-96034204a076\u001b[0m\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.881211:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.881211:  14%|#4        | 1/7 [00:00<00:02,  2.03it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:43,126]\u001b[0m Trial 0 finished with value: 1.88121106614205 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 1.88121106614205.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.881211:  14%|#4        | 1/7 [00:00<00:02,  2.03it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.881211:  14%|#4        | 1/7 [00:03<00:02,  2.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.881211:  29%|##8       | 2/7 [00:03<00:05,  1.16s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:45,859]\u001b[0m Trial 1 finished with value: 1.8892872523014648 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 1.88121106614205.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.881211:  29%|##8       | 2/7 [00:03<00:05,  1.16s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.881211:  29%|##8       | 2/7 [00:03<00:05,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.881211:  43%|####2     | 3/7 [00:03<00:04,  1.02s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:46,529]\u001b[0m Trial 2 finished with value: 1.882403311826488 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 1.88121106614205.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.881211:  43%|####2     | 3/7 [00:03<00:04,  1.02s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.881211:  43%|####2     | 3/7 [00:04<00:04,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.881211:  57%|#####7    | 4/7 [00:04<00:02,  1.19it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:46,964]\u001b[0m Trial 3 finished with value: 1.8904261369826816 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 1.88121106614205.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.881211:  57%|#####7    | 4/7 [00:04<00:02,  1.19it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.879781:  57%|#####7    | 4/7 [00:04<00:02,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.879781:  71%|#######1  | 5/7 [00:04<00:01,  1.40it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:47,373]\u001b[0m Trial 4 finished with value: 1.8797805210098522 and parameters: {'feature_fraction': 0.5}. Best is trial 4 with value: 1.8797805210098522.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.879781:  71%|#######1  | 5/7 [00:04<00:01,  1.40it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.879781:  71%|#######1  | 5/7 [00:05<00:01,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.879781:  86%|########5 | 6/7 [00:05<00:00,  1.46it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:47,996]\u001b[0m Trial 5 finished with value: 1.8911813269436173 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 4 with value: 1.8797805210098522.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.879781:  86%|########5 | 6/7 [00:05<00:00,  1.46it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.878645:  86%|########5 | 6/7 [00:07<00:00,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.878645: 100%|##########| 7/7 [00:07<00:00,  1.01it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:49,682]\u001b[0m Trial 6 finished with value: 1.8786445201912902 and parameters: {'feature_fraction': 0.8}. Best is trial 6 with value: 1.8786445201912902.\u001b[0m\n",
      "feature_fraction, val_score: 1.878645: 100%|##########| 7/7 [00:07<00:00,  1.01s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:   0%|          | 0/20 [00:02<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:   5%|5         | 1/20 [00:02<00:45,  2.38s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:52,069]\u001b[0m Trial 7 finished with value: 1.8881006331783026 and parameters: {'num_leaves': 53}. Best is trial 7 with value: 1.8881006331783026.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:   5%|5         | 1/20 [00:02<00:45,  2.38s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:   5%|5         | 1/20 [00:04<00:45,  2.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  10%|#         | 2/20 [00:04<00:39,  2.18s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:53,775]\u001b[0m Trial 8 finished with value: 1.87864452019129 and parameters: {'num_leaves': 31}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  10%|#         | 2/20 [00:04<00:39,  2.18s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  10%|#         | 2/20 [00:07<00:39,  2.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  15%|#5        | 3/20 [00:07<00:44,  2.63s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:16:57,448]\u001b[0m Trial 9 finished with value: 1.8921154025767402 and parameters: {'num_leaves': 73}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  15%|#5        | 3/20 [00:07<00:44,  2.63s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  15%|#5        | 3/20 [00:13<00:44,  2.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  20%|##        | 4/20 [00:13<00:59,  3.71s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:03,672]\u001b[0m Trial 10 finished with value: 1.8935547594444755 and parameters: {'num_leaves': 239}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  20%|##        | 4/20 [00:13<00:59,  3.71s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  20%|##        | 4/20 [00:14<00:59,  3.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  25%|##5       | 5/20 [00:14<00:40,  2.68s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:03,974]\u001b[0m Trial 11 finished with value: 1.8919991816135338 and parameters: {'num_leaves': 6}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  25%|##5       | 5/20 [00:14<00:40,  2.68s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  25%|##5       | 5/20 [00:16<00:40,  2.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  30%|###       | 6/20 [00:16<00:33,  2.42s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:05,791]\u001b[0m Trial 12 finished with value: 1.9146946855695615 and parameters: {'num_leaves': 174}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  30%|###       | 6/20 [00:16<00:33,  2.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  30%|###       | 6/20 [00:16<00:33,  2.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  35%|###5      | 7/20 [00:16<00:23,  1.78s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:06,067]\u001b[0m Trial 13 finished with value: 1.8888126900102244 and parameters: {'num_leaves': 11}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 1.878645:  35%|###5      | 7/20 [00:16<00:23,  1.78s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  35%|###5      | 7/20 [00:20<00:23,  1.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  40%|####      | 8/20 [00:20<00:28,  2.36s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:09,767]\u001b[0m Trial 14 finished with value: 1.8989782705688476 and parameters: {'num_leaves': 126}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  40%|####      | 8/20 [00:20<00:28,  2.36s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  40%|####      | 8/20 [00:21<00:28,  2.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  45%|####5     | 9/20 [00:21<00:21,  1.99s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:10,907]\u001b[0m Trial 15 finished with value: 1.8992943220299443 and parameters: {'num_leaves': 98}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  45%|####5     | 9/20 [00:21<00:21,  1.99s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  45%|####5     | 9/20 [00:28<00:21,  1.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  50%|#####     | 10/20 [00:28<00:36,  3.68s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:18,510]\u001b[0m Trial 16 finished with value: 1.8928386730629938 and parameters: {'num_leaves': 186}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  50%|#####     | 10/20 [00:28<00:36,  3.68s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  50%|#####     | 10/20 [00:30<00:36,  3.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  55%|#####5    | 11/20 [00:30<00:28,  3.12s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:20,344]\u001b[0m Trial 17 finished with value: 1.8920125114030972 and parameters: {'num_leaves': 40}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  55%|#####5    | 11/20 [00:30<00:28,  3.12s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  55%|#####5    | 11/20 [00:31<00:28,  3.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  60%|######    | 12/20 [00:31<00:19,  2.42s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:21,120]\u001b[0m Trial 18 finished with value: 1.9162128614281264 and parameters: {'num_leaves': 2}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  60%|######    | 12/20 [00:31<00:19,  2.42s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  60%|######    | 12/20 [00:37<00:19,  2.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  65%|######5   | 13/20 [00:37<00:23,  3.39s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:26,783]\u001b[0m Trial 19 finished with value: 1.896162988523475 and parameters: {'num_leaves': 161}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  65%|######5   | 13/20 [00:37<00:23,  3.39s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  65%|######5   | 13/20 [00:39<00:23,  3.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  70%|#######   | 14/20 [00:39<00:19,  3.20s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:29,519]\u001b[0m Trial 20 finished with value: 1.8856662583006656 and parameters: {'num_leaves': 244}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  70%|#######   | 14/20 [00:39<00:19,  3.20s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  70%|#######   | 14/20 [00:41<00:19,  3.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  75%|#######5  | 15/20 [00:41<00:13,  2.70s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:31,064]\u001b[0m Trial 21 finished with value: 1.8896883353181009 and parameters: {'num_leaves': 103}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  75%|#######5  | 15/20 [00:41<00:13,  2.70s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  75%|#######5  | 15/20 [00:42<00:13,  2.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  80%|########  | 16/20 [00:42<00:08,  2.08s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:31,696]\u001b[0m Trial 22 finished with value: 1.8801514528287246 and parameters: {'num_leaves': 39}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  80%|########  | 16/20 [00:42<00:08,  2.08s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  80%|########  | 16/20 [00:44<00:08,  2.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  85%|########5 | 17/20 [00:44<00:07,  2.35s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:34,674]\u001b[0m Trial 23 finished with value: 1.893568787235004 and parameters: {'num_leaves': 81}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  85%|########5 | 17/20 [00:44<00:07,  2.35s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  85%|########5 | 17/20 [00:47<00:07,  2.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  90%|######### | 18/20 [00:47<00:04,  2.30s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:36,855]\u001b[0m Trial 24 finished with value: 1.8939369268503925 and parameters: {'num_leaves': 205}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  90%|######### | 18/20 [00:47<00:04,  2.30s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  90%|######### | 18/20 [00:51<00:04,  2.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645:  95%|#########5| 19/20 [00:51<00:03,  3.06s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:41,687]\u001b[0m Trial 25 finished with value: 1.8903983242988422 and parameters: {'num_leaves': 136}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  95%|#########5| 19/20 [00:52<00:03,  3.06s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.878645:  95%|#########5| 19/20 [00:53<00:03,  3.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.878645: 100%|##########| 20/20 [00:53<00:00,  2.58s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:43,160]\u001b[0m Trial 26 finished with value: 1.8874836054292157 and parameters: {'num_leaves': 28}. Best is trial 8 with value: 1.87864452019129.\u001b[0m\n",
      "num_leaves, val_score: 1.878645: 100%|##########| 20/20 [00:53<00:00,  2.67s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.878645:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.878645:   0%|          | 0/10 [00:01<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.878645:  10%|#         | 1/10 [00:01<00:09,  1.11s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:44,280]\u001b[0m Trial 27 finished with value: 1.8983468335354636 and parameters: {'bagging_fraction': 0.6876651381065724, 'bagging_freq': 2}. Best is trial 27 with value: 1.8983468335354636.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  10%|#         | 1/10 [00:01<00:09,  1.11s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  10%|#         | 1/10 [00:02<00:09,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.878645:  20%|##        | 2/10 [00:02<00:08,  1.10s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:45,369]\u001b[0m Trial 28 finished with value: 1.9164810248779398 and parameters: {'bagging_fraction': 0.40352718704115476, 'bagging_freq': 7}. Best is trial 27 with value: 1.8983468335354636.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  20%|##        | 2/10 [00:02<00:08,  1.10s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  20%|##        | 2/10 [00:03<00:08,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.878645:  30%|###       | 3/10 [00:03<00:07,  1.14s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:46,582]\u001b[0m Trial 29 finished with value: 1.8963598133362305 and parameters: {'bagging_fraction': 0.9740663608944669, 'bagging_freq': 7}. Best is trial 29 with value: 1.8963598133362305.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  30%|###       | 3/10 [00:03<00:07,  1.14s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  30%|###       | 3/10 [00:04<00:07,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.878645:  40%|####      | 4/10 [00:04<00:07,  1.20s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:47,942]\u001b[0m Trial 30 finished with value: 1.913596359509842 and parameters: {'bagging_fraction': 0.403330156356484, 'bagging_freq': 1}. Best is trial 29 with value: 1.8963598133362305.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  40%|####      | 4/10 [00:04<00:07,  1.20s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  40%|####      | 4/10 [00:05<00:07,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.878645:  50%|#####     | 5/10 [00:05<00:05,  1.05s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:48,643]\u001b[0m Trial 31 finished with value: 1.8841886120868316 and parameters: {'bagging_fraction': 0.9960887792478093, 'bagging_freq': 4}. Best is trial 31 with value: 1.8841886120868316.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  50%|#####     | 5/10 [00:05<00:05,  1.05s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  50%|#####     | 5/10 [00:05<00:05,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.878645:  60%|######    | 6/10 [00:05<00:03,  1.12it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:49,159]\u001b[0m Trial 32 finished with value: 1.9046828360040864 and parameters: {'bagging_fraction': 0.6998577805596184, 'bagging_freq': 4}. Best is trial 31 with value: 1.8841886120868316.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  60%|######    | 6/10 [00:05<00:03,  1.12it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  60%|######    | 6/10 [00:06<00:03,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.878645:  70%|#######   | 7/10 [00:06<00:02,  1.28it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:49,684]\u001b[0m Trial 33 finished with value: 1.8883259268963062 and parameters: {'bagging_fraction': 0.8539814475875971, 'bagging_freq': 6}. Best is trial 31 with value: 1.8841886120868316.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  70%|#######   | 7/10 [00:06<00:02,  1.28it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  70%|#######   | 7/10 [00:06<00:02,  1.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.878645:  80%|########  | 8/10 [00:06<00:01,  1.47it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:50,121]\u001b[0m Trial 34 finished with value: 1.8988568741242187 and parameters: {'bagging_fraction': 0.5508419973913347, 'bagging_freq': 2}. Best is trial 31 with value: 1.8841886120868316.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  80%|########  | 8/10 [00:06<00:01,  1.47it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  80%|########  | 8/10 [00:07<00:01,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.878645:  90%|######### | 9/10 [00:07<00:00,  1.49it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:50,779]\u001b[0m Trial 35 finished with value: 1.8990967735742201 and parameters: {'bagging_fraction': 0.8602711140378124, 'bagging_freq': 5}. Best is trial 31 with value: 1.8841886120868316.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  90%|######### | 9/10 [00:07<00:00,  1.49it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.878645:  90%|######### | 9/10 [00:08<00:00,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.878645: 100%|##########| 10/10 [00:08<00:00,  1.58it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:51,323]\u001b[0m Trial 36 finished with value: 1.9082886682115907 and parameters: {'bagging_fraction': 0.5451493414347665, 'bagging_freq': 1}. Best is trial 31 with value: 1.8841886120868316.\u001b[0m\n",
      "bagging, val_score: 1.878645: 100%|##########| 10/10 [00:08<00:00,  1.23it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:   0%|          | 0/6 [00:02<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:  17%|#6        | 1/6 [00:02<00:13,  2.63s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:53,961]\u001b[0m Trial 37 finished with value: 1.880573410636945 and parameters: {'feature_fraction': 0.8160000000000001}. Best is trial 37 with value: 1.880573410636945.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:  17%|#6        | 1/6 [00:02<00:13,  2.63s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:  17%|#6        | 1/6 [00:03<00:13,  2.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:  33%|###3      | 2/6 [00:03<00:08,  2.00s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:54,494]\u001b[0m Trial 38 finished with value: 1.8902636368654846 and parameters: {'feature_fraction': 0.784}. Best is trial 37 with value: 1.880573410636945.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:  33%|###3      | 2/6 [00:03<00:08,  2.00s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:  33%|###3      | 2/6 [00:03<00:08,  2.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:  50%|#####     | 3/6 [00:03<00:04,  1.55s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:54,986]\u001b[0m Trial 39 finished with value: 1.889090223684712 and parameters: {'feature_fraction': 0.7520000000000001}. Best is trial 37 with value: 1.880573410636945.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:  50%|#####     | 3/6 [00:03<00:04,  1.55s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:  50%|#####     | 3/6 [00:04<00:04,  1.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:  67%|######6   | 4/6 [00:04<00:02,  1.23s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:55,482]\u001b[0m Trial 40 finished with value: 1.8914571190962781 and parameters: {'feature_fraction': 0.8480000000000001}. Best is trial 37 with value: 1.880573410636945.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:  67%|######6   | 4/6 [00:04<00:02,  1.23s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:  67%|######6   | 4/6 [00:04<00:02,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:  83%|########3 | 5/6 [00:04<00:01,  1.02s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:56,008]\u001b[0m Trial 41 finished with value: 1.884033288434772 and parameters: {'feature_fraction': 0.7200000000000001}. Best is trial 37 with value: 1.880573410636945.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:  83%|########3 | 5/6 [00:04<00:01,  1.02s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645:  83%|########3 | 5/6 [00:06<00:01,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.878645: 100%|##########| 6/6 [00:06<00:00,  1.16s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:57,486]\u001b[0m Trial 42 finished with value: 1.893386662108822 and parameters: {'feature_fraction': 0.88}. Best is trial 37 with value: 1.880573410636945.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.878645: 100%|##########| 6/6 [00:06<00:00,  1.03s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:   0%|          | 0/20 [00:01<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:   5%|5         | 1/20 [00:01<00:23,  1.25s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:58,740]\u001b[0m Trial 43 finished with value: 1.8940732825834639 and parameters: {'lambda_l1': 1.055186615567664, 'lambda_l2': 3.490037902964006e-05}. Best is trial 43 with value: 1.8940732825834639.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:   5%|5         | 1/20 [00:01<00:23,  1.25s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:   5%|5         | 1/20 [00:02<00:23,  1.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  10%|#         | 2/20 [00:02<00:22,  1.24s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:17:59,964]\u001b[0m Trial 44 finished with value: 1.8882740072221604 and parameters: {'lambda_l1': 2.4850050313583317e-08, 'lambda_l2': 9.254806861536222}. Best is trial 44 with value: 1.8882740072221604.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  10%|#         | 2/20 [00:02<00:22,  1.24s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  10%|#         | 2/20 [00:03<00:22,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  15%|#5        | 3/20 [00:03<00:20,  1.22s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:01,138]\u001b[0m Trial 45 finished with value: 1.8786445201816269 and parameters: {'lambda_l1': 1.6839494381664064e-08, 'lambda_l2': 4.5194919231654736e-08}. Best is trial 45 with value: 1.8786445201816269.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  15%|#5        | 3/20 [00:03<00:20,  1.22s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  15%|#5        | 3/20 [00:05<00:20,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  20%|##        | 4/20 [00:05<00:20,  1.30s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:02,607]\u001b[0m Trial 46 finished with value: 1.8786445201866637 and parameters: {'lambda_l1': 1.6142255219098937e-08, 'lambda_l2': 1.4300649884799128e-08}. Best is trial 45 with value: 1.8786445201816269.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  20%|##        | 4/20 [00:05<00:20,  1.30s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  20%|##        | 4/20 [00:07<00:20,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  25%|##5       | 5/20 [00:07<00:22,  1.48s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:04,527]\u001b[0m Trial 47 finished with value: 1.8786445201878323 and parameters: {'lambda_l1': 1.0213145299192452e-08, 'lambda_l2': 1.0812142262878258e-08}. Best is trial 45 with value: 1.8786445201816269.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  25%|##5       | 5/20 [00:07<00:22,  1.48s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  25%|##5       | 5/20 [00:09<00:22,  1.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  30%|###       | 6/20 [00:09<00:22,  1.64s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:06,522]\u001b[0m Trial 48 finished with value: 1.8786445201874005 and parameters: {'lambda_l1': 1.0458608202791996e-08, 'lambda_l2': 1.1771950275143954e-08}. Best is trial 45 with value: 1.8786445201816269.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  30%|###       | 6/20 [00:09<00:22,  1.64s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  30%|###       | 6/20 [00:10<00:22,  1.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  35%|###5      | 7/20 [00:10<00:19,  1.47s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:07,607]\u001b[0m Trial 49 finished with value: 1.8786445201873985 and parameters: {'lambda_l1': 1.0560061077302221e-08, 'lambda_l2': 1.1820706153329449e-08}. Best is trial 45 with value: 1.8786445201816269.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  35%|###5      | 7/20 [00:10<00:19,  1.47s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  35%|###5      | 7/20 [00:10<00:19,  1.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  40%|####      | 8/20 [00:10<00:14,  1.18s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:08,108]\u001b[0m Trial 50 finished with value: 1.8786445201872757 and parameters: {'lambda_l1': 1.2943825349184651e-08, 'lambda_l2': 1.0196504281504851e-08}. Best is trial 45 with value: 1.8786445201816269.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  40%|####      | 8/20 [00:10<00:14,  1.18s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  40%|####      | 8/20 [00:11<00:14,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  45%|####5     | 9/20 [00:11<00:10,  1.03it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:08,608]\u001b[0m Trial 51 finished with value: 1.8786445201866102 and parameters: {'lambda_l1': 1.1305627355868325e-08, 'lambda_l2': 1.598374119284067e-08}. Best is trial 45 with value: 1.8786445201816269.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  45%|####5     | 9/20 [00:11<00:10,  1.03it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  45%|####5     | 9/20 [00:11<00:10,  1.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  50%|#####     | 10/20 [00:11<00:08,  1.16it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:09,210]\u001b[0m Trial 52 finished with value: 1.8786445201870472 and parameters: {'lambda_l1': 1.2083294616551195e-08, 'lambda_l2': 1.1082303499011888e-08}. Best is trial 45 with value: 1.8786445201816269.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  50%|#####     | 10/20 [00:11<00:08,  1.16it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  50%|#####     | 10/20 [00:12<00:08,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  55%|#####5    | 11/20 [00:12<00:06,  1.33it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:09,702]\u001b[0m Trial 53 finished with value: 1.8786445201878745 and parameters: {'lambda_l1': 1.4445855943330924e-08, 'lambda_l2': 1.0392022137395522e-08}. Best is trial 45 with value: 1.8786445201816269.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  55%|#####5    | 11/20 [00:12<00:06,  1.33it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  55%|#####5    | 11/20 [00:12<00:06,  1.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  60%|######    | 12/20 [00:12<00:05,  1.48it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:10,202]\u001b[0m Trial 54 finished with value: 1.878644520187183 and parameters: {'lambda_l1': 1.3097286743992483e-08, 'lambda_l2': 1.3521159030977699e-08}. Best is trial 45 with value: 1.8786445201816269.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  60%|######    | 12/20 [00:12<00:05,  1.48it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  60%|######    | 12/20 [00:13<00:05,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  65%|######5   | 13/20 [00:13<00:05,  1.38it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:11,031]\u001b[0m Trial 55 finished with value: 1.8786445201862378 and parameters: {'lambda_l1': 1.2434613741851878e-07, 'lambda_l2': 2.430602566270497e-08}. Best is trial 45 with value: 1.8786445201816269.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  65%|######5   | 13/20 [00:13<00:05,  1.38it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  65%|######5   | 13/20 [00:15<00:05,  1.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  70%|#######   | 14/20 [00:15<00:07,  1.17s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:13,257]\u001b[0m Trial 56 finished with value: 1.8786445201461983 and parameters: {'lambda_l1': 1.4520204823714248e-06, 'lambda_l2': 4.0074044869868737e-07}. Best is trial 56 with value: 1.8786445201461983.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  70%|#######   | 14/20 [00:15<00:07,  1.17s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  70%|#######   | 14/20 [00:16<00:07,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  75%|#######5  | 15/20 [00:16<00:05,  1.03s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:13,961]\u001b[0m Trial 57 finished with value: 1.8786445200739168 and parameters: {'lambda_l1': 2.6063115625554204e-06, 'lambda_l2': 1.1695262870477449e-06}. Best is trial 57 with value: 1.8786445200739168.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  75%|#######5  | 15/20 [00:16<00:05,  1.03s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  75%|#######5  | 15/20 [00:17<00:05,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  80%|########  | 16/20 [00:17<00:03,  1.12it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:14,517]\u001b[0m Trial 58 finished with value: 1.8786445200186106 and parameters: {'lambda_l1': 1.3286556830692963e-06, 'lambda_l2': 1.64281088221712e-06}. Best is trial 58 with value: 1.8786445200186106.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  80%|########  | 16/20 [00:17<00:03,  1.12it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  80%|########  | 16/20 [00:17<00:03,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  85%|########5 | 17/20 [00:17<00:02,  1.29it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:15,017]\u001b[0m Trial 59 finished with value: 1.8786445200054251 and parameters: {'lambda_l1': 3.181569491228002e-06, 'lambda_l2': 2.0015435383943302e-06}. Best is trial 59 with value: 1.8786445200054251.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  85%|########5 | 17/20 [00:17<00:02,  1.29it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  85%|########5 | 17/20 [00:19<00:02,  1.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  90%|######### | 18/20 [00:19<00:02,  1.02s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:16,602]\u001b[0m Trial 60 finished with value: 1.8786445199080204 and parameters: {'lambda_l1': 4.380514414886285e-06, 'lambda_l2': 2.6247333391911702e-06}. Best is trial 60 with value: 1.8786445199080204.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  90%|######### | 18/20 [00:19<00:02,  1.02s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  90%|######### | 18/20 [00:20<00:02,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  95%|#########5| 19/20 [00:20<00:00,  1.01it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:17,531]\u001b[0m Trial 61 finished with value: 1.8786445198924993 and parameters: {'lambda_l1': 2.5804292137444745e-06, 'lambda_l2': 2.7723931790040237e-06}. Best is trial 61 with value: 1.8786445198924993.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  95%|#########5| 19/20 [00:20<00:00,  1.01it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.878645:  95%|#########5| 19/20 [00:21<00:00,  1.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.878645: 100%|##########| 20/20 [00:21<00:00,  1.01it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:18,522]\u001b[0m Trial 62 finished with value: 1.8786445199838935 and parameters: {'lambda_l1': 4.128790542998656e-06, 'lambda_l2': 1.8771012180010528e-06}. Best is trial 61 with value: 1.8786445198924993.\u001b[0m\n",
      "regularization_factors, val_score: 1.878645: 100%|##########| 20/20 [00:21<00:00,  1.05s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.878645:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.878645:   0%|          | 0/5 [00:01<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.878645:  20%|##        | 1/5 [00:01<00:04,  1.02s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:19,550]\u001b[0m Trial 63 finished with value: 1.890831241311922 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 1.890831241311922.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.878645:  20%|##        | 1/5 [00:01<00:04,  1.02s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.878645:  20%|##        | 1/5 [00:02<00:04,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.878645:  40%|####      | 2/5 [00:02<00:03,  1.06s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:20,709]\u001b[0m Trial 64 finished with value: 1.8847362341328764 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 1.8847362341328764.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.878645:  40%|####      | 2/5 [00:02<00:03,  1.06s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.878645:  40%|####      | 2/5 [00:03<00:03,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.878645:  60%|######    | 3/5 [00:03<00:02,  1.10s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:21,909]\u001b[0m Trial 65 finished with value: 1.896389632099392 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 1.8847362341328764.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.878645:  60%|######    | 3/5 [00:03<00:02,  1.10s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.878645:  60%|######    | 3/5 [00:04<00:02,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.878645:  80%|########  | 4/5 [00:04<00:01,  1.24s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:23,455]\u001b[0m Trial 66 finished with value: 1.889461653583555 and parameters: {'min_child_samples': 50}. Best is trial 64 with value: 1.8847362341328764.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.878645:  80%|########  | 4/5 [00:04<00:01,  1.24s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34662\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.878645:  80%|########  | 4/5 [00:06<00:01,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.878645: 100%|##########| 5/5 [00:06<00:00,  1.22s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:24,645]\u001b[0m Trial 67 finished with value: 1.8941584378323526 and parameters: {'min_child_samples': 10}. Best is trial 64 with value: 1.8847362341328764.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.878645: 100%|##########| 5/5 [00:06<00:00,  1.22s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category2</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_&lt;h1&gt;</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_&lt;/i&gt;</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category1+category2</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country+category1</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_17_y</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_18_y</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_19_y</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_23_y</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_24_y</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importance\n",
       "category2                    54\n",
       "number_of_<h1>                2\n",
       "number_of_</i>                1\n",
       "category1+category2          36\n",
       "country+category1             9\n",
       "...                         ...\n",
       "wordvec_17_y                  2\n",
       "wordvec_18_y                  2\n",
       "wordvec_19_y                  6\n",
       "wordvec_23_y                  4\n",
       "wordvec_24_y                  3\n",
       "\n",
       "[148 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-27 00:18:24,689]\u001b[0m A new study created in memory with name: no-name-e8e8de11-9a3b-4fe8-a7f2-b82c73b50bd4\u001b[0m\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.877643:   0%|          | 0/7 [00:01<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.877643:  14%|#4        | 1/7 [00:01<00:06,  1.08s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:25,786]\u001b[0m Trial 0 finished with value: 1.877642538720197 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 1.877642538720197.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.877643:  14%|#4        | 1/7 [00:01<00:06,  1.08s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.875602:  14%|#4        | 1/7 [00:02<00:06,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.875602:  29%|##8       | 2/7 [00:02<00:05,  1.14s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:27,068]\u001b[0m Trial 1 finished with value: 1.8756021176443485 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 1.8756021176443485.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.875602:  29%|##8       | 2/7 [00:02<00:05,  1.14s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.875602:  29%|##8       | 2/7 [00:04<00:05,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.875602:  43%|####2     | 3/7 [00:04<00:05,  1.29s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:28,727]\u001b[0m Trial 2 finished with value: 1.8777698398567808 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 1.8756021176443485.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.875602:  43%|####2     | 3/7 [00:04<00:05,  1.29s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.873365:  43%|####2     | 3/7 [00:05<00:05,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.873365:  57%|#####7    | 4/7 [00:05<00:04,  1.35s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:30,199]\u001b[0m Trial 3 finished with value: 1.8733647362812196 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 3 with value: 1.8733647362812196.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.873365:  57%|#####7    | 4/7 [00:05<00:04,  1.35s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.873365:  57%|#####7    | 4/7 [00:06<00:04,  1.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.873365:  71%|#######1  | 5/7 [00:06<00:02,  1.34s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:31,507]\u001b[0m Trial 4 finished with value: 1.8746886956771214 and parameters: {'feature_fraction': 0.5}. Best is trial 3 with value: 1.8733647362812196.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.873365:  71%|#######1  | 5/7 [00:06<00:02,  1.34s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.873365:  71%|#######1  | 5/7 [00:07<00:02,  1.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.873365:  86%|########5 | 6/7 [00:07<00:01,  1.07s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:31,950]\u001b[0m Trial 5 finished with value: 1.8762774361387056 and parameters: {'feature_fraction': 0.6}. Best is trial 3 with value: 1.8733647362812196.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.873365:  86%|########5 | 6/7 [00:07<00:01,  1.07s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.873365:  86%|########5 | 6/7 [00:07<00:01,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.873365: 100%|##########| 7/7 [00:07<00:00,  1.09it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:32,521]\u001b[0m Trial 6 finished with value: 1.876082306511443 and parameters: {'feature_fraction': 1.0}. Best is trial 3 with value: 1.8733647362812196.\u001b[0m\n",
      "feature_fraction, val_score: 1.873365: 100%|##########| 7/7 [00:07<00:00,  1.12s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.873365:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:   5%|5         | 1/20 [00:00<00:16,  1.14it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:33,407]\u001b[0m Trial 7 finished with value: 1.8728390811808475 and parameters: {'num_leaves': 56}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:   5%|5         | 1/20 [00:00<00:16,  1.14it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:   5%|5         | 1/20 [00:01<00:16,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  10%|#         | 2/20 [00:01<00:16,  1.06it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:34,502]\u001b[0m Trial 8 finished with value: 1.8778239531383385 and parameters: {'num_leaves': 81}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  10%|#         | 2/20 [00:01<00:16,  1.06it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  10%|#         | 2/20 [00:06<00:16,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  15%|#5        | 3/20 [00:06<00:34,  2.05s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:39,133]\u001b[0m Trial 9 finished with value: 1.8752343584986013 and parameters: {'num_leaves': 252}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  15%|#5        | 3/20 [00:06<00:34,  2.05s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  15%|#5        | 3/20 [00:07<00:34,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  20%|##        | 4/20 [00:07<00:29,  1.83s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:40,454]\u001b[0m Trial 10 finished with value: 1.88316708401888 and parameters: {'num_leaves': 13}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  20%|##        | 4/20 [00:07<00:29,  1.83s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  20%|##        | 4/20 [00:11<00:29,  1.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  25%|##5       | 5/20 [00:11<00:37,  2.47s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:44,406]\u001b[0m Trial 11 finished with value: 1.8788576567898811 and parameters: {'num_leaves': 124}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  25%|##5       | 5/20 [00:11<00:37,  2.47s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  25%|##5       | 5/20 [00:12<00:37,  2.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  30%|###       | 6/20 [00:12<00:28,  2.04s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:45,463]\u001b[0m Trial 12 finished with value: 1.8781212520573791 and parameters: {'num_leaves': 17}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  30%|###       | 6/20 [00:12<00:28,  2.04s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  30%|###       | 6/20 [00:19<00:28,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  35%|###5      | 7/20 [00:19<00:42,  3.25s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:51,542]\u001b[0m Trial 13 finished with value: 1.8919295295972793 and parameters: {'num_leaves': 253}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  35%|###5      | 7/20 [00:19<00:42,  3.25s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  35%|###5      | 7/20 [00:20<00:42,  3.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  40%|####      | 8/20 [00:20<00:31,  2.63s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:52,723]\u001b[0m Trial 14 finished with value: 1.8849245360001654 and parameters: {'num_leaves': 72}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  40%|####      | 8/20 [00:20<00:31,  2.63s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  40%|####      | 8/20 [00:21<00:31,  2.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  45%|####5     | 9/20 [00:21<00:25,  2.35s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:54,412]\u001b[0m Trial 15 finished with value: 1.8767092720530538 and parameters: {'num_leaves': 184}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  45%|####5     | 9/20 [00:21<00:25,  2.35s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  45%|####5     | 9/20 [00:22<00:25,  2.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  50%|#####     | 10/20 [00:22<00:19,  1.95s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:55,428]\u001b[0m Trial 16 finished with value: 1.8815415256683758 and parameters: {'num_leaves': 58}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  50%|#####     | 10/20 [00:22<00:19,  1.95s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  50%|#####     | 10/20 [00:27<00:19,  1.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  55%|#####5    | 11/20 [00:27<00:23,  2.63s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:18:59,656]\u001b[0m Trial 17 finished with value: 1.8767315469478043 and parameters: {'num_leaves': 168}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  55%|#####5    | 11/20 [00:27<00:23,  2.63s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  55%|#####5    | 11/20 [00:31<00:23,  2.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  60%|######    | 12/20 [00:31<00:24,  3.05s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:03,673]\u001b[0m Trial 18 finished with value: 1.884372936118903 and parameters: {'num_leaves': 119}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  60%|######    | 12/20 [00:31<00:24,  3.05s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  60%|######    | 12/20 [00:32<00:24,  3.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  65%|######5   | 13/20 [00:32<00:18,  2.60s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:05,229]\u001b[0m Trial 19 finished with value: 1.8765164475551084 and parameters: {'num_leaves': 37}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  65%|######5   | 13/20 [00:32<00:18,  2.60s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  65%|######5   | 13/20 [00:37<00:18,  2.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  70%|#######   | 14/20 [00:37<00:19,  3.23s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:09,923]\u001b[0m Trial 20 finished with value: 1.8757588435432782 and parameters: {'num_leaves': 189}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  70%|#######   | 14/20 [00:37<00:19,  3.23s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  70%|#######   | 14/20 [00:39<00:19,  3.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  75%|#######5  | 15/20 [00:39<00:14,  2.99s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:12,349]\u001b[0m Trial 21 finished with value: 1.8770725242324624 and parameters: {'num_leaves': 99}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  75%|#######5  | 15/20 [00:39<00:14,  2.99s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  75%|#######5  | 15/20 [00:41<00:14,  2.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  80%|########  | 16/20 [00:41<00:10,  2.64s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:14,188]\u001b[0m Trial 22 finished with value: 1.880824091139023 and parameters: {'num_leaves': 151}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  80%|########  | 16/20 [00:41<00:10,  2.64s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  80%|########  | 16/20 [00:48<00:10,  2.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  85%|########5 | 17/20 [00:48<00:11,  3.95s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:21,179]\u001b[0m Trial 23 finished with value: 1.8871685213599572 and parameters: {'num_leaves': 221}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  85%|########5 | 17/20 [00:48<00:11,  3.95s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  85%|########5 | 17/20 [00:50<00:11,  3.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  90%|######### | 18/20 [00:50<00:06,  3.28s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:22,895]\u001b[0m Trial 24 finished with value: 1.8774885576050337 and parameters: {'num_leaves': 48}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  90%|######### | 18/20 [00:50<00:06,  3.28s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  90%|######### | 18/20 [00:51<00:06,  3.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.872839:  95%|#########5| 19/20 [00:51<00:02,  2.50s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:23,567]\u001b[0m Trial 25 finished with value: 1.8990437197713295 and parameters: {'num_leaves': 4}. Best is trial 7 with value: 1.8728390811808475.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.872839:  95%|#########5| 19/20 [00:51<00:02,  2.50s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.866317:  95%|#########5| 19/20 [00:54<00:02,  2.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.866317: 100%|##########| 20/20 [00:54<00:00,  2.75s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:26,912]\u001b[0m Trial 26 finished with value: 1.86631735533685 and parameters: {'num_leaves': 103}. Best is trial 26 with value: 1.86631735533685.\u001b[0m\n",
      "num_leaves, val_score: 1.866317: 100%|##########| 20/20 [00:54<00:00,  2.72s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866317:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866317:   0%|          | 0/10 [00:02<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866317:  10%|#         | 1/10 [00:02<00:25,  2.85s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:29,763]\u001b[0m Trial 27 finished with value: 1.9026072296269183 and parameters: {'bagging_fraction': 0.7942904203897649, 'bagging_freq': 2}. Best is trial 27 with value: 1.9026072296269183.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  10%|#         | 1/10 [00:02<00:25,  2.85s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  10%|#         | 1/10 [00:05<00:25,  2.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866317:  20%|##        | 2/10 [00:05<00:22,  2.82s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:32,521]\u001b[0m Trial 28 finished with value: 1.9178503978756272 and parameters: {'bagging_fraction': 0.43927811616625884, 'bagging_freq': 7}. Best is trial 27 with value: 1.9026072296269183.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  20%|##        | 2/10 [00:05<00:22,  2.82s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  20%|##        | 2/10 [00:08<00:22,  2.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866317:  30%|###       | 3/10 [00:08<00:20,  2.95s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:35,767]\u001b[0m Trial 29 finished with value: 1.8779050092078986 and parameters: {'bagging_fraction': 0.967327807861999, 'bagging_freq': 7}. Best is trial 29 with value: 1.8779050092078986.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  30%|###       | 3/10 [00:08<00:20,  2.95s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  30%|###       | 3/10 [00:09<00:20,  2.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866317:  40%|####      | 4/10 [00:09<00:13,  2.33s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:36,667]\u001b[0m Trial 30 finished with value: 1.9036128525808091 and parameters: {'bagging_fraction': 0.4498516648837888, 'bagging_freq': 1}. Best is trial 29 with value: 1.8779050092078986.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  40%|####      | 4/10 [00:09<00:13,  2.33s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  40%|####      | 4/10 [00:10<00:13,  2.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866317:  50%|#####     | 5/10 [00:10<00:09,  1.98s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:37,834]\u001b[0m Trial 31 finished with value: 1.8870803654486827 and parameters: {'bagging_fraction': 0.65253314502093, 'bagging_freq': 4}. Best is trial 29 with value: 1.8779050092078986.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  50%|#####     | 5/10 [00:10<00:09,  1.98s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  50%|#####     | 5/10 [00:14<00:09,  1.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866317:  60%|######    | 6/10 [00:14<00:10,  2.51s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:41,576]\u001b[0m Trial 32 finished with value: 1.8892295043163814 and parameters: {'bagging_fraction': 0.995623623736215, 'bagging_freq': 4}. Best is trial 29 with value: 1.8779050092078986.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  60%|######    | 6/10 [00:14<00:10,  2.51s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  60%|######    | 6/10 [00:15<00:10,  2.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866317:  70%|#######   | 7/10 [00:15<00:06,  2.15s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:42,869]\u001b[0m Trial 33 finished with value: 1.9138142517281282 and parameters: {'bagging_fraction': 0.6446052561352884, 'bagging_freq': 6}. Best is trial 29 with value: 1.8779050092078986.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  70%|#######   | 7/10 [00:15<00:06,  2.15s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  70%|#######   | 7/10 [00:18<00:06,  2.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866317:  80%|########  | 8/10 [00:18<00:04,  2.24s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:45,318]\u001b[0m Trial 34 finished with value: 1.885720662865877 and parameters: {'bagging_fraction': 0.8320360877661532, 'bagging_freq': 2}. Best is trial 29 with value: 1.8779050092078986.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  80%|########  | 8/10 [00:18<00:04,  2.24s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  80%|########  | 8/10 [00:22<00:04,  2.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866317:  90%|######### | 9/10 [00:22<00:02,  2.79s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:49,412]\u001b[0m Trial 35 finished with value: 1.9124213031014377 and parameters: {'bagging_fraction': 0.5263079332635419, 'bagging_freq': 5}. Best is trial 29 with value: 1.8779050092078986.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  90%|######### | 9/10 [00:22<00:02,  2.79s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.866317:  90%|######### | 9/10 [00:26<00:02,  2.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.866317: 100%|##########| 10/10 [00:26<00:00,  3.15s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:53,378]\u001b[0m Trial 36 finished with value: 1.8848581436092553 and parameters: {'bagging_fraction': 0.8797429707635765, 'bagging_freq': 1}. Best is trial 29 with value: 1.8779050092078986.\u001b[0m\n",
      "bagging, val_score: 1.866317: 100%|##########| 10/10 [00:26<00:00,  2.65s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:   0%|          | 0/6 [00:03<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:  17%|#6        | 1/6 [00:03<00:18,  3.62s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:57,007]\u001b[0m Trial 37 finished with value: 1.8746571940930021 and parameters: {'feature_fraction': 0.8839999999999999}. Best is trial 37 with value: 1.8746571940930021.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:  17%|#6        | 1/6 [00:03<00:18,  3.62s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:  17%|#6        | 1/6 [00:06<00:18,  3.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:  33%|###3      | 2/6 [00:06<00:13,  3.36s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:19:59,764]\u001b[0m Trial 38 finished with value: 1.872295493194465 and parameters: {'feature_fraction': 0.852}. Best is trial 38 with value: 1.872295493194465.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:  33%|###3      | 2/6 [00:06<00:13,  3.36s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:  33%|###3      | 2/6 [00:07<00:13,  3.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:  50%|#####     | 3/6 [00:07<00:08,  2.74s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:01,048]\u001b[0m Trial 39 finished with value: 1.8854297658079482 and parameters: {'feature_fraction': 0.9159999999999999}. Best is trial 38 with value: 1.872295493194465.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:  50%|#####     | 3/6 [00:07<00:08,  2.74s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:  50%|#####     | 3/6 [00:08<00:08,  2.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:  67%|######6   | 4/6 [00:08<00:04,  2.28s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:02,271]\u001b[0m Trial 40 finished with value: 1.8701387163030072 and parameters: {'feature_fraction': 0.82}. Best is trial 40 with value: 1.8701387163030072.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:  67%|######6   | 4/6 [00:08<00:04,  2.28s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:  67%|######6   | 4/6 [00:12<00:04,  2.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:  83%|########3 | 5/6 [00:12<00:02,  2.59s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:05,588]\u001b[0m Trial 41 finished with value: 1.8783465784983877 and parameters: {'feature_fraction': 0.9799999999999999}. Best is trial 40 with value: 1.8701387163030072.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:  83%|########3 | 5/6 [00:12<00:02,  2.59s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317:  83%|########3 | 5/6 [00:13<00:02,  2.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.866317: 100%|##########| 6/6 [00:13<00:00,  2.24s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:07,003]\u001b[0m Trial 42 finished with value: 1.8679174963593481 and parameters: {'feature_fraction': 0.948}. Best is trial 42 with value: 1.8679174963593481.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.866317: 100%|##########| 6/6 [00:13<00:00,  2.27s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:   0%|          | 0/20 [00:06<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:   5%|5         | 1/20 [00:06<02:02,  6.46s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:13,467]\u001b[0m Trial 43 finished with value: 1.8773809308059175 and parameters: {'lambda_l1': 0.05031385458406239, 'lambda_l2': 0.263201071820749}. Best is trial 43 with value: 1.8773809308059175.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:   5%|5         | 1/20 [00:06<02:02,  6.46s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:   5%|5         | 1/20 [00:10<02:02,  6.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  10%|#         | 2/20 [00:10<01:41,  5.66s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:17,283]\u001b[0m Trial 44 finished with value: 1.8663173553156447 and parameters: {'lambda_l1': 1.0140665397945793e-08, 'lambda_l2': 1.1960095538606013e-08}. Best is trial 44 with value: 1.8663173553156447.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  10%|#         | 2/20 [00:10<01:41,  5.66s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  10%|#         | 2/20 [00:13<01:41,  5.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  15%|#5        | 3/20 [00:13<01:23,  4.88s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:20,343]\u001b[0m Trial 45 finished with value: 1.866317355319441 and parameters: {'lambda_l1': 1.364471937978386e-08, 'lambda_l2': 1.2061670900224672e-08}. Best is trial 44 with value: 1.8663173553156447.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  15%|#5        | 3/20 [00:13<01:23,  4.88s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  15%|#5        | 3/20 [00:16<01:23,  4.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  20%|##        | 4/20 [00:16<01:10,  4.42s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:23,678]\u001b[0m Trial 46 finished with value: 1.866317355319332 and parameters: {'lambda_l1': 1.0845485437934934e-08, 'lambda_l2': 1.0304800659219916e-08}. Best is trial 44 with value: 1.8663173553156447.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  20%|##        | 4/20 [00:16<01:10,  4.42s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  20%|##        | 4/20 [00:19<01:10,  4.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  25%|##5       | 5/20 [00:19<00:57,  3.84s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:26,156]\u001b[0m Trial 47 finished with value: 1.8663173553124355 and parameters: {'lambda_l1': 1.2845430835287275e-08, 'lambda_l2': 1.0622883881280257e-08}. Best is trial 47 with value: 1.8663173553124355.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  25%|##5       | 5/20 [00:19<00:57,  3.84s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  25%|##5       | 5/20 [00:20<00:57,  3.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  30%|###       | 6/20 [00:20<00:43,  3.11s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:27,554]\u001b[0m Trial 48 finished with value: 1.8663173553156291 and parameters: {'lambda_l1': 1.0478070069262131e-08, 'lambda_l2': 1.1749241382363814e-08}. Best is trial 47 with value: 1.8663173553124355.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  30%|###       | 6/20 [00:20<00:43,  3.11s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  30%|###       | 6/20 [00:21<00:43,  3.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  35%|###5      | 7/20 [00:21<00:33,  2.60s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:28,962]\u001b[0m Trial 49 finished with value: 1.8663173553127794 and parameters: {'lambda_l1': 1.1741683540964894e-08, 'lambda_l2': 1.1079547823989287e-08}. Best is trial 47 with value: 1.8663173553124355.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  35%|###5      | 7/20 [00:21<00:33,  2.60s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  35%|###5      | 7/20 [00:25<00:33,  2.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  40%|####      | 8/20 [00:25<00:33,  2.79s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:32,208]\u001b[0m Trial 50 finished with value: 1.8663173553175298 and parameters: {'lambda_l1': 1.0184503777223437e-08, 'lambda_l2': 1.1588107488611371e-08}. Best is trial 47 with value: 1.8663173553124355.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  40%|####      | 8/20 [00:25<00:33,  2.79s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  40%|####      | 8/20 [00:26<00:33,  2.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  45%|####5     | 9/20 [00:26<00:26,  2.40s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:33,680]\u001b[0m Trial 51 finished with value: 1.866317355312481 and parameters: {'lambda_l1': 1.2838345936394443e-08, 'lambda_l2': 1.04806330177621e-08}. Best is trial 47 with value: 1.8663173553124355.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  45%|####5     | 9/20 [00:26<00:26,  2.40s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  45%|####5     | 9/20 [00:31<00:26,  2.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  50%|#####     | 10/20 [00:31<00:30,  3.02s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:38,167]\u001b[0m Trial 52 finished with value: 1.8663173553164376 and parameters: {'lambda_l1': 1.367781009793389e-08, 'lambda_l2': 1.1330870940264761e-08}. Best is trial 47 with value: 1.8663173553124355.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  50%|#####     | 10/20 [00:31<00:30,  3.02s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  50%|#####     | 10/20 [00:36<00:30,  3.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  55%|#####5    | 11/20 [00:36<00:32,  3.59s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:43,092]\u001b[0m Trial 53 finished with value: 1.8663173553114891 and parameters: {'lambda_l1': 1.375050002588712e-08, 'lambda_l2': 1.0549838584105748e-08}. Best is trial 53 with value: 1.8663173553114891.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  55%|#####5    | 11/20 [00:36<00:32,  3.59s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  55%|#####5    | 11/20 [00:40<00:32,  3.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  60%|######    | 12/20 [00:40<00:31,  3.88s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:47,633]\u001b[0m Trial 54 finished with value: 1.866317355312579 and parameters: {'lambda_l1': 1.138055442660426e-08, 'lambda_l2': 1.2010474479971405e-08}. Best is trial 53 with value: 1.8663173553114891.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  60%|######    | 12/20 [00:40<00:31,  3.88s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  60%|######    | 12/20 [00:42<00:31,  3.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  65%|######5   | 13/20 [00:42<00:23,  3.34s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:49,729]\u001b[0m Trial 55 finished with value: 1.8663173553053696 and parameters: {'lambda_l1': 5.334470821120136e-08, 'lambda_l2': 1.0175995791432818e-08}. Best is trial 55 with value: 1.8663173553053696.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  65%|######5   | 13/20 [00:42<00:23,  3.34s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  65%|######5   | 13/20 [00:43<00:23,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  70%|#######   | 14/20 [00:43<00:16,  2.72s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:50,990]\u001b[0m Trial 56 finished with value: 1.8663173536885962 and parameters: {'lambda_l1': 1.0904903681170722e-06, 'lambda_l2': 1.3422238801235337e-06}. Best is trial 56 with value: 1.8663173536885962.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  70%|#######   | 14/20 [00:43<00:16,  2.72s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  70%|#######   | 14/20 [00:47<00:16,  2.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  75%|#######5  | 15/20 [00:47<00:14,  2.89s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:54,296]\u001b[0m Trial 57 finished with value: 1.8663173516697036 and parameters: {'lambda_l1': 2.995034179686214e-06, 'lambda_l2': 2.965557432293175e-06}. Best is trial 57 with value: 1.8663173516697036.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  75%|#######5  | 15/20 [00:47<00:14,  2.89s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  75%|#######5  | 15/20 [00:48<00:14,  2.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  80%|########  | 16/20 [00:48<00:09,  2.40s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:55,538]\u001b[0m Trial 58 finished with value: 1.8663173435523928 and parameters: {'lambda_l1': 9.26376902652792e-06, 'lambda_l2': 9.84598138505586e-06}. Best is trial 58 with value: 1.8663173435523928.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  80%|########  | 16/20 [00:48<00:09,  2.40s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  80%|########  | 16/20 [00:51<00:09,  2.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  85%|########5 | 17/20 [00:51<00:07,  2.57s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:20:58,498]\u001b[0m Trial 59 finished with value: 1.8663173501139545 and parameters: {'lambda_l1': 3.593471520076697e-06, 'lambda_l2': 4.703256937346791e-06}. Best is trial 58 with value: 1.8663173435523928.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  85%|########5 | 17/20 [00:51<00:07,  2.57s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  85%|########5 | 17/20 [00:55<00:07,  2.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  90%|######### | 18/20 [00:55<00:05,  2.86s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:02,030]\u001b[0m Trial 60 finished with value: 1.8663173503968116 and parameters: {'lambda_l1': 3.2489747944778147e-06, 'lambda_l2': 4.659010754583254e-06}. Best is trial 58 with value: 1.8663173435523928.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  90%|######### | 18/20 [00:55<00:05,  2.86s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  90%|######### | 18/20 [00:58<00:05,  2.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  95%|#########5| 19/20 [00:58<00:03,  3.10s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:05,701]\u001b[0m Trial 61 finished with value: 1.8663173491749263 and parameters: {'lambda_l1': 5.251999272936871e-06, 'lambda_l2': 4.600247590850055e-06}. Best is trial 58 with value: 1.8663173435523928.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  95%|#########5| 19/20 [00:58<00:03,  3.10s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.866317:  95%|#########5| 19/20 [01:01<00:03,  3.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.866317: 100%|##########| 20/20 [01:01<00:00,  3.07s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:08,704]\u001b[0m Trial 62 finished with value: 1.8663173504285462 and parameters: {'lambda_l1': 3.1952132527758167e-06, 'lambda_l2': 4.660700081892872e-06}. Best is trial 58 with value: 1.8663173435523928.\u001b[0m\n",
      "regularization_factors, val_score: 1.866317: 100%|##########| 20/20 [01:01<00:00,  3.08s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.866317:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.866317:   0%|          | 0/5 [00:01<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.866317:  20%|##        | 1/5 [00:01<00:04,  1.00s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:09,716]\u001b[0m Trial 63 finished with value: 1.8836317623958123 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 1.8836317623958123.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.866317:  20%|##        | 1/5 [00:01<00:04,  1.00s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.866317:  20%|##        | 1/5 [00:01<00:04,  1.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.866317:  40%|####      | 2/5 [00:01<00:02,  1.09it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:10,425]\u001b[0m Trial 64 finished with value: 1.8764298865732534 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 1.8764298865732534.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.866317:  40%|####      | 2/5 [00:01<00:02,  1.09it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.866317:  40%|####      | 2/5 [00:03<00:02,  1.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.866317:  60%|######    | 3/5 [00:03<00:02,  1.08s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:11,879]\u001b[0m Trial 65 finished with value: 1.8960064245703077 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 1.8764298865732534.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.866317:  60%|######    | 3/5 [00:03<00:02,  1.08s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.866317:  60%|######    | 3/5 [00:06<00:02,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.866317:  80%|########  | 4/5 [00:06<00:01,  1.80s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:15,352]\u001b[0m Trial 66 finished with value: 1.881233145672376 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 1.8764298865732534.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.866317:  80%|########  | 4/5 [00:06<00:01,  1.80s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34668\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.257231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.866317:  80%|########  | 4/5 [00:09<00:01,  1.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.866317: 100%|##########| 5/5 [00:09<00:00,  2.07s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:18,076]\u001b[0m Trial 67 finished with value: 1.8716621306313972 and parameters: {'min_child_samples': 10}. Best is trial 67 with value: 1.8716621306313972.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.866317: 100%|##########| 5/5 [00:09<00:00,  1.87s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category2</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_&lt;h1&gt;</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_&lt;/i&gt;</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category1+category2</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country+category1</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_17_y</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_18_y</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_19_y</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_23_y</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_24_y</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importance\n",
       "category2                    58\n",
       "number_of_<h1>               12\n",
       "number_of_</i>                3\n",
       "category1+category2          42\n",
       "country+category1             8\n",
       "...                         ...\n",
       "wordvec_17_y                  9\n",
       "wordvec_18_y                 14\n",
       "wordvec_19_y                 12\n",
       "wordvec_23_y                 14\n",
       "wordvec_24_y                 18\n",
       "\n",
       "[148 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-27 00:21:18,128]\u001b[0m A new study created in memory with name: no-name-427e31e2-b203-466c-ac89-442982e24e31\u001b[0m\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.895513:   0%|          | 0/7 [00:01<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.895513:  14%|#4        | 1/7 [00:01<00:06,  1.08s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:19,221]\u001b[0m Trial 0 finished with value: 1.8955126533344786 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 1.8955126533344786.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.895513:  14%|#4        | 1/7 [00:01<00:06,  1.08s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.895513:  14%|#4        | 1/7 [00:02<00:06,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.895513:  29%|##8       | 2/7 [00:02<00:05,  1.14s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:20,510]\u001b[0m Trial 1 finished with value: 1.895632355770519 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 1.8955126533344786.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.895513:  29%|##8       | 2/7 [00:02<00:05,  1.14s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.895513:  29%|##8       | 2/7 [00:04<00:05,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.895513:  43%|####2     | 3/7 [00:04<00:05,  1.31s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:22,207]\u001b[0m Trial 2 finished with value: 1.9001680703127712 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 1.8955126533344786.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.895513:  43%|####2     | 3/7 [00:04<00:05,  1.31s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.887813:  43%|####2     | 3/7 [00:06<00:05,  1.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.887813:  57%|#####7    | 4/7 [00:06<00:04,  1.59s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:24,447]\u001b[0m Trial 3 finished with value: 1.8878134292020425 and parameters: {'feature_fraction': 0.7}. Best is trial 3 with value: 1.8878134292020425.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.887813:  57%|#####7    | 4/7 [00:06<00:04,  1.59s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.887813:  57%|#####7    | 4/7 [00:09<00:04,  1.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.887813:  71%|#######1  | 5/7 [00:09<00:03,  1.95s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:27,245]\u001b[0m Trial 4 finished with value: 1.894359006664112 and parameters: {'feature_fraction': 0.8}. Best is trial 3 with value: 1.8878134292020425.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.887813:  71%|#######1  | 5/7 [00:09<00:03,  1.95s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.887813:  71%|#######1  | 5/7 [00:10<00:03,  1.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.887813:  86%|########5 | 6/7 [00:10<00:01,  1.80s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:28,683]\u001b[0m Trial 5 finished with value: 1.9032263583156495 and parameters: {'feature_fraction': 0.6}. Best is trial 3 with value: 1.8878134292020425.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 1.887813:  86%|########5 | 6/7 [00:10<00:01,  1.80s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 1.887813:  86%|########5 | 6/7 [00:12<00:01,  1.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 1.887813: 100%|##########| 7/7 [00:12<00:00,  1.77s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:30,385]\u001b[0m Trial 6 finished with value: 1.8920716598572123 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 3 with value: 1.8878134292020425.\u001b[0m\n",
      "feature_fraction, val_score: 1.887813: 100%|##########| 7/7 [00:12<00:00,  1.75s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:   0%|          | 0/20 [00:06<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:   5%|5         | 1/20 [00:06<01:56,  6.11s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:36,504]\u001b[0m Trial 7 finished with value: 1.8987826386791293 and parameters: {'num_leaves': 153}. Best is trial 7 with value: 1.8987826386791293.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:   5%|5         | 1/20 [00:06<01:56,  6.11s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:   5%|5         | 1/20 [00:07<01:56,  6.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  10%|#         | 2/20 [00:07<01:25,  4.74s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:38,066]\u001b[0m Trial 8 finished with value: 1.906642090795282 and parameters: {'num_leaves': 122}. Best is trial 7 with value: 1.8987826386791293.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  10%|#         | 2/20 [00:07<01:25,  4.74s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  10%|#         | 2/20 [00:09<01:25,  4.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  15%|#5        | 3/20 [00:09<01:07,  3.97s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:40,222]\u001b[0m Trial 9 finished with value: 1.9133096856308873 and parameters: {'num_leaves': 113}. Best is trial 7 with value: 1.8987826386791293.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  15%|#5        | 3/20 [00:09<01:07,  3.97s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  15%|#5        | 3/20 [00:11<01:07,  3.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  20%|##        | 4/20 [00:11<00:54,  3.39s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:42,268]\u001b[0m Trial 10 finished with value: 1.9112163068497665 and parameters: {'num_leaves': 3}. Best is trial 7 with value: 1.8987826386791293.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  20%|##        | 4/20 [00:11<00:54,  3.39s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  20%|##        | 4/20 [00:13<00:54,  3.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  25%|##5       | 5/20 [00:13<00:43,  2.93s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:44,111]\u001b[0m Trial 11 finished with value: 1.9026422443021749 and parameters: {'num_leaves': 250}. Best is trial 7 with value: 1.8987826386791293.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  25%|##5       | 5/20 [00:13<00:43,  2.93s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  25%|##5       | 5/20 [00:14<00:43,  2.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  30%|###       | 6/20 [00:14<00:30,  2.15s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:44,465]\u001b[0m Trial 12 finished with value: 1.9006829881403944 and parameters: {'num_leaves': 12}. Best is trial 7 with value: 1.8987826386791293.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  30%|###       | 6/20 [00:14<00:30,  2.15s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  30%|###       | 6/20 [00:22<00:30,  2.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  35%|###5      | 7/20 [00:22<00:53,  4.15s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:53,284]\u001b[0m Trial 13 finished with value: 1.901173093346635 and parameters: {'num_leaves': 243}. Best is trial 7 with value: 1.8987826386791293.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  35%|###5      | 7/20 [00:22<00:53,  4.15s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  35%|###5      | 7/20 [00:25<00:53,  4.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  40%|####      | 8/20 [00:25<00:44,  3.68s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:21:55,846]\u001b[0m Trial 14 finished with value: 1.9043904476482743 and parameters: {'num_leaves': 64}. Best is trial 7 with value: 1.8987826386791293.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  40%|####      | 8/20 [00:25<00:44,  3.68s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  40%|####      | 8/20 [00:32<00:44,  3.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  45%|####5     | 9/20 [00:32<00:52,  4.73s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:03,032]\u001b[0m Trial 15 finished with value: 1.8927870637990671 and parameters: {'num_leaves': 194}. Best is trial 15 with value: 1.8927870637990671.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  45%|####5     | 9/20 [00:32<00:52,  4.73s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  45%|####5     | 9/20 [00:35<00:52,  4.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  50%|#####     | 10/20 [00:35<00:41,  4.12s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:05,735]\u001b[0m Trial 16 finished with value: 1.8966951477095273 and parameters: {'num_leaves': 62}. Best is trial 15 with value: 1.8927870637990671.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  50%|#####     | 10/20 [00:35<00:41,  4.12s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  50%|#####     | 10/20 [00:37<00:41,  4.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  55%|#####5    | 11/20 [00:37<00:31,  3.54s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:07,908]\u001b[0m Trial 17 finished with value: 1.9099613450524686 and parameters: {'num_leaves': 200}. Best is trial 15 with value: 1.8927870637990671.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  55%|#####5    | 11/20 [00:37<00:31,  3.54s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  55%|#####5    | 11/20 [00:38<00:31,  3.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  60%|######    | 12/20 [00:38<00:22,  2.77s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:08,897]\u001b[0m Trial 18 finished with value: 1.890010415534081 and parameters: {'num_leaves': 54}. Best is trial 18 with value: 1.890010415534081.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  60%|######    | 12/20 [00:38<00:22,  2.77s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  60%|######    | 12/20 [00:41<00:22,  2.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  65%|######5   | 13/20 [00:41<00:19,  2.74s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:11,554]\u001b[0m Trial 19 finished with value: 1.8946528554477962 and parameters: {'num_leaves': 53}. Best is trial 18 with value: 1.890010415534081.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  65%|######5   | 13/20 [00:41<00:19,  2.74s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  65%|######5   | 13/20 [00:41<00:19,  2.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  70%|#######   | 14/20 [00:41<00:12,  2.05s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:11,985]\u001b[0m Trial 20 finished with value: 1.907772875664852 and parameters: {'num_leaves': 27}. Best is trial 18 with value: 1.890010415534081.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  70%|#######   | 14/20 [00:41<00:12,  2.05s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  70%|#######   | 14/20 [00:42<00:12,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  75%|#######5  | 15/20 [00:42<00:09,  1.84s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:13,356]\u001b[0m Trial 21 finished with value: 1.8987623779374112 and parameters: {'num_leaves': 92}. Best is trial 18 with value: 1.890010415534081.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  75%|#######5  | 15/20 [00:42<00:09,  1.84s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  75%|#######5  | 15/20 [00:47<00:09,  1.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  80%|########  | 16/20 [00:47<00:10,  2.58s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:17,649]\u001b[0m Trial 22 finished with value: 1.901371314806784 and parameters: {'num_leaves': 151}. Best is trial 18 with value: 1.890010415534081.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  80%|########  | 16/20 [00:47<00:10,  2.58s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  80%|########  | 16/20 [00:48<00:10,  2.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  85%|########5 | 17/20 [00:48<00:06,  2.23s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:19,052]\u001b[0m Trial 23 finished with value: 1.9042120274418732 and parameters: {'num_leaves': 38}. Best is trial 18 with value: 1.890010415534081.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  85%|########5 | 17/20 [00:48<00:06,  2.23s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  85%|########5 | 17/20 [00:51<00:06,  2.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  90%|######### | 18/20 [00:51<00:04,  2.41s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:21,911]\u001b[0m Trial 24 finished with value: 1.9021812727512106 and parameters: {'num_leaves': 79}. Best is trial 18 with value: 1.890010415534081.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  90%|######### | 18/20 [00:51<00:04,  2.41s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  90%|######### | 18/20 [00:57<00:04,  2.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813:  95%|#########5| 19/20 [00:57<00:03,  3.36s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:27,469]\u001b[0m Trial 25 finished with value: 1.8950405186409425 and parameters: {'num_leaves': 102}. Best is trial 18 with value: 1.890010415534081.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  95%|#########5| 19/20 [00:57<00:03,  3.36s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 1.887813:  95%|#########5| 19/20 [01:01<00:03,  3.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 1.887813: 100%|##########| 20/20 [01:01<00:00,  3.69s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:31,916]\u001b[0m Trial 26 finished with value: 1.9054912780270756 and parameters: {'num_leaves': 148}. Best is trial 18 with value: 1.890010415534081.\u001b[0m\n",
      "num_leaves, val_score: 1.887813: 100%|##########| 20/20 [01:01<00:00,  3.08s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.887813:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.887813:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.887813:  10%|#         | 1/10 [00:00<00:04,  2.20it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:32,377]\u001b[0m Trial 27 finished with value: 1.9019938692859202 and parameters: {'bagging_fraction': 0.7322228108125756, 'bagging_freq': 5}. Best is trial 27 with value: 1.9019938692859202.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.887813:  10%|#         | 1/10 [00:00<00:04,  2.20it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.887813:  10%|#         | 1/10 [00:00<00:04,  2.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.887813:  20%|##        | 2/10 [00:00<00:03,  2.22it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:32,815]\u001b[0m Trial 28 finished with value: 1.9104820959672062 and parameters: {'bagging_fraction': 0.42238013737744357, 'bagging_freq': 1}. Best is trial 27 with value: 1.9019938692859202.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.887813:  20%|##        | 2/10 [00:00<00:03,  2.22it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.887813:  20%|##        | 2/10 [00:01<00:03,  2.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.887813:  30%|###       | 3/10 [00:01<00:03,  1.96it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:33,466]\u001b[0m Trial 29 finished with value: 1.8921069869345684 and parameters: {'bagging_fraction': 0.9813888216019415, 'bagging_freq': 7}. Best is trial 29 with value: 1.8921069869345684.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.887813:  30%|###       | 3/10 [00:01<00:03,  1.96it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.887813:  30%|###       | 3/10 [00:01<00:03,  1.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.887813:  40%|####      | 4/10 [00:01<00:02,  2.03it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:33,920]\u001b[0m Trial 30 finished with value: 1.9152881735887572 and parameters: {'bagging_fraction': 0.42315986585978, 'bagging_freq': 1}. Best is trial 29 with value: 1.8921069869345684.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.887813:  40%|####      | 4/10 [00:02<00:02,  2.03it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.885546:  40%|####      | 4/10 [00:04<00:02,  2.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.885546:  50%|#####     | 5/10 [00:04<00:05,  1.10s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:36,433]\u001b[0m Trial 31 finished with value: 1.8855455711655327 and parameters: {'bagging_fraction': 0.9947596680407689, 'bagging_freq': 7}. Best is trial 31 with value: 1.8855455711655327.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.885546:  50%|#####     | 5/10 [00:04<00:05,  1.10s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.883818:  50%|#####     | 5/10 [00:05<00:05,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.883818:  60%|######    | 6/10 [00:05<00:03,  1.05it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:37,053]\u001b[0m Trial 32 finished with value: 1.8838183202162104 and parameters: {'bagging_fraction': 0.9608720942707712, 'bagging_freq': 7}. Best is trial 32 with value: 1.8838183202162104.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.883818:  60%|######    | 6/10 [00:05<00:03,  1.05it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.883818:  60%|######    | 6/10 [00:05<00:03,  1.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.883818:  70%|#######   | 7/10 [00:05<00:02,  1.17it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:37,663]\u001b[0m Trial 33 finished with value: 1.8930110649104661 and parameters: {'bagging_fraction': 0.988882341995304, 'bagging_freq': 7}. Best is trial 32 with value: 1.8838183202162104.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.883818:  70%|#######   | 7/10 [00:05<00:02,  1.17it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.883818:  70%|#######   | 7/10 [00:06<00:02,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.883818:  80%|########  | 8/10 [00:06<00:01,  1.28it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:38,283]\u001b[0m Trial 34 finished with value: 1.9022179951665252 and parameters: {'bagging_fraction': 0.8474939874973669, 'bagging_freq': 5}. Best is trial 32 with value: 1.8838183202162104.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.883818:  80%|########  | 8/10 [00:06<00:01,  1.28it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.883818:  80%|########  | 8/10 [00:06<00:01,  1.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.883818:  90%|######### | 9/10 [00:06<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:38,814]\u001b[0m Trial 35 finished with value: 1.8856555095214083 and parameters: {'bagging_fraction': 0.8978238600449622, 'bagging_freq': 7}. Best is trial 32 with value: 1.8838183202162104.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 1.883818:  90%|######### | 9/10 [00:06<00:00,  1.41it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 1.883818:  90%|######### | 9/10 [00:09<00:00,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 1.883818: 100%|##########| 10/10 [00:09<00:00,  1.19s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:41,123]\u001b[0m Trial 36 finished with value: 1.9066205156966014 and parameters: {'bagging_fraction': 0.9829170838058502, 'bagging_freq': 7}. Best is trial 32 with value: 1.8838183202162104.\u001b[0m\n",
      "bagging, val_score: 1.883818: 100%|##########| 10/10 [00:09<00:00,  1.09it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:   0%|          | 0/6 [00:01<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:  17%|#6        | 1/6 [00:01<00:08,  1.65s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:42,783]\u001b[0m Trial 37 finished with value: 1.8930474141511313 and parameters: {'feature_fraction': 0.748}. Best is trial 37 with value: 1.8930474141511313.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:  17%|#6        | 1/6 [00:01<00:08,  1.65s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:  17%|#6        | 1/6 [00:03<00:08,  1.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:  33%|###3      | 2/6 [00:03<00:06,  1.67s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:44,490]\u001b[0m Trial 38 finished with value: 1.899037983761415 and parameters: {'feature_fraction': 0.62}. Best is trial 37 with value: 1.8930474141511313.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:  33%|###3      | 2/6 [00:03<00:06,  1.67s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:  33%|###3      | 2/6 [00:04<00:06,  1.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:  50%|#####     | 3/6 [00:04<00:04,  1.63s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:46,037]\u001b[0m Trial 39 finished with value: 1.8973452376940088 and parameters: {'feature_fraction': 0.652}. Best is trial 37 with value: 1.8930474141511313.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:  50%|#####     | 3/6 [00:04<00:04,  1.63s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:  50%|#####     | 3/6 [00:06<00:04,  1.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:  67%|######6   | 4/6 [00:06<00:03,  1.60s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:47,571]\u001b[0m Trial 40 finished with value: 1.8895091305229061 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 40 with value: 1.8895091305229061.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:  67%|######6   | 4/6 [00:06<00:03,  1.60s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:  67%|######6   | 4/6 [00:07<00:03,  1.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:  83%|########3 | 5/6 [00:07<00:01,  1.55s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:48,992]\u001b[0m Trial 41 finished with value: 1.8932515855858059 and parameters: {'feature_fraction': 0.716}. Best is trial 40 with value: 1.8895091305229061.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:  83%|########3 | 5/6 [00:07<00:01,  1.55s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818:  83%|########3 | 5/6 [00:08<00:01,  1.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 1.883818: 100%|##########| 6/6 [00:08<00:00,  1.31s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:49,741]\u001b[0m Trial 42 finished with value: 1.891411219293014 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 40 with value: 1.8895091305229061.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.883818: 100%|##########| 6/6 [00:08<00:00,  1.44s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:   5%|5         | 1/20 [00:00<00:12,  1.49it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:50,417]\u001b[0m Trial 43 finished with value: 1.8838183199440521 and parameters: {'lambda_l1': 1.1789535678221707e-08, 'lambda_l2': 2.774633070383231e-06}. Best is trial 43 with value: 1.8838183199440521.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:   5%|5         | 1/20 [00:00<00:12,  1.49it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:   5%|5         | 1/20 [00:01<00:12,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  10%|#         | 2/20 [00:01<00:11,  1.59it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:50,951]\u001b[0m Trial 44 finished with value: 1.8838183200208276 and parameters: {'lambda_l1': 1.212538893631635e-08, 'lambda_l2': 1.8354108905021276e-06}. Best is trial 43 with value: 1.8838183199440521.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  10%|#         | 2/20 [00:01<00:11,  1.59it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  10%|#         | 2/20 [00:01<00:11,  1.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  15%|#5        | 3/20 [00:01<00:10,  1.61it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:51,552]\u001b[0m Trial 45 finished with value: 1.8838183199174046 and parameters: {'lambda_l1': 1.8499139392081146e-08, 'lambda_l2': 3.008398134809778e-06}. Best is trial 45 with value: 1.8838183199174046.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  15%|#5        | 3/20 [00:01<00:10,  1.61it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  15%|#5        | 3/20 [00:03<00:10,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  20%|##        | 4/20 [00:03<00:17,  1.08s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:53,713]\u001b[0m Trial 46 finished with value: 1.8838183199777947 and parameters: {'lambda_l1': 1.4080215198495686e-08, 'lambda_l2': 2.4424037357470985e-06}. Best is trial 45 with value: 1.8838183199174046.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  20%|##        | 4/20 [00:03<00:17,  1.08s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  20%|##        | 4/20 [00:05<00:17,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  25%|##5       | 5/20 [00:05<00:17,  1.18s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:55,127]\u001b[0m Trial 47 finished with value: 1.8838183199464968 and parameters: {'lambda_l1': 1.0239279066486913e-08, 'lambda_l2': 2.809420004049294e-06}. Best is trial 45 with value: 1.8838183199174046.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  25%|##5       | 5/20 [00:05<00:17,  1.18s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  25%|##5       | 5/20 [00:06<00:17,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  30%|###       | 6/20 [00:06<00:14,  1.02s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:55,786]\u001b[0m Trial 48 finished with value: 1.8838183198503147 and parameters: {'lambda_l1': 1.4016117657464253e-08, 'lambda_l2': 4.023885027036801e-06}. Best is trial 48 with value: 1.8838183198503147.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  30%|###       | 6/20 [00:06<00:14,  1.02s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  30%|###       | 6/20 [00:06<00:14,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  35%|###5      | 7/20 [00:06<00:11,  1.12it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:56,364]\u001b[0m Trial 49 finished with value: 1.8838183198454514 and parameters: {'lambda_l1': 1.832368885702647e-08, 'lambda_l2': 4.055602217977826e-06}. Best is trial 49 with value: 1.8838183198454514.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  35%|###5      | 7/20 [00:06<00:11,  1.12it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  35%|###5      | 7/20 [00:07<00:11,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  40%|####      | 8/20 [00:07<00:09,  1.26it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:56,940]\u001b[0m Trial 50 finished with value: 1.8838183198599938 and parameters: {'lambda_l1': 1.3346829745846155e-08, 'lambda_l2': 3.4269496369514202e-06}. Best is trial 49 with value: 1.8838183198454514.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  40%|####      | 8/20 [00:07<00:09,  1.26it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  40%|####      | 8/20 [00:09<00:09,  1.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  45%|####5     | 9/20 [00:09<00:12,  1.13s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:22:58,845]\u001b[0m Trial 51 finished with value: 1.8838183198608887 and parameters: {'lambda_l1': 1.1589773618246523e-08, 'lambda_l2': 3.88765658836577e-06}. Best is trial 49 with value: 1.8838183198454514.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  45%|####5     | 9/20 [00:09<00:12,  1.13s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  45%|####5     | 9/20 [00:10<00:12,  1.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  50%|#####     | 10/20 [00:10<00:12,  1.30s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:23:00,537]\u001b[0m Trial 52 finished with value: 1.8838183196790597 and parameters: {'lambda_l1': 1.0763241060397028e-08, 'lambda_l2': 6.103680304554141e-06}. Best is trial 52 with value: 1.8838183196790597.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  50%|#####     | 10/20 [00:10<00:12,  1.30s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  50%|#####     | 10/20 [00:12<00:12,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  55%|#####5    | 11/20 [00:12<00:12,  1.43s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:23:02,260]\u001b[0m Trial 53 finished with value: 1.8838183195634723 and parameters: {'lambda_l1': 1.4698680837703283e-08, 'lambda_l2': 7.247831663264478e-06}. Best is trial 53 with value: 1.8838183195634723.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  55%|#####5    | 11/20 [00:12<00:12,  1.43s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  55%|#####5    | 11/20 [00:13<00:12,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  60%|######    | 12/20 [00:13<00:10,  1.28s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:23:03,205]\u001b[0m Trial 54 finished with value: 1.883818318563881 and parameters: {'lambda_l1': 1.5257814011568608e-08, 'lambda_l2': 2.1523716472830473e-05}. Best is trial 54 with value: 1.883818318563881.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  60%|######    | 12/20 [00:13<00:10,  1.28s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  60%|######    | 12/20 [00:14<00:10,  1.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  65%|######5   | 13/20 [00:14<00:08,  1.16s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:23:04,077]\u001b[0m Trial 55 finished with value: 1.8838182860959998 and parameters: {'lambda_l1': 1.944920793589882e-06, 'lambda_l2': 0.0004469489678110876}. Best is trial 55 with value: 1.8838182860959998.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  65%|######5   | 13/20 [00:14<00:08,  1.16s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  65%|######5   | 13/20 [00:14<00:08,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  70%|#######   | 14/20 [00:14<00:05,  1.02it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:23:04,632]\u001b[0m Trial 56 finished with value: 1.883818144794169 and parameters: {'lambda_l1': 5.1756007138871116e-05, 'lambda_l2': 0.002339681288363832}. Best is trial 56 with value: 1.883818144794169.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  70%|#######   | 14/20 [00:14<00:05,  1.02it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  70%|#######   | 14/20 [00:15<00:05,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  75%|#######5  | 15/20 [00:15<00:04,  1.18it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:23:05,175]\u001b[0m Trial 57 finished with value: 1.8838182584810719 and parameters: {'lambda_l1': 4.82587273066422e-05, 'lambda_l2': 0.0008451740910990262}. Best is trial 56 with value: 1.883818144794169.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  75%|#######5  | 15/20 [00:15<00:04,  1.18it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  75%|#######5  | 15/20 [00:15<00:04,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  80%|########  | 16/20 [00:15<00:03,  1.32it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:23:05,718]\u001b[0m Trial 58 finished with value: 1.8838178363951084 and parameters: {'lambda_l1': 0.00014752963064640543, 'lambda_l2': 0.006456570878287601}. Best is trial 58 with value: 1.8838178363951084.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  80%|########  | 16/20 [00:15<00:03,  1.32it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  80%|########  | 16/20 [00:18<00:03,  1.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  85%|########5 | 17/20 [00:18<00:03,  1.31s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:23:08,309]\u001b[0m Trial 59 finished with value: 1.8838178611505965 and parameters: {'lambda_l1': 0.00010172195429492197, 'lambda_l2': 0.006097349827149588}. Best is trial 58 with value: 1.8838178363951084.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  85%|########5 | 17/20 [00:18<00:03,  1.31s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  85%|########5 | 17/20 [00:19<00:03,  1.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  90%|######### | 18/20 [00:19<00:02,  1.08s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:23:08,854]\u001b[0m Trial 60 finished with value: 1.8840259139881015 and parameters: {'lambda_l1': 0.00014822767027728953, 'lambda_l2': 0.02452975665801275}. Best is trial 58 with value: 1.8838178363951084.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  90%|######### | 18/20 [00:19<00:02,  1.08s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  90%|######### | 18/20 [00:19<00:02,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  95%|#########5| 19/20 [00:19<00:00,  1.08it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:23:09,435]\u001b[0m Trial 61 finished with value: 1.8838181784377193 and parameters: {'lambda_l1': 0.00011039047144306694, 'lambda_l2': 0.001944816441034726}. Best is trial 58 with value: 1.8838178363951084.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  95%|#########5| 19/20 [00:19<00:00,  1.08it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 1.883818:  95%|#########5| 19/20 [00:20<00:00,  1.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 1.883818: 100%|##########| 20/20 [00:20<00:00,  1.22it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:23:09,998]\u001b[0m Trial 62 finished with value: 1.8838182505554228 and parameters: {'lambda_l1': 0.00011145379720681737, 'lambda_l2': 0.0009952903581453977}. Best is trial 58 with value: 1.8838178363951084.\u001b[0m\n",
      "regularization_factors, val_score: 1.883818: 100%|##########| 20/20 [00:20<00:00,  1.01s/it]\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.883818:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.883818:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.883818:  20%|##        | 1/5 [00:00<00:02,  1.80it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:23:10,557]\u001b[0m Trial 63 finished with value: 1.8974733669462471 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 1.8974733669462471.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.883818:  20%|##        | 1/5 [00:00<00:02,  1.80it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.883818:  20%|##        | 1/5 [00:02<00:02,  1.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.883818:  40%|####      | 2/5 [00:02<00:02,  1.15it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:23:12,173]\u001b[0m Trial 64 finished with value: 1.8944922045027655 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 1.8944922045027655.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.883818:  40%|####      | 2/5 [00:02<00:02,  1.15it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.883818:  40%|####      | 2/5 [00:04<00:02,  1.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.883818:  60%|######    | 3/5 [00:04<00:02,  1.19s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:23:14,102]\u001b[0m Trial 65 finished with value: 1.9034082314737424 and parameters: {'min_child_samples': 10}. Best is trial 64 with value: 1.8944922045027655.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.883818:  60%|######    | 3/5 [00:04<00:02,  1.19s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.883818:  60%|######    | 3/5 [00:05<00:02,  1.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.883818:  80%|########  | 4/5 [00:05<00:01,  1.34s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:23:15,799]\u001b[0m Trial 66 finished with value: 1.8935092846215544 and parameters: {'min_child_samples': 100}. Best is trial 66 with value: 1.8935092846215544.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.883818:  80%|########  | 4/5 [00:05<00:01,  1.34s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34676\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score 1.256994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 1.883818:  80%|########  | 4/5 [00:06<00:01,  1.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 1.883818: 100%|##########| 5/5 [00:06<00:00,  1.09s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-27 00:23:16,307]\u001b[0m Trial 67 finished with value: 1.8959990311974055 and parameters: {'min_child_samples': 50}. Best is trial 66 with value: 1.8935092846215544.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.883818: 100%|##########| 5/5 [00:06<00:00,  1.26s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category2</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_&lt;h1&gt;</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_&lt;/i&gt;</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category1+category2</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country+category1</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_17_y</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_18_y</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_19_y</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_23_y</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_24_y</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importance\n",
       "category2                    55\n",
       "number_of_<h1>                2\n",
       "number_of_</i>                1\n",
       "category1+category2          34\n",
       "country+category1            17\n",
       "...                         ...\n",
       "wordvec_17_y                  4\n",
       "wordvec_18_y                  4\n",
       "wordvec_19_y                  2\n",
       "wordvec_23_y                  5\n",
       "wordvec_24_y                  6\n",
       "\n",
       "[148 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"data/lgbm_config_svd64_raw.json\") as f:\n",
    "    optuna_config_dict = json.load(f)\n",
    "\n",
    "feature_cols = optuna_config_dict[\"selected_feature\"]\n",
    "CATEGORICAL_COLS = [\n",
    "    \"country\",\n",
    "    \"category1\",\n",
    "    \"category2\",\n",
    "    \"country+category1\",\n",
    "    \"country+category2\",\n",
    "    \"category1+category2\",\n",
    "]\n",
    "\n",
    "for categorical_col in set(CATEGORICAL_COLS):\n",
    "    if categorical_col not in feature_cols:\n",
    "        CATEGORICAL_COLS.remove(categorical_col)\n",
    "\n",
    "        \n",
    "params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "    }\n",
    "\n",
    "oof, pred, importances = run_optuna_lgbm(test_data, pd.concat([train_data, dang_df], axis=1), [\"danger\"], feature_cols, CATEGORICAL_COLS, 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.69785709, 1.69589163, 2.39570365, ..., 0.93878453, 0.22826567,\n",
       "       0.53302405])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10540</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10545 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       danger\n",
       "0           1\n",
       "1           0\n",
       "2           2\n",
       "3           0\n",
       "4           0\n",
       "...       ...\n",
       "10540       6\n",
       "10541       1\n",
       "10542       0\n",
       "10543       0\n",
       "10544       0\n",
       "\n",
       "[10545 rows x 1 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dang_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
