{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF, PCA\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "import nltk\n",
    "from nltk import PunktSentenceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import transformers\n",
    "import gensim.downloader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_train_test(train, test):\n",
    "    all_df = pd.merge(train, test, how=\"outer\")\n",
    "    all_df[\"data_type\"] = \"\"\n",
    "    for n in range(len(all_df)):\n",
    "        all_df[\"data_type\"][n] = \"test\" if np.isnan(all_df[\"state\"][n]) else \"train\"\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-685f4a3720c8>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_df[\"data_type\"][n] = \"test\" if np.isnan(all_df[\"state\"][n]) else \"train\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>goal</th>\n",
       "      <th>country</th>\n",
       "      <th>duration</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>html_content</th>\n",
       "      <th>state</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4001-5000</td>\n",
       "      <td>CH</td>\n",
       "      <td>29</td>\n",
       "      <td>publishing</td>\n",
       "      <td>young adult</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;span class=\"bold\"&gt;...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3001-4000</td>\n",
       "      <td>NL</td>\n",
       "      <td>34</td>\n",
       "      <td>fashion</td>\n",
       "      <td>ready-to-wear</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;h1 class=\"page-anc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19001-20000</td>\n",
       "      <td>US</td>\n",
       "      <td>30</td>\n",
       "      <td>food</td>\n",
       "      <td>spaces</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt; As our society ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2001-3000</td>\n",
       "      <td>US</td>\n",
       "      <td>41</td>\n",
       "      <td>technology</td>\n",
       "      <td>3d printing</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt;My name is Donal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2001-3000</td>\n",
       "      <td>GB</td>\n",
       "      <td>29</td>\n",
       "      <td>technology</td>\n",
       "      <td>diy electronics</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;div class=\"templat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21084</th>\n",
       "      <td>21084</td>\n",
       "      <td>9001-10000</td>\n",
       "      <td>US</td>\n",
       "      <td>30</td>\n",
       "      <td>food</td>\n",
       "      <td>drinks</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt;Its time to get ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21085</th>\n",
       "      <td>21085</td>\n",
       "      <td>1-1000</td>\n",
       "      <td>US</td>\n",
       "      <td>29</td>\n",
       "      <td>food</td>\n",
       "      <td>small batch</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt;I have been roas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21086</th>\n",
       "      <td>21086</td>\n",
       "      <td>1001-2000</td>\n",
       "      <td>US</td>\n",
       "      <td>27</td>\n",
       "      <td>crafts</td>\n",
       "      <td>pottery</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt;         I have ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21087</th>\n",
       "      <td>21087</td>\n",
       "      <td>2001-3000</td>\n",
       "      <td>US</td>\n",
       "      <td>30</td>\n",
       "      <td>design</td>\n",
       "      <td>graphic design</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;h1 class=\"page-anc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21088</th>\n",
       "      <td>21088</td>\n",
       "      <td>1001-2000</td>\n",
       "      <td>US</td>\n",
       "      <td>30</td>\n",
       "      <td>fashion</td>\n",
       "      <td>ready-to-wear</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt;I have been deve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21089 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         goal country  duration   category1        category2  \\\n",
       "0          0    4001-5000      CH        29  publishing      young adult   \n",
       "1          1    3001-4000      NL        34     fashion    ready-to-wear   \n",
       "2          2  19001-20000      US        30        food           spaces   \n",
       "3          3    2001-3000      US        41  technology      3d printing   \n",
       "4          4    2001-3000      GB        29  technology  diy electronics   \n",
       "...      ...          ...     ...       ...         ...              ...   \n",
       "21084  21084   9001-10000      US        30        food           drinks   \n",
       "21085  21085       1-1000      US        29        food      small batch   \n",
       "21086  21086    1001-2000      US        27      crafts          pottery   \n",
       "21087  21087    2001-3000      US        30      design   graphic design   \n",
       "21088  21088    1001-2000      US        30     fashion    ready-to-wear   \n",
       "\n",
       "                                            html_content  state data_type  \n",
       "0      <div class=\"contents\"><div><span class=\"bold\">...    0.0     train  \n",
       "1      <div class=\"contents\"><div><h1 class=\"page-anc...    0.0     train  \n",
       "2      <div class=\"contents\"><div><p> As our society ...    0.0     train  \n",
       "3      <div class=\"contents\"><div><p>My name is Donal...    0.0     train  \n",
       "4      <div class=\"contents\"><div><div class=\"templat...    1.0     train  \n",
       "...                                                  ...    ...       ...  \n",
       "21084  <div class=\"contents\"><div><p>Its time to get ...    NaN      test  \n",
       "21085  <div class=\"contents\"><div><p>I have been roas...    NaN      test  \n",
       "21086  <div class=\"contents\"><div><p>         I have ...    NaN      test  \n",
       "21087  <div class=\"contents\"><div><h1 class=\"page-anc...    NaN      test  \n",
       "21088  <div class=\"contents\"><div><p>I have been deve...    NaN      test  \n",
       "\n",
       "[21089 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = concat_train_test(train, test)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_spaces(html):\n",
    "    sbd = PunktSentenceTokenizer()\n",
    "    html_no_spaces = \" \".join(sbd.sentences_from_text(html, realign_boundaries=True))\n",
    "    return re.sub(r'\\s+', \" \", html_no_spaces)\n",
    "\n",
    "def cleanup_japanese(html):\n",
    "    return re.sub('[ぁ-ん ァ-ン 一-龥]', '', html)\n",
    "\n",
    "def number_of_sentence(html):\n",
    "    sbd = PunktSentenceTokenizer()\n",
    "    return len(sbd.sentences_from_text(html, realign_boundaries=True))\n",
    "\n",
    "def add_number_of_sentence(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    df[\"number_of_sentence\"] = list(map(number_of_sentence, df[\"html_raw\"]))\n",
    "    return df\n",
    "\n",
    "def number_of_char(html):\n",
    "    return len(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bs_get_text(html):\n",
    "    res = str(BeautifulSoup(html).get_text())\n",
    "    if not res:\n",
    "        res = \"\"\n",
    "    return res\n",
    "\n",
    "\n",
    "def extract_each_paragraphs(html_text):\n",
    "    paragraphs = []\n",
    "    para_list = html_text.split(\"<p>\")\n",
    "    if not \"<p>\" in html_text[0:4]:\n",
    "        para_list = para_list[1:]\n",
    "    for para in para_list:\n",
    "        if \"</p>\" in para:\n",
    "            para_new = para.split(\"</p>\")[0]\n",
    "        else:\n",
    "            para_new = \"\"\n",
    "            \n",
    "        #それでも残っているhtmlタグを取り除く(要らないかも)\n",
    "        para_new = get_text(para_new)\n",
    "        #para_new = remove_nobreak_space(para_new)\n",
    "        \n",
    "        paragraphs.append(para_new)\n",
    "    try:\n",
    "        paragraphs.remove(\"\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        paragraphs.remove(\" \")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "def count_number_of_words(html_text):\n",
    "    text = get_text(html_text)\n",
    "    token = bert_tokenizer.encode_plus(text)\n",
    "    ids = token['input_ids']\n",
    "    return len(ids)-2\n",
    "    \n",
    "    \n",
    "def add_html_raw(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    df[\"html_raw\"] = list(map(bs_get_text, df[\"html_compiled\"]))\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_number_of_word(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    df[\"number_of_word\"] = list(map(count_number_of_words, df[\"html_compiled\"]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_video_exist(n_video):\n",
    "    is_video_exist = 1 if n_video != 0 else 0\n",
    "    return is_video_exist\n",
    "\n",
    "def improve_n_video(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    df[\"video\"] = list(map(is_video_exist, df[\"number_of_<video>\"]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_paragraphs(para_lis):\n",
    "    para_len_lis = []\n",
    "    for para in para_lis:\n",
    "        n_word = count_number_of_words(para)\n",
    "        para_len_lis.append(n_word)\n",
    "    length = sum(para_len_lis)\n",
    "    while length > 512:\n",
    "        para_len_lis = para_len_lis[1:]\n",
    "        length = sum(para_len_lis)\n",
    "    n_paragraph = len(para_len_lis)\n",
    "    selected_para = para_lis[-n_paragraph:]\n",
    "    return selected_para\n",
    "\n",
    "def choose_para(html):\n",
    "    para_list = extract_each_paragraphs(html)\n",
    "    selected_para_list = select_paragraphs(para_list)\n",
    "    sentence = \" \".join(selected_para_list)\n",
    "    return sentence\n",
    "\n",
    "def add_each_paragraphs(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    df[\"selected_paragraphs\"] = list(map(choose_para, df[\"html_compiled\"]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnA_pre_columnB(A_B):\n",
    "    columnA, columnB = A_B\n",
    "    if columnB == 0:\n",
    "        return np.inf\n",
    "    else:\n",
    "        return columnA / columnB\n",
    "    \n",
    "def add_AperB(df_origin, columns):\n",
    "    \"\"\"\n",
    "    columns : tuple\n",
    "    columnA,B,C: str\n",
    "    \"\"\"\n",
    "    df = df_origin.copy()\n",
    "    columnA, columnB = columns\n",
    "    columnC = f'{columnA.split(\"_\")[-1]}_per_{columnB.split(\"_\")[-1]}'\n",
    "    df[columnC] = list(map(columnA_pre_columnB, zip(df[columnA], df[columnB])))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_html_tag(html):\n",
    "    html_tags = [\"a\", \"div\", \"!\", \"span\", \"img\", \"button\", \"video\", \"figure\",\n",
    "                 \"figcaption\", \"h1\",\"h1 \", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"polygon\",\n",
    "                 \"iframe\", \"style\", \"svg\", \"use\", \"time\", \"source\", \"li\",\n",
    "                 \"ul\", \"track\", \"embed\", \"input\", \"param\",\n",
    "                ]\n",
    "    html = html.replace(u'\\xa0', u' ')\n",
    "    html = html.replace(u'\\xc2', u' ')\n",
    "    spaces = re.compile(r'\\s+')\n",
    "    html = spaces.sub(\" \", html)\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    html = url.sub(\"<URL>\", html)\n",
    "    \n",
    "    for tag in html_tags:\n",
    "        compiler = re.compile(r\"<{}.*?>\".format(tag))\n",
    "        html = compiler.sub(f\"<{tag}>\", html)\n",
    "        \n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_html_tag(html_text):\n",
    "    tag_list = re.findall(r\"<.*?>\", html_text)\n",
    "    return tag_list\n",
    "\n",
    "def extract_and_join_tag(html):\n",
    "    tag_list = extract_html_tag(html)\n",
    "    tag_only_content = \" \".join(tag_list)\n",
    "    return tag_only_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tag_set(df):\n",
    "    tags = set()\n",
    "    for html_text in df.html_content:\n",
    "        compiled_html_text = compile_html_tag(html_text)\n",
    "        tags |= set(extract_html_tag(compiled_html_text))\n",
    "    return tags\n",
    "\n",
    "def count_n_tag(html_tag):\n",
    "    html, tag = html_tag\n",
    "    return html.count(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TAGS = make_tag_set(all_df)\n",
    "def get_text(html):\n",
    "    html_tags = ALL_TAGS\n",
    "    for tag in html_tags:\n",
    "        html = re.sub(tag, \"\", html)\n",
    "    html = cleanup_spaces(html)\n",
    "    return html\n",
    "\n",
    "def add_html_raw_text(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    df[\"html_raw\"] = list(map(get_text, df[\"html_compiled\"]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_number_of_tag(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    tag_set = make_tag_set(df)\n",
    "    for tag in tag_set:\n",
    "        df[f\"number_of_{tag}\"] = list(map(count_n_tag, zip(df[\"html_compiled\"], [tag]*len(df))))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_compiled_html(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    df[\"html_compiled\"] = list(map(compile_html_tag, df[\"html_content\"]))\n",
    "    return df\n",
    "\n",
    "def add_tag_only(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    df[\"tag_only\"] = list(map(extract_and_join_tag, df[\"html_compiled\"]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pair(candidates):\n",
    "    pairs = []\n",
    "    N = len(candidates)\n",
    "    for n, first in enumerate(candidates):\n",
    "        for k in range(n+1,N):\n",
    "            second = candidates[k]\n",
    "            pairs.append([first, second])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:17<00:00,  8.74s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>goal</th>\n",
       "      <th>country</th>\n",
       "      <th>duration</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>html_content</th>\n",
       "      <th>state</th>\n",
       "      <th>data_type</th>\n",
       "      <th>html_compiled</th>\n",
       "      <th>html_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4001-5000</td>\n",
       "      <td>CH</td>\n",
       "      <td>29</td>\n",
       "      <td>publishing</td>\n",
       "      <td>young adult</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;span class=\"bold\"&gt;...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;span&gt;Mark Saggia&lt;/span&gt; is an Itali...</td>\n",
       "      <td>Mark Saggia is an Italian writer who emigrated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3001-4000</td>\n",
       "      <td>NL</td>\n",
       "      <td>34</td>\n",
       "      <td>fashion</td>\n",
       "      <td>ready-to-wear</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;h1 class=\"page-anc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;h1&gt;Hello, I am Augustinas. I am a g...</td>\n",
       "      <td>Hello, I am Augustinas. I am a graphic designe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19001-20000</td>\n",
       "      <td>US</td>\n",
       "      <td>30</td>\n",
       "      <td>food</td>\n",
       "      <td>spaces</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt; As our society ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;p&gt; As our society begins to wake up...</td>\n",
       "      <td>As our society begins to wake up from the han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2001-3000</td>\n",
       "      <td>US</td>\n",
       "      <td>41</td>\n",
       "      <td>technology</td>\n",
       "      <td>3d printing</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt;My name is Donal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;p&gt;My name is Donald Osborne and I a...</td>\n",
       "      <td>My name is Donald Osborne and I am an entrepre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2001-3000</td>\n",
       "      <td>GB</td>\n",
       "      <td>29</td>\n",
       "      <td>technology</td>\n",
       "      <td>diy electronics</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;div class=\"templat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;div&gt; &lt;figure&gt; &lt;img&gt; &lt;/figure&gt; &lt;/div...</td>\n",
       "      <td>We all love to play, don't we! No matter the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         goal country  duration   category1        category2  \\\n",
       "0   0    4001-5000      CH        29  publishing      young adult   \n",
       "1   1    3001-4000      NL        34     fashion    ready-to-wear   \n",
       "2   2  19001-20000      US        30        food           spaces   \n",
       "3   3    2001-3000      US        41  technology      3d printing   \n",
       "4   4    2001-3000      GB        29  technology  diy electronics   \n",
       "\n",
       "                                        html_content  state data_type  \\\n",
       "0  <div class=\"contents\"><div><span class=\"bold\">...    0.0     train   \n",
       "1  <div class=\"contents\"><div><h1 class=\"page-anc...    0.0     train   \n",
       "2  <div class=\"contents\"><div><p> As our society ...    0.0     train   \n",
       "3  <div class=\"contents\"><div><p>My name is Donal...    0.0     train   \n",
       "4  <div class=\"contents\"><div><div class=\"templat...    1.0     train   \n",
       "\n",
       "                                       html_compiled  \\\n",
       "0  <div><div><span>Mark Saggia</span> is an Itali...   \n",
       "1  <div><div><h1>Hello, I am Augustinas. I am a g...   \n",
       "2  <div><div><p> As our society begins to wake up...   \n",
       "3  <div><div><p>My name is Donald Osborne and I a...   \n",
       "4  <div><div><div> <figure> <img> </figure> </div...   \n",
       "\n",
       "                                            html_raw  \n",
       "0  Mark Saggia is an Italian writer who emigrated...  \n",
       "1  Hello, I am Augustinas. I am a graphic designe...  \n",
       "2   As our society begins to wake up from the han...  \n",
       "3  My name is Donald Osborne and I am an entrepre...  \n",
       "4   We all love to play, don't we! No matter the ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nlp_preprocess(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    funcs = [add_compiled_html,\n",
    "            add_html_raw_text,\n",
    "            #add_each_paragraphs,\n",
    "            #add_tag_only,\n",
    "            #add_number_of_tag,\n",
    "            #add_number_of_word,\n",
    "            #add_number_of_sentence,\n",
    "            ]\n",
    "    for func in tqdm(funcs):\n",
    "        df = func(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "all_new = nlp_preprocess(all_df)\n",
    "#all_new.to_csv('data/all_nlp_preprocessed.csv', index=False)\n",
    "all_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tfidf_svd(df, target_col, stop_words=\"english\", max_gram=2, num_features_tfidf=2000, num_features_svd=128):\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                                 ngram_range=(1,max_gram),\n",
    "                                max_features=num_features_tfidf,\n",
    "                                )\n",
    "    transformer = TruncatedSVD(n_components=num_features_svd)\n",
    "    \n",
    "    X = vectorizer.fit_transform(df[target_col])\n",
    "    matrix = transformer.fit_transform(X)\n",
    "    \n",
    "    columns = [f\"tfidf_svd_{target_col}_{dim}\" for dim in range(num_features_svd)]\n",
    "    feature_df = pd.DataFrame(matrix, columns=columns)\n",
    "    ids = [n for n in range(len(df))]\n",
    "    feature_df[\"id\"] = ids\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_svd_raw_64 = make_tfidf_svd(all_new, \"html_raw\", stop_words=\"english\", max_gram=1, num_features_tfidf=1000, num_features_svd=64)\n",
    "tfidf_svd_raw_64_2gram = make_tfidf_svd(all_new, \"html_raw\", stop_words=\"english\", max_gram=2, num_features_tfidf=None, num_features_svd=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_svd_raw_64_2gram.to_csv(\"data/tfidf_svd_raw_128_2gram.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tfidf(df_origin, num_features):\n",
    "    df = df_origin.copy()\n",
    "    Ngram = 1 if num_features <= 1000 else 2\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                                 ngram_range=(1,Ngram),\n",
    "                                max_features=num_features,\n",
    "                                )\n",
    "    X = vectorizer.fit_transform(df.html_raw)\n",
    "    matrix = vectorizer.transform(df.html_raw)\n",
    "    columns = [f\"tfidf_{word}\" for word in vectorizer.get_feature_names()]\n",
    "    feature_df = pd.DataFrame.sparse.from_spmatrix(data=matrix, columns=columns)\n",
    "    ids = [n for n in range(len(df))]\n",
    "    feature_df[\"id\"] = ids\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_1000 = make_tfidf(all_new, 1000)\n",
    "tfidf_1000.to_csv('data/tfidf_1000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_00</th>\n",
       "      <th>tfidf_000</th>\n",
       "      <th>tfidf_10</th>\n",
       "      <th>tfidf_100</th>\n",
       "      <th>tfidf_11</th>\n",
       "      <th>tfidf_12</th>\n",
       "      <th>tfidf_13</th>\n",
       "      <th>tfidf_14</th>\n",
       "      <th>tfidf_15</th>\n",
       "      <th>tfidf_16</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_york</th>\n",
       "      <th>tfidf_young</th>\n",
       "      <th>tfidf_youth</th>\n",
       "      <th>tfidf_youtube</th>\n",
       "      <th>tfidf_このコンテンツを表示するにはhtml5対応のブラウザが必要です</th>\n",
       "      <th>tfidf_再生</th>\n",
       "      <th>tfidf_動画を再生</th>\n",
       "      <th>tfidf_音ありでリプレイ</th>\n",
       "      <th>tfidf_音声ありで</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.239666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065161</td>\n",
       "      <td>0.065161</td>\n",
       "      <td>0.065161</td>\n",
       "      <td>0.065161</td>\n",
       "      <td>0.065161</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.566628</td>\n",
       "      <td>0.026780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154056</td>\n",
       "      <td>0.154056</td>\n",
       "      <td>0.154056</td>\n",
       "      <td>0.154056</td>\n",
       "      <td>0.154056</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21084</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21085</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21086</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106112</td>\n",
       "      <td>0.085617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21087</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21088</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21089 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tfidf_00  tfidf_000  tfidf_10  tfidf_100  tfidf_11  tfidf_12  tfidf_13  \\\n",
       "0      0.000000   0.000000  0.000000        0.0   0.00000       0.0       0.0   \n",
       "1      0.000000   0.000000  0.000000        0.0   0.00000       0.0       0.0   \n",
       "2      0.239666   0.000000  0.144805        0.0   0.00000       0.0       0.0   \n",
       "3      0.000000   0.000000  0.000000        0.0   0.00000       0.0       0.0   \n",
       "4      0.566628   0.026780  0.000000        0.0   0.00000       0.0       0.0   \n",
       "...         ...        ...       ...        ...       ...       ...       ...   \n",
       "21084  0.000000   0.000000  0.000000        0.0   0.00000       0.0       0.0   \n",
       "21085  0.000000   0.000000  0.126209        0.0   0.00000       0.0       0.0   \n",
       "21086  0.000000   0.073088  0.000000        0.0   0.09915       0.0       0.0   \n",
       "21087  0.000000   0.000000  0.000000        0.0   0.00000       0.0       0.0   \n",
       "21088  0.000000   0.000000  0.000000        0.0   0.00000       0.0       0.0   \n",
       "\n",
       "       tfidf_14  tfidf_15  tfidf_16  ...  tfidf_york  tfidf_young  \\\n",
       "0      0.000000  0.000000       0.0  ...         0.0     0.000000   \n",
       "1      0.000000  0.000000       0.0  ...         0.0     0.097765   \n",
       "2      0.000000  0.059710       0.0  ...         0.0     0.000000   \n",
       "3      0.000000  0.000000       0.0  ...         0.0     0.000000   \n",
       "4      0.000000  0.000000       0.0  ...         0.0     0.000000   \n",
       "...         ...       ...       ...  ...         ...          ...   \n",
       "21084  0.000000  0.000000       0.0  ...         0.0     0.000000   \n",
       "21085  0.000000  0.000000       0.0  ...         0.0     0.000000   \n",
       "21086  0.106112  0.085617       0.0  ...         0.0     0.000000   \n",
       "21087  0.000000  0.000000       0.0  ...         0.0     0.000000   \n",
       "21088  0.000000  0.000000       0.0  ...         0.0     0.000000   \n",
       "\n",
       "       tfidf_youth  tfidf_youtube  tfidf_このコンテンツを表示するにはhtml5対応のブラウザが必要です  \\\n",
       "0              0.0            0.0                               0.000000   \n",
       "1              0.0            0.0                               0.000000   \n",
       "2              0.0            0.0                               0.065161   \n",
       "3              0.0            0.0                               0.000000   \n",
       "4              0.0            0.0                               0.154056   \n",
       "...            ...            ...                                    ...   \n",
       "21084          0.0            0.0                               0.000000   \n",
       "21085          0.0            0.0                               0.000000   \n",
       "21086          0.0            0.0                               0.000000   \n",
       "21087          0.0            0.0                               0.000000   \n",
       "21088          0.0            0.0                               0.000000   \n",
       "\n",
       "       tfidf_再生  tfidf_動画を再生  tfidf_音ありでリプレイ  tfidf_音声ありで     id  \n",
       "0      0.000000     0.000000        0.000000     0.000000      0  \n",
       "1      0.000000     0.000000        0.000000     0.000000      1  \n",
       "2      0.065161     0.065161        0.065161     0.065161      2  \n",
       "3      0.000000     0.000000        0.000000     0.000000      3  \n",
       "4      0.154056     0.154056        0.154056     0.154056      4  \n",
       "...         ...          ...             ...          ...    ...  \n",
       "21084  0.000000     0.000000        0.000000     0.000000  21084  \n",
       "21085  0.000000     0.000000        0.000000     0.000000  21085  \n",
       "21086  0.000000     0.000000        0.000000     0.000000  21086  \n",
       "21087  0.000000     0.000000        0.000000     0.000000  21087  \n",
       "21088  0.000000     0.000000        0.000000     0.000000  21088  \n",
       "\n",
       "[21089 rows x 1001 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_1000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "#from nltk.corpus import wordnet\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    #text = cleanup_japanese(text)\n",
    "    #text = cleanup_spaces(text)\n",
    "    normalized_text = normalize_unicode(text)\n",
    "    normalized_text = normalize_number(normalized_text)\n",
    "    normalized_text = lower_text(normalized_text)\n",
    "    return normalized_text\n",
    "\n",
    "\n",
    "def lower_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def normalize_unicode(text, form='NFKC'):\n",
    "    normalized_text = unicodedata.normalize(form, text)\n",
    "    return normalized_text\n",
    "\n",
    "\n",
    "def lemmatize_term(term, pos=None):\n",
    "    if pos is None:\n",
    "        synsets = wordnet.synsets(term)\n",
    "        if not synsets:\n",
    "            return term\n",
    "        pos = synsets[0].pos()\n",
    "        if pos == wordnet.ADJ_SAT:\n",
    "            pos = wordnet.ADJ\n",
    "    return nltk.WordNetLemmatizer().lemmatize(term, pos=pos)\n",
    "\n",
    "\n",
    "def normalize_number(text):\n",
    "    # 連続した数字を除去\n",
    "    replaced_text = re.sub(r'\\d+', '', text)\n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paragraphs_content(html):\n",
    "    return \" \".join(extract_each_paragraphs(html))\n",
    "\n",
    "def add_paragraphs_content(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    df[\"paragraph's_content\"] = list(map(extract_paragraphs_content, df[\"html_compiled\"]))\n",
    "    return df\n",
    "\n",
    "def add_normalized_html(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    #df[\"normalized_html_raw\"] = list(map(normalize, df[\"paragraph's_content\"]))\n",
    "    df[\"normalized_html_raw\"] = list(map(normalize, df[\"html_raw\"]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:34<00:00,  8.73s/it]\n"
     ]
    }
   ],
   "source": [
    "all_df_new = all_df.copy()\n",
    "funcs = [add_compiled_html,\n",
    "         add_html_raw_text,\n",
    "         add_paragraphs_content,\n",
    "        add_normalized_html,]\n",
    "for func in tqdm(funcs):\n",
    "    all_df_new = func(all_df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>goal</th>\n",
       "      <th>country</th>\n",
       "      <th>duration</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>html_content</th>\n",
       "      <th>state</th>\n",
       "      <th>html_compiled</th>\n",
       "      <th>html_raw</th>\n",
       "      <th>paragraph's_content</th>\n",
       "      <th>normalized_html_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4001-5000</td>\n",
       "      <td>CH</td>\n",
       "      <td>29</td>\n",
       "      <td>publishing</td>\n",
       "      <td>young adult</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;span class=\"bold\"&gt;...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;span&gt;Mark Saggia&lt;/span&gt; is an Itali...</td>\n",
       "      <td>Mark Saggia is an Italian writer who emigrated...</td>\n",
       "      <td>He is a Nerd, Star Wars, Marvel Comics and vid...</td>\n",
       "      <td>mark saggia is an italian writer who emigrated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3001-4000</td>\n",
       "      <td>NL</td>\n",
       "      <td>34</td>\n",
       "      <td>fashion</td>\n",
       "      <td>ready-to-wear</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;h1 class=\"page-anc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;h1&gt;Hello, I am Augustinas. I am a g...</td>\n",
       "      <td>Hello, I am Augustinas. I am a graphic designe...</td>\n",
       "      <td>I think that street fashion is not haute coutu...</td>\n",
       "      <td>hello, i am augustinas. i am a graphic designe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19001-20000</td>\n",
       "      <td>US</td>\n",
       "      <td>30</td>\n",
       "      <td>food</td>\n",
       "      <td>spaces</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt; As our society ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;p&gt; As our society begins to wake up...</td>\n",
       "      <td>As our society begins to wake up from the han...</td>\n",
       "      <td>As our society begins to wake up from the han...</td>\n",
       "      <td>as our society begins to wake up from the han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2001-3000</td>\n",
       "      <td>US</td>\n",
       "      <td>41</td>\n",
       "      <td>technology</td>\n",
       "      <td>3d printing</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt;My name is Donal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;p&gt;My name is Donald Osborne and I a...</td>\n",
       "      <td>My name is Donald Osborne and I am an entrepre...</td>\n",
       "      <td>My name is Donald Osborne and I am an entrepre...</td>\n",
       "      <td>my name is donald osborne and i am an entrepre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2001-3000</td>\n",
       "      <td>GB</td>\n",
       "      <td>29</td>\n",
       "      <td>technology</td>\n",
       "      <td>diy electronics</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;div class=\"templat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;div&gt; &lt;figure&gt; &lt;img&gt; &lt;/figure&gt; &lt;/div...</td>\n",
       "      <td>We all love to play, don't we! No matter the ...</td>\n",
       "      <td>We all love to play, don't we! No matter the a...</td>\n",
       "      <td>we all love to play, don't we! no matter the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         goal country  duration   category1        category2  \\\n",
       "0   0    4001-5000      CH        29  publishing      young adult   \n",
       "1   1    3001-4000      NL        34     fashion    ready-to-wear   \n",
       "2   2  19001-20000      US        30        food           spaces   \n",
       "3   3    2001-3000      US        41  technology      3d printing   \n",
       "4   4    2001-3000      GB        29  technology  diy electronics   \n",
       "\n",
       "                                        html_content  state  \\\n",
       "0  <div class=\"contents\"><div><span class=\"bold\">...    0.0   \n",
       "1  <div class=\"contents\"><div><h1 class=\"page-anc...    0.0   \n",
       "2  <div class=\"contents\"><div><p> As our society ...    0.0   \n",
       "3  <div class=\"contents\"><div><p>My name is Donal...    0.0   \n",
       "4  <div class=\"contents\"><div><div class=\"templat...    1.0   \n",
       "\n",
       "                                       html_compiled  \\\n",
       "0  <div><div><span>Mark Saggia</span> is an Itali...   \n",
       "1  <div><div><h1>Hello, I am Augustinas. I am a g...   \n",
       "2  <div><div><p> As our society begins to wake up...   \n",
       "3  <div><div><p>My name is Donald Osborne and I a...   \n",
       "4  <div><div><div> <figure> <img> </figure> </div...   \n",
       "\n",
       "                                            html_raw  \\\n",
       "0  Mark Saggia is an Italian writer who emigrated...   \n",
       "1  Hello, I am Augustinas. I am a graphic designe...   \n",
       "2   As our society begins to wake up from the han...   \n",
       "3  My name is Donald Osborne and I am an entrepre...   \n",
       "4   We all love to play, don't we! No matter the ...   \n",
       "\n",
       "                                 paragraph's_content  \\\n",
       "0  He is a Nerd, Star Wars, Marvel Comics and vid...   \n",
       "1  I think that street fashion is not haute coutu...   \n",
       "2   As our society begins to wake up from the han...   \n",
       "3  My name is Donald Osborne and I am an entrepre...   \n",
       "4  We all love to play, don't we! No matter the a...   \n",
       "\n",
       "                                 normalized_html_raw  \n",
       "0  mark saggia is an italian writer who emigrated...  \n",
       "1  hello, i am augustinas. i am a graphic designe...  \n",
       "2   as our society begins to wake up from the han...  \n",
       "3  my name is donald osborne and i am an entrepre...  \n",
       "4   we all love to play, don't we! no matter the ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_short_vectors = gensim.downloader.load('glove-twitter-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_most_freq_word(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    \n",
    "    num_features = 1\n",
    "    vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                                 ngram_range=(1,1),\n",
    "                                max_features=num_features,)\n",
    "    mfw_dict = {}\n",
    "    for n in range(len(df)):\n",
    "        try:\n",
    "            vectorizer.fit_transform([df.normalized_html_raw.iloc[n]])\n",
    "            feature = vectorizer.get_feature_names()[0]\n",
    "        except:\n",
    "            # no text\n",
    "            feature = \"\"\n",
    "        mfw_dict[f\"{n}\"] = feature\n",
    "    mfw_df = pd.DataFrame({\"id\": mfw_dict.keys(), \"mfw\": mfw_dict.values()})\n",
    "    \n",
    "    \n",
    "    num_features = 2\n",
    "    vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                                 ngram_range=(1,1),\n",
    "                                max_features=num_features,)\n",
    "    sfw_dict = {}\n",
    "    for n in range(len(df)):\n",
    "        try:\n",
    "            vectorizer.fit_transform([df.normalized_html_raw.iloc[n]])\n",
    "            feature = list(vectorizer.get_feature_names())\n",
    "            feature.remove(mfw_df[\"mfw\"].iloc[n])\n",
    "            feature = feature[0]\n",
    "        except:\n",
    "            # no text\n",
    "            feature = \"\"\n",
    "        sfw_dict[f\"{n}\"] = feature     \n",
    "    mfw_df[\"sfw\"] =  sfw_dict.values()\n",
    "    \n",
    "    return mfw_df\n",
    "\n",
    "\n",
    "def word_to_vector2(words):\n",
    "    try:\n",
    "        vector = glove_short_vectors[words[0]]\n",
    "    except:\n",
    "        try:\n",
    "            vector = glove_short_vectors[words[1]]\n",
    "        except:\n",
    "            vector = np.zeros(25)\n",
    "    return vector\n",
    "\n",
    "def add_wordvec2(df_origin, columns):\n",
    "    df = df_origin.copy()\n",
    "    col1, col2 = columns\n",
    "    df[[f\"mfw_{n}\" for n in range(25)]] = list(map(word_to_vector2, zip(df[col1], df[col2])))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mfw</th>\n",
       "      <th>sfw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>game</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>people</td>\n",
       "      <td>street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>complete</td>\n",
       "      <td>aquaponics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>products</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>bit</td>\n",
       "      <td>micro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>photos</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>luxury</td>\n",
       "      <td>design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>cuff</td>\n",
       "      <td>wrist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>graphic</td>\n",
       "      <td>borge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>residence</td>\n",
       "      <td>film</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id        mfw         sfw\n",
       "0  0       game        book\n",
       "1  1     people      street\n",
       "2  2   complete  aquaponics\n",
       "3  3   products    business\n",
       "4  4        bit       micro\n",
       "5  5     photos        like\n",
       "6  6     luxury      design\n",
       "7  7       cuff       wrist\n",
       "8  8    graphic       borge\n",
       "9  9  residence        film"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfw_df = extract_most_freq_word(all_df_new)\n",
    "mfw_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfw_df = add_wordvec(mfw_df)\n",
    "mfw_df.to_csv('data/mfw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_most_informative_word(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    \n",
    "    num_features = 5000\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                                 ngram_range=(1,1),\n",
    "                                max_features=num_features,)\n",
    "    X = vectorizer.fit_transform(df.normalized_html_raw)\n",
    "    matrix = vectorizer.transform(df.normalized_html_raw)\n",
    "    feature_name = vectorizer.get_feature_names()\n",
    "    \n",
    "    miws = []\n",
    "    ids = df[\"id\"]\n",
    "    for n in tqdm(range(len(df))):\n",
    "        miw_column = np.argmax(matrix[n])\n",
    "        miw = feature_name[miw_column]\n",
    "        miws.append(miw)\n",
    "    miw_df = pd.DataFrame({\"id\": ids, \"miw\": miws})\n",
    "    return miw_df\n",
    "\n",
    "def word_to_vector(words):\n",
    "    try:\n",
    "        vector = glove_short_vectors[words]\n",
    "    except:\n",
    "        print(words)\n",
    "        vector = np.zeros(25)\n",
    "    return vector\n",
    "\n",
    "def add_wordvec(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    df[[f\"miw_{n}\" for n in range(25)]] = list(map(word_to_vector, df[\"miw\"]))\n",
    "    df = df.drop(\"miw\", axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21089/21089 [00:03<00:00, 6875.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n",
      "このコンテンツを表示するにはhtml対応のブラウザが必要です\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>miw_0</th>\n",
       "      <th>miw_1</th>\n",
       "      <th>miw_2</th>\n",
       "      <th>miw_3</th>\n",
       "      <th>miw_4</th>\n",
       "      <th>miw_5</th>\n",
       "      <th>miw_6</th>\n",
       "      <th>miw_7</th>\n",
       "      <th>miw_8</th>\n",
       "      <th>...</th>\n",
       "      <th>miw_15</th>\n",
       "      <th>miw_16</th>\n",
       "      <th>miw_17</th>\n",
       "      <th>miw_18</th>\n",
       "      <th>miw_19</th>\n",
       "      <th>miw_20</th>\n",
       "      <th>miw_21</th>\n",
       "      <th>miw_22</th>\n",
       "      <th>miw_23</th>\n",
       "      <th>miw_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.14600</td>\n",
       "      <td>0.329100</td>\n",
       "      <td>0.268780</td>\n",
       "      <td>-1.394500</td>\n",
       "      <td>-0.300440</td>\n",
       "      <td>0.77901</td>\n",
       "      <td>1.35370</td>\n",
       "      <td>0.373930</td>\n",
       "      <td>0.504780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102870</td>\n",
       "      <td>-0.17618</td>\n",
       "      <td>-1.288100</td>\n",
       "      <td>-0.598010</td>\n",
       "      <td>0.261310</td>\n",
       "      <td>-1.261900</td>\n",
       "      <td>0.392020</td>\n",
       "      <td>0.593090</td>\n",
       "      <td>-0.552320</td>\n",
       "      <td>0.005087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.73473</td>\n",
       "      <td>0.120720</td>\n",
       "      <td>0.607640</td>\n",
       "      <td>-0.504740</td>\n",
       "      <td>-0.057365</td>\n",
       "      <td>0.52869</td>\n",
       "      <td>0.59001</td>\n",
       "      <td>-0.237530</td>\n",
       "      <td>1.140600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034995</td>\n",
       "      <td>0.10252</td>\n",
       "      <td>0.021756</td>\n",
       "      <td>-0.308370</td>\n",
       "      <td>0.430040</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>-0.504040</td>\n",
       "      <td>0.230500</td>\n",
       "      <td>-1.449700</td>\n",
       "      <td>0.589240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.07785</td>\n",
       "      <td>0.065545</td>\n",
       "      <td>-0.349580</td>\n",
       "      <td>-0.378050</td>\n",
       "      <td>0.873780</td>\n",
       "      <td>0.24333</td>\n",
       "      <td>1.49570</td>\n",
       "      <td>-0.562600</td>\n",
       "      <td>0.070204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>0.16465</td>\n",
       "      <td>0.320060</td>\n",
       "      <td>-0.045544</td>\n",
       "      <td>-0.319110</td>\n",
       "      <td>-1.013800</td>\n",
       "      <td>-0.054359</td>\n",
       "      <td>0.200740</td>\n",
       "      <td>0.320610</td>\n",
       "      <td>-0.455840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.70687</td>\n",
       "      <td>0.277370</td>\n",
       "      <td>0.291350</td>\n",
       "      <td>-0.326550</td>\n",
       "      <td>0.538730</td>\n",
       "      <td>-0.65520</td>\n",
       "      <td>1.35720</td>\n",
       "      <td>-0.252000</td>\n",
       "      <td>-0.316420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149920</td>\n",
       "      <td>0.71925</td>\n",
       "      <td>-0.162080</td>\n",
       "      <td>0.623380</td>\n",
       "      <td>0.380480</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>0.478960</td>\n",
       "      <td>-0.523910</td>\n",
       "      <td>-0.798070</td>\n",
       "      <td>0.278350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.30963</td>\n",
       "      <td>-0.206810</td>\n",
       "      <td>-0.041067</td>\n",
       "      <td>-0.149900</td>\n",
       "      <td>0.843800</td>\n",
       "      <td>0.64058</td>\n",
       "      <td>-0.54087</td>\n",
       "      <td>0.055304</td>\n",
       "      <td>1.194000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394530</td>\n",
       "      <td>0.79590</td>\n",
       "      <td>0.501160</td>\n",
       "      <td>0.056856</td>\n",
       "      <td>1.026600</td>\n",
       "      <td>-0.793950</td>\n",
       "      <td>-0.804790</td>\n",
       "      <td>1.111700</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>-0.244400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10539</th>\n",
       "      <td>21084</td>\n",
       "      <td>-0.52575</td>\n",
       "      <td>-0.229000</td>\n",
       "      <td>0.317210</td>\n",
       "      <td>1.120200</td>\n",
       "      <td>-0.113580</td>\n",
       "      <td>0.43399</td>\n",
       "      <td>0.94626</td>\n",
       "      <td>-1.406300</td>\n",
       "      <td>0.277020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.432380</td>\n",
       "      <td>1.08140</td>\n",
       "      <td>-0.507060</td>\n",
       "      <td>0.429500</td>\n",
       "      <td>0.373860</td>\n",
       "      <td>-0.675640</td>\n",
       "      <td>0.441460</td>\n",
       "      <td>0.082967</td>\n",
       "      <td>1.074900</td>\n",
       "      <td>0.846170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10540</th>\n",
       "      <td>21085</td>\n",
       "      <td>-1.45320</td>\n",
       "      <td>0.255940</td>\n",
       "      <td>0.081679</td>\n",
       "      <td>0.490810</td>\n",
       "      <td>-0.059128</td>\n",
       "      <td>0.63656</td>\n",
       "      <td>1.45660</td>\n",
       "      <td>-1.060700</td>\n",
       "      <td>0.479030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.509060</td>\n",
       "      <td>1.24320</td>\n",
       "      <td>-0.541210</td>\n",
       "      <td>0.193750</td>\n",
       "      <td>0.357030</td>\n",
       "      <td>-0.988500</td>\n",
       "      <td>-0.693350</td>\n",
       "      <td>-0.339980</td>\n",
       "      <td>0.718270</td>\n",
       "      <td>1.070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>21086</td>\n",
       "      <td>-0.49515</td>\n",
       "      <td>1.283500</td>\n",
       "      <td>-1.236000</td>\n",
       "      <td>0.708940</td>\n",
       "      <td>0.295160</td>\n",
       "      <td>-0.48593</td>\n",
       "      <td>0.55181</td>\n",
       "      <td>-1.055300</td>\n",
       "      <td>-0.291370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068498</td>\n",
       "      <td>0.51722</td>\n",
       "      <td>-0.204610</td>\n",
       "      <td>0.794370</td>\n",
       "      <td>-0.696780</td>\n",
       "      <td>-0.945340</td>\n",
       "      <td>-0.336830</td>\n",
       "      <td>-0.805960</td>\n",
       "      <td>0.542580</td>\n",
       "      <td>-0.736610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>21087</td>\n",
       "      <td>0.85912</td>\n",
       "      <td>-0.573080</td>\n",
       "      <td>1.341200</td>\n",
       "      <td>0.021117</td>\n",
       "      <td>0.516680</td>\n",
       "      <td>-0.37890</td>\n",
       "      <td>0.11455</td>\n",
       "      <td>-0.635790</td>\n",
       "      <td>-0.581480</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098900</td>\n",
       "      <td>0.28815</td>\n",
       "      <td>-0.689680</td>\n",
       "      <td>0.233150</td>\n",
       "      <td>0.089295</td>\n",
       "      <td>-0.993910</td>\n",
       "      <td>-0.822220</td>\n",
       "      <td>-0.341300</td>\n",
       "      <td>-0.357680</td>\n",
       "      <td>-0.550620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>21088</td>\n",
       "      <td>1.36160</td>\n",
       "      <td>-0.125140</td>\n",
       "      <td>0.617700</td>\n",
       "      <td>0.632880</td>\n",
       "      <td>0.316220</td>\n",
       "      <td>-1.20730</td>\n",
       "      <td>0.69181</td>\n",
       "      <td>-1.737500</td>\n",
       "      <td>-0.789500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314630</td>\n",
       "      <td>0.89104</td>\n",
       "      <td>0.619370</td>\n",
       "      <td>-0.228900</td>\n",
       "      <td>0.343050</td>\n",
       "      <td>-0.459310</td>\n",
       "      <td>-0.055432</td>\n",
       "      <td>-0.565070</td>\n",
       "      <td>0.167970</td>\n",
       "      <td>-0.813500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21089 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    miw_0     miw_1     miw_2     miw_3     miw_4    miw_5  \\\n",
       "0          0  1.14600  0.329100  0.268780 -1.394500 -0.300440  0.77901   \n",
       "1          1 -0.73473  0.120720  0.607640 -0.504740 -0.057365  0.52869   \n",
       "2          2  0.07785  0.065545 -0.349580 -0.378050  0.873780  0.24333   \n",
       "3          3  0.70687  0.277370  0.291350 -0.326550  0.538730 -0.65520   \n",
       "4          4  0.30963 -0.206810 -0.041067 -0.149900  0.843800  0.64058   \n",
       "...      ...      ...       ...       ...       ...       ...      ...   \n",
       "10539  21084 -0.52575 -0.229000  0.317210  1.120200 -0.113580  0.43399   \n",
       "10540  21085 -1.45320  0.255940  0.081679  0.490810 -0.059128  0.63656   \n",
       "10541  21086 -0.49515  1.283500 -1.236000  0.708940  0.295160 -0.48593   \n",
       "10542  21087  0.85912 -0.573080  1.341200  0.021117  0.516680 -0.37890   \n",
       "10543  21088  1.36160 -0.125140  0.617700  0.632880  0.316220 -1.20730   \n",
       "\n",
       "         miw_6     miw_7     miw_8  ...    miw_15   miw_16    miw_17  \\\n",
       "0      1.35370  0.373930  0.504780  ...  0.102870 -0.17618 -1.288100   \n",
       "1      0.59001 -0.237530  1.140600  ... -0.034995  0.10252  0.021756   \n",
       "2      1.49570 -0.562600  0.070204  ...  0.355000  0.16465  0.320060   \n",
       "3      1.35720 -0.252000 -0.316420  ... -0.149920  0.71925 -0.162080   \n",
       "4     -0.54087  0.055304  1.194000  ...  0.394530  0.79590  0.501160   \n",
       "...        ...       ...       ...  ...       ...      ...       ...   \n",
       "10539  0.94626 -1.406300  0.277020  ... -0.432380  1.08140 -0.507060   \n",
       "10540  1.45660 -1.060700  0.479030  ... -0.509060  1.24320 -0.541210   \n",
       "10541  0.55181 -1.055300 -0.291370  ...  0.068498  0.51722 -0.204610   \n",
       "10542  0.11455 -0.635790 -0.581480  ...  1.098900  0.28815 -0.689680   \n",
       "10543  0.69181 -1.737500 -0.789500  ...  0.314630  0.89104  0.619370   \n",
       "\n",
       "         miw_18    miw_19    miw_20    miw_21    miw_22    miw_23    miw_24  \n",
       "0     -0.598010  0.261310 -1.261900  0.392020  0.593090 -0.552320  0.005087  \n",
       "1     -0.308370  0.430040  0.002524 -0.504040  0.230500 -1.449700  0.589240  \n",
       "2     -0.045544 -0.319110 -1.013800 -0.054359  0.200740  0.320610 -0.455840  \n",
       "3      0.623380  0.380480 -0.045843  0.478960 -0.523910 -0.798070  0.278350  \n",
       "4      0.056856  1.026600 -0.793950 -0.804790  1.111700  0.013755 -0.244400  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "10539  0.429500  0.373860 -0.675640  0.441460  0.082967  1.074900  0.846170  \n",
       "10540  0.193750  0.357030 -0.988500 -0.693350 -0.339980  0.718270  1.070400  \n",
       "10541  0.794370 -0.696780 -0.945340 -0.336830 -0.805960  0.542580 -0.736610  \n",
       "10542  0.233150  0.089295 -0.993910 -0.822220 -0.341300 -0.357680 -0.550620  \n",
       "10543 -0.228900  0.343050 -0.459310 -0.055432 -0.565070  0.167970 -0.813500  \n",
       "\n",
       "[21089 rows x 26 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miw_df = extract_most_informative_word(all_df_new)\n",
    "miw_df = add_wordvec(miw_df)\n",
    "miw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "miw_df.to_csv('data/miw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_minimal_tfidf(df_origin, num_features):\n",
    "    df = df_origin.copy()\n",
    "    Ngram = 1 if num_features <= 1000 else 2\n",
    "    vectorizer = TfidfVectorizer(\n",
    "                                 ngram_range=(1,Ngram),\n",
    "                                max_features=num_features,\n",
    "                                )\n",
    "    ids = [n for n in range(len(df))]\n",
    "    minimal_tfidf = pd.DataFrame({\"id\": ids})\n",
    "    for category2 in df.category2.unique():\n",
    "        mini_df = df[df[\"category2\"] == category2]\n",
    "        X = vectorizer.fit_transform(mini_df.html_raw)\n",
    "        matrix = vectorizer.transform(df.html_raw)\n",
    "        columns = [f\"tfidf_{category2}_{n}\" for n in range(num_features)]\n",
    "        feature_df = pd.DataFrame.sparse.from_spmatrix(data=matrix, columns=columns)\n",
    "        ids = mini_df[\"id\"]\n",
    "        feature_df[\"id\"] = ids\n",
    "        \n",
    "        minimal_tfidf = pd.merge(minimal_tfidf, feature_df, on=\"id\", how=\"outer\")\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
