{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna.integration.lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_new = pd.read_csv('data/all_nlp_preprocessed.csv')\n",
    "bert_embeded = pd.read_csv('kaggle-notebook/data/bert_embeded_pretrained_cat2.csv')\n",
    "tfidf_500 = pd.read_csv('data/tfidf_500.csv')\n",
    "tfidf_1000 = pd.read_csv('data/tfidf_1000.csv')\n",
    "tfidf_2000 = pd.read_csv('data/tfidf_2000.csv')\n",
    "mfw_df = pd.read_csv('data/mfw.csv')\n",
    "miw_df = pd.read_csv('data/miw.csv')\n",
    "sub = pd.read_csv('data/sample_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_new = pd.merge(all_new, bert_embeded, on=\"id\", how='outer')\n",
    "all_new = pd.merge(all_new, tfidf_1000, on=\"id\", how=\"outer\")\n",
    "#all_new = pd.merge(all_new, mfw_df, on=\"id\", how=\"outer\")\n",
    "all_new = pd.merge(all_new, miw_df, on=\"id\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_new[[f\"{n+50}\" for n in range(25)]] = np.array(all_new[[f\"{n}\" for n in range(25)]]) + np.array(all_new[[f\"{n+25}\" for n in range(25)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tag_set(df):\n",
    "    tags = set()\n",
    "    for compiled_html_text in df.html_compiled:\n",
    "        tags |= set(extract_html_tag(compiled_html_text))\n",
    "    return tags\n",
    "\n",
    "\n",
    "def extract_html_tag(html_text):\n",
    "    tag_list = re.findall(r\"<.*?>\", html_text)\n",
    "    return tag_list\n",
    "\n",
    "\n",
    "def remove_endtag(tagset):\n",
    "    taglist = list(tagset)\n",
    "    tags = set()\n",
    "    for tag in taglist:\n",
    "        if tag != \"</animate>\":\n",
    "            tag = tag.replace(\"</\", \"<\")\n",
    "        tags.add(tag)\n",
    "    return tags\n",
    "\n",
    "def get_tag_collumns(tagset):\n",
    "    columns = []\n",
    "    for tag in tagset:\n",
    "        columns.append(f\"number_of_{tag}\")\n",
    "    return columns\n",
    "    \n",
    "ALL_TAGS = make_tag_set(all_new)\n",
    "ALL_TAGS = remove_endtag(ALL_TAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pair(candidates):\n",
    "    pairs = []\n",
    "    N = len(candidates)\n",
    "    for n, first in enumerate(candidates):\n",
    "        for k in range(n+1,N):\n",
    "            second = candidates[k]\n",
    "            pairs.append([first, second])\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def get_div_columns(pairs):\n",
    "    columns = []\n",
    "    for pair in pairs:\n",
    "        columnA, columnB = pair\n",
    "        columns.append(f'{columnA.split(\"_\")[-1]}_per_{columnB.split(\"_\")[-1]}')\n",
    "    return columns\n",
    "\n",
    "candidates = [\"goal_min\",\n",
    "                  \"number_of_word\",\n",
    "                  \"duration\",\n",
    "                  \"number_of_sentence\",\n",
    "                  \"number_of_<p>\",\n",
    "                  \"number_of_<figure>\",]\n",
    "div_tuples = make_pair(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 + 25 + 25 + 32 + 15 + 1000 + 25 = 1128\n"
     ]
    }
   ],
   "source": [
    "TARGET_COLS = [\"state\"]\n",
    "CATEGORICAL_COLS = ['country', \"category1\"]\n",
    "categ1_cols = [f\"{n+25}\" for n in range(25)]\n",
    "categ2_cols = [f\"{n}\" for n in range(25)]\n",
    "categ1_2_cols = [f\"{n+50}\" for n in range(25)]\n",
    "bert_cols = [f\"bert_{n}\" for n in range(768)]\n",
    "tfidf_cols = tfidf_1000.columns.drop(\"id\")\n",
    "mfw_cols = [f\"wordvec_{n}\" for n in range(25)]\n",
    "tag_cols = get_tag_collumns(ALL_TAGS)\n",
    "div_cols = get_div_columns(div_tuples)\n",
    "\n",
    "FEATURE_COLS = [\n",
    " 'country',\n",
    " 'duration',\n",
    " 'category1',\n",
    " 'goal_min',\n",
    " 'number_of_word',\n",
    " 'number_of_sentence',\n",
    "]\n",
    "\n",
    "FEATURE_COLS.extend(categ2_cols)\n",
    "FEATURE_COLS.extend(categ1_2_cols)\n",
    "#FEATURE_COLS.extend(bert_cols)\n",
    "FEATURE_COLS.extend(tag_cols)\n",
    "FEATURE_COLS.extend(div_cols)\n",
    "FEATURE_COLS.extend(tfidf_cols)\n",
    "FEATURE_COLS.extend(mfw_cols)\n",
    "print(f\"{6} + {len(categ2_cols)} + {len(categ1_2_cols)} + {len(tag_cols)} + {len(div_cols)} + {len(tfidf_cols)} + {len(mfw_cols)} = {len(FEATURE_COLS)}\")\n",
    "\n",
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = all_new[all_new[\"data_type\"] == \"test\"]\n",
    "train_set = all_new[all_new[\"data_type\"] == \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_null_optuna_lgbm(train, target_cols, feature_cols, categorical_cols):\n",
    "    \"\"\"\n",
    "    import optuna.integration.lightgbm as lgb\n",
    "    \"\"\"\n",
    "    X_train = train[feature_cols]\n",
    "    y_train = train[target_cols]\n",
    "    #X_test = test[feature_cols]\n",
    "    \n",
    "    #y_preds = []\n",
    "    #models = []\n",
    "    #oof_train = np.zeros((len(X_train),))\n",
    "    importances = []\n",
    "    \n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    for fold_id, (train_index, valid_index) in enumerate(cv.split(X_train)):\n",
    "        X_tr = X_train.loc[train_index, :]\n",
    "        X_val = X_train.loc[valid_index, :]\n",
    "        \n",
    "        # null target\n",
    "        y_tr = np.array(y_train.loc[train_index]).squeeze()\n",
    "        y_val = np.array(y_train.loc[valid_index]).squeeze()\n",
    "        random.shuffle(y_tr)\n",
    "        random.shuffle(y_val)\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_tr,\n",
    "                                y_tr,\n",
    "                                categorical_feature=categorical_cols)\n",
    "\n",
    "        lgb_eval = lgb.Dataset(X_val,\n",
    "                               y_val,\n",
    "                               reference=lgb_train,\n",
    "                               categorical_feature=categorical_cols)\n",
    "        \n",
    "        model = lgb.train(params,\n",
    "                          lgb_train,\n",
    "                          valid_sets=[lgb_train, lgb_eval],\n",
    "                          verbose_eval=False,\n",
    "                          num_boost_round=1000,\n",
    "                          early_stopping_rounds=5,\n",
    "                          )\n",
    "        \n",
    "        \"\"\"\n",
    "        oof_train[valid_index] = model.predict(X_val,\n",
    "                                               num_iteration=model.best_iteration)\n",
    "        y_pred = model.predict(X_test,\n",
    "                               num_iteration=model.best_iteration)\n",
    "\n",
    "        y_preds.append(y_pred)\n",
    "        models.append(model)\n",
    "        \"\"\"\n",
    "        \n",
    "        # display importance\n",
    "        importance = pd.DataFrame(model.feature_importance(), index=feature_cols, columns=['importance'])\n",
    "        importance = importance.sort_values(\"importance\")\n",
    "        display(importance)\n",
    "        importances.append(importance)\n",
    "\n",
    "    #return oof_train, sum(y_preds) / len(y_preds), importances\n",
    "    return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null_importances(num_iteration=10):\n",
    "    feature_cols = FEATURE_COLS\n",
    "    categorical_cols = CATEGORICAL_COLS\n",
    "    target_cols = TARGET_COLS\n",
    "    \n",
    "    null_importances = []\n",
    "    for n in range(num_iteration):\n",
    "        importances = run_null_optuna_lgbm(train_set, target_cols, feature_cols, categorical_cols)\n",
    "        null_importances.extend(importances)\n",
    "    return null_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:40:03,977]\u001b[0m A new study created in memory with name: no-name-8786cb2f-9f44-44d7-9c13-aeab629d8256\u001b[0m\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.693474:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.693474:  14%|#4        | 1/7 [00:00<00:02,  2.05it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:04,472]\u001b[0m Trial 0 finished with value: 0.6934736127804769 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.6934736127804769.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.693474:  14%|#4        | 1/7 [00:00<00:02,  2.05it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.693383:  14%|#4        | 1/7 [00:00<00:02,  2.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.693383:  29%|##8       | 2/7 [00:00<00:02,  2.02it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:04,983]\u001b[0m Trial 1 finished with value: 0.6933833587904045 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.6933833587904045.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.693383:  29%|##8       | 2/7 [00:01<00:02,  2.02it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692468:  29%|##8       | 2/7 [00:01<00:02,  2.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.692468:  43%|####2     | 3/7 [00:01<00:02,  1.92it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:05,568]\u001b[0m Trial 2 finished with value: 0.692468085345172 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 0.692468085345172.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692468:  43%|####2     | 3/7 [00:01<00:02,  1.92it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692468:  43%|####2     | 3/7 [00:02<00:02,  1.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.692468:  57%|#####7    | 4/7 [00:02<00:01,  1.86it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:06,147]\u001b[0m Trial 3 finished with value: 0.6929317730351847 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 0.692468085345172.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692468:  57%|#####7    | 4/7 [00:02<00:01,  1.86it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692468:  57%|#####7    | 4/7 [00:02<00:01,  1.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.692468:  71%|#######1  | 5/7 [00:02<00:01,  1.87it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:06,670]\u001b[0m Trial 4 finished with value: 0.6936123930433927 and parameters: {'feature_fraction': 1.0}. Best is trial 2 with value: 0.692468085345172.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692468:  71%|#######1  | 5/7 [00:02<00:01,  1.87it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692468:  71%|#######1  | 5/7 [00:03<00:01,  1.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.692468:  86%|########5 | 6/7 [00:03<00:00,  1.91it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:07,171]\u001b[0m Trial 5 finished with value: 0.6927230779272351 and parameters: {'feature_fraction': 0.8}. Best is trial 2 with value: 0.692468085345172.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692468:  86%|########5 | 6/7 [00:03<00:00,  1.91it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692468:  86%|########5 | 6/7 [00:03<00:00,  1.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.692468: 100%|##########| 7/7 [00:03<00:00,  1.93it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:07,673]\u001b[0m Trial 6 finished with value: 0.693401748249397 and parameters: {'feature_fraction': 0.6}. Best is trial 2 with value: 0.692468085345172.\u001b[0m\n",
      "feature_fraction, val_score: 0.692468: 100%|##########| 7/7 [00:03<00:00,  1.89it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692468:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692468:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692468:   5%|5         | 1/20 [00:00<00:15,  1.23it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:08,495]\u001b[0m Trial 7 finished with value: 0.6925997351105058 and parameters: {'num_leaves': 116}. Best is trial 7 with value: 0.6925997351105058.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692468:   5%|5         | 1/20 [00:00<00:15,  1.23it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692136:   5%|5         | 1/20 [00:01<00:15,  1.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692136:  10%|#         | 2/20 [00:01<00:14,  1.27it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:09,228]\u001b[0m Trial 8 finished with value: 0.6921359827596277 and parameters: {'num_leaves': 43}. Best is trial 8 with value: 0.6921359827596277.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692136:  10%|#         | 2/20 [00:01<00:14,  1.27it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692136:  10%|#         | 2/20 [00:02<00:14,  1.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692136:  15%|#5        | 3/20 [00:02<00:14,  1.19it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:10,193]\u001b[0m Trial 9 finished with value: 0.6937281044434332 and parameters: {'num_leaves': 184}. Best is trial 8 with value: 0.6921359827596277.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692136:  15%|#5        | 3/20 [00:02<00:14,  1.19it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692136:  15%|#5        | 3/20 [00:03<00:14,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692136:  20%|##        | 4/20 [00:03<00:12,  1.32it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:10,762]\u001b[0m Trial 10 finished with value: 0.6929740027395588 and parameters: {'num_leaves': 6}. Best is trial 8 with value: 0.6921359827596277.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692136:  20%|##        | 4/20 [00:03<00:12,  1.32it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692136:  20%|##        | 4/20 [00:03<00:12,  1.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692136:  25%|##5       | 5/20 [00:03<00:10,  1.42it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:11,332]\u001b[0m Trial 11 finished with value: 0.6927145887472045 and parameters: {'num_leaves': 18}. Best is trial 8 with value: 0.6921359827596277.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692136:  25%|##5       | 5/20 [00:03<00:10,  1.42it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692136:  25%|##5       | 5/20 [00:04<00:10,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692136:  30%|###       | 6/20 [00:04<00:09,  1.42it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:12,032]\u001b[0m Trial 12 finished with value: 0.6927279843039281 and parameters: {'num_leaves': 84}. Best is trial 8 with value: 0.6921359827596277.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692136:  30%|###       | 6/20 [00:04<00:09,  1.42it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692136:  30%|###       | 6/20 [00:05<00:09,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692136:  35%|###5      | 7/20 [00:05<00:09,  1.41it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:40:12,766]\u001b[0m Trial 13 finished with value: 0.6922789177351605 and parameters: {'num_leaves': 58}. Best is trial 8 with value: 0.6921359827596277.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692136:  35%|###5      | 7/20 [00:05<00:09,  1.41it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  35%|###5      | 7/20 [00:05<00:09,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.691919:  40%|####      | 8/20 [00:05<00:08,  1.46it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:13,384]\u001b[0m Trial 14 finished with value: 0.691918756316588 and parameters: {'num_leaves': 47}. Best is trial 14 with value: 0.691918756316588.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  40%|####      | 8/20 [00:05<00:08,  1.46it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  40%|####      | 8/20 [00:06<00:08,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.691919:  45%|####5     | 9/20 [00:06<00:07,  1.51it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:13,999]\u001b[0m Trial 15 finished with value: 0.6921780203849182 and parameters: {'num_leaves': 42}. Best is trial 14 with value: 0.691918756316588.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  45%|####5     | 9/20 [00:06<00:07,  1.51it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  45%|####5     | 9/20 [00:07<00:07,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.691919:  50%|#####     | 10/20 [00:07<00:07,  1.37it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:14,888]\u001b[0m Trial 16 finished with value: 0.6932418975136552 and parameters: {'num_leaves': 160}. Best is trial 14 with value: 0.691918756316588.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  50%|#####     | 10/20 [00:07<00:07,  1.37it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  50%|#####     | 10/20 [00:08<00:07,  1.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.691919:  55%|#####5    | 11/20 [00:08<00:07,  1.20it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:15,951]\u001b[0m Trial 17 finished with value: 0.6942148246148109 and parameters: {'num_leaves': 231}. Best is trial 14 with value: 0.691918756316588.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  55%|#####5    | 11/20 [00:08<00:07,  1.20it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  55%|#####5    | 11/20 [00:09<00:07,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.691919:  60%|######    | 12/20 [00:09<00:06,  1.24it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:16,699]\u001b[0m Trial 18 finished with value: 0.6926536774995506 and parameters: {'num_leaves': 88}. Best is trial 14 with value: 0.691918756316588.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  60%|######    | 12/20 [00:09<00:06,  1.24it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  60%|######    | 12/20 [00:09<00:06,  1.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.691919:  65%|######5   | 13/20 [00:09<00:05,  1.39it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:17,212]\u001b[0m Trial 19 finished with value: 0.6932146431657685 and parameters: {'num_leaves': 4}. Best is trial 14 with value: 0.691918756316588.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  65%|######5   | 13/20 [00:09<00:05,  1.39it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  65%|######5   | 13/20 [00:10<00:05,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.691919:  70%|#######   | 14/20 [00:10<00:04,  1.42it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:17,890]\u001b[0m Trial 20 finished with value: 0.6922320588319364 and parameters: {'num_leaves': 54}. Best is trial 14 with value: 0.691918756316588.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  70%|#######   | 14/20 [00:10<00:04,  1.42it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  70%|#######   | 14/20 [00:10<00:04,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.691919:  75%|#######5  | 15/20 [00:10<00:03,  1.50it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:18,471]\u001b[0m Trial 21 finished with value: 0.6924355245300754 and parameters: {'num_leaves': 37}. Best is trial 14 with value: 0.691918756316588.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  75%|#######5  | 15/20 [00:10<00:03,  1.50it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  75%|#######5  | 15/20 [00:11<00:03,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.691919:  80%|########  | 16/20 [00:11<00:02,  1.36it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:19,369]\u001b[0m Trial 22 finished with value: 0.6923062023786553 and parameters: {'num_leaves': 78}. Best is trial 14 with value: 0.691918756316588.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  80%|########  | 16/20 [00:11<00:02,  1.36it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  80%|########  | 16/20 [00:12<00:02,  1.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.691919:  85%|########5 | 17/20 [00:12<00:02,  1.41it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:20,005]\u001b[0m Trial 23 finished with value: 0.6924355245300755 and parameters: {'num_leaves': 37}. Best is trial 14 with value: 0.691918756316588.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  85%|########5 | 17/20 [00:12<00:02,  1.41it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  85%|########5 | 17/20 [00:13<00:02,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.691919:  90%|######### | 18/20 [00:13<00:01,  1.36it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:20,810]\u001b[0m Trial 24 finished with value: 0.6926438315085822 and parameters: {'num_leaves': 115}. Best is trial 14 with value: 0.691918756316588.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  90%|######### | 18/20 [00:13<00:01,  1.36it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  90%|######### | 18/20 [00:13<00:01,  1.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.691919:  95%|#########5| 19/20 [00:13<00:00,  1.45it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:21,392]\u001b[0m Trial 25 finished with value: 0.6924334806057225 and parameters: {'num_leaves': 30}. Best is trial 14 with value: 0.691918756316588.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  95%|#########5| 19/20 [00:13<00:00,  1.45it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.691919:  95%|#########5| 19/20 [00:14<00:00,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.691919: 100%|##########| 20/20 [00:14<00:00,  1.38it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:22,191]\u001b[0m Trial 26 finished with value: 0.6919900654468475 and parameters: {'num_leaves': 63}. Best is trial 14 with value: 0.691918756316588.\u001b[0m\n",
      "num_leaves, val_score: 0.691919: 100%|##########| 20/20 [00:14<00:00,  1.38it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.691919:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.691919:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.691919:  10%|#         | 1/10 [00:00<00:05,  1.69it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:22,793]\u001b[0m Trial 27 finished with value: 0.6939248477969392 and parameters: {'bagging_fraction': 0.43134304844324595, 'bagging_freq': 5}. Best is trial 27 with value: 0.6939248477969392.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  10%|#         | 1/10 [00:00<00:05,  1.69it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  10%|#         | 1/10 [00:01<00:05,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.691919:  20%|##        | 2/10 [00:01<00:04,  1.62it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:23,472]\u001b[0m Trial 28 finished with value: 0.6934706066216649 and parameters: {'bagging_fraction': 0.9708217980764361, 'bagging_freq': 1}. Best is trial 28 with value: 0.6934706066216649.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  20%|##        | 2/10 [00:01<00:04,  1.62it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  20%|##        | 2/10 [00:01<00:04,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.691919:  30%|###       | 3/10 [00:01<00:04,  1.59it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:24,124]\u001b[0m Trial 29 finished with value: 0.6931507974816065 and parameters: {'bagging_fraction': 0.7020413972138473, 'bagging_freq': 7}. Best is trial 29 with value: 0.6931507974816065.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  30%|###       | 3/10 [00:01<00:04,  1.59it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  30%|###       | 3/10 [00:02<00:04,  1.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.691919:  40%|####      | 4/10 [00:02<00:03,  1.62it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:24,717]\u001b[0m Trial 30 finished with value: 0.694060900821261 and parameters: {'bagging_fraction': 0.42896636530203813, 'bagging_freq': 1}. Best is trial 29 with value: 0.6931507974816065.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  40%|####      | 4/10 [00:02<00:03,  1.62it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  40%|####      | 4/10 [00:03<00:03,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.691919:  50%|#####     | 5/10 [00:03<00:03,  1.62it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:25,336]\u001b[0m Trial 31 finished with value: 0.6929313804598757 and parameters: {'bagging_fraction': 0.9841712258134216, 'bagging_freq': 4}. Best is trial 31 with value: 0.6929313804598757.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  50%|#####     | 5/10 [00:03<00:03,  1.62it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  50%|#####     | 5/10 [00:03<00:03,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.691919:  60%|######    | 6/10 [00:03<00:02,  1.64it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:25,930]\u001b[0m Trial 32 finished with value: 0.6940286933263521 and parameters: {'bagging_fraction': 0.7241810128975851, 'bagging_freq': 7}. Best is trial 31 with value: 0.6929313804598757.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  60%|######    | 6/10 [00:03<00:02,  1.64it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  60%|######    | 6/10 [00:04<00:02,  1.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.691919:  70%|#######   | 7/10 [00:04<00:01,  1.61it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:26,575]\u001b[0m Trial 33 finished with value: 0.692939946854079 and parameters: {'bagging_fraction': 0.8478683413256012, 'bagging_freq': 2}. Best is trial 31 with value: 0.6929313804598757.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  70%|#######   | 7/10 [00:04<00:01,  1.61it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  70%|#######   | 7/10 [00:04<00:01,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.691919:  80%|########  | 8/10 [00:04<00:01,  1.63it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:27,167]\u001b[0m Trial 34 finished with value: 0.692994377856147 and parameters: {'bagging_fraction': 0.5572430285932344, 'bagging_freq': 3}. Best is trial 31 with value: 0.6929313804598757.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  80%|########  | 8/10 [00:04<00:01,  1.63it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  80%|########  | 8/10 [00:05<00:01,  1.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.691919:  90%|######### | 9/10 [00:05<00:00,  1.65it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:27,763]\u001b[0m Trial 35 finished with value: 0.6932595221351304 and parameters: {'bagging_fraction': 0.5653930181837683, 'bagging_freq': 5}. Best is trial 31 with value: 0.6929313804598757.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  90%|######### | 9/10 [00:05<00:00,  1.65it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.691919:  90%|######### | 9/10 [00:06<00:00,  1.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.691919: 100%|##########| 10/10 [00:06<00:00,  1.65it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:28,371]\u001b[0m Trial 36 finished with value: 0.6943425274076956 and parameters: {'bagging_fraction': 0.8379757553480309, 'bagging_freq': 6}. Best is trial 31 with value: 0.6929313804598757.\u001b[0m\n",
      "bagging, val_score: 0.691919: 100%|##########| 10/10 [00:06<00:00,  1.62it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:  17%|#6        | 1/6 [00:00<00:03,  1.66it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:28,981]\u001b[0m Trial 37 finished with value: 0.6933809234874665 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 37 with value: 0.6933809234874665.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:  17%|#6        | 1/6 [00:00<00:03,  1.66it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:  17%|#6        | 1/6 [00:01<00:03,  1.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:  33%|###3      | 2/6 [00:01<00:02,  1.55it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:29,722]\u001b[0m Trial 38 finished with value: 0.6931514706383249 and parameters: {'feature_fraction': 0.652}. Best is trial 38 with value: 0.6931514706383249.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:  33%|###3      | 2/6 [00:01<00:02,  1.55it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:  33%|###3      | 2/6 [00:02<00:02,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:  50%|#####     | 3/6 [00:02<00:02,  1.45it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:40:30,513]\u001b[0m Trial 39 finished with value: 0.6932121963163549 and parameters: {'feature_fraction': 0.62}. Best is trial 38 with value: 0.6931514706383249.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:  50%|#####     | 3/6 [00:02<00:02,  1.45it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:  50%|#####     | 3/6 [00:02<00:02,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:  67%|######6   | 4/6 [00:02<00:01,  1.51it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:31,120]\u001b[0m Trial 40 finished with value: 0.6923348782383607 and parameters: {'feature_fraction': 0.716}. Best is trial 40 with value: 0.6923348782383607.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:  67%|######6   | 4/6 [00:02<00:01,  1.51it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:  67%|######6   | 4/6 [00:03<00:01,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:  83%|########3 | 5/6 [00:03<00:00,  1.46it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:31,855]\u001b[0m Trial 41 finished with value: 0.6926029287728983 and parameters: {'feature_fraction': 0.748}. Best is trial 40 with value: 0.6923348782383607.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:  83%|########3 | 5/6 [00:03<00:00,  1.46it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919:  83%|########3 | 5/6 [00:04<00:00,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.691919: 100%|##########| 6/6 [00:04<00:00,  1.50it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:32,478]\u001b[0m Trial 42 finished with value: 0.6920899548269931 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 42 with value: 0.6920899548269931.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.691919: 100%|##########| 6/6 [00:04<00:00,  1.46it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:   5%|5         | 1/20 [00:00<00:12,  1.54it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:33,138]\u001b[0m Trial 43 finished with value: 0.6919187588697477 and parameters: {'lambda_l1': 5.4419162562790245e-06, 'lambda_l2': 3.937158958233508e-05}. Best is trial 43 with value: 0.6919187588697477.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:   5%|5         | 1/20 [00:00<00:12,  1.54it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:   5%|5         | 1/20 [00:01<00:12,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  10%|#         | 2/20 [00:01<00:11,  1.55it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:33,775]\u001b[0m Trial 44 finished with value: 0.6919187592044914 and parameters: {'lambda_l1': 2.9563774234864016e-06, 'lambda_l2': 4.80026835020466e-05}. Best is trial 43 with value: 0.6919187588697477.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  10%|#         | 2/20 [00:01<00:11,  1.55it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  10%|#         | 2/20 [00:01<00:11,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  15%|#5        | 3/20 [00:01<00:10,  1.55it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:34,417]\u001b[0m Trial 45 finished with value: 0.6919187612391055 and parameters: {'lambda_l1': 3.4331315455230007e-06, 'lambda_l2': 8.352180056880941e-05}. Best is trial 43 with value: 0.6919187588697477.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  15%|#5        | 3/20 [00:01<00:10,  1.55it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  15%|#5        | 3/20 [00:02<00:10,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  20%|##        | 4/20 [00:02<00:10,  1.55it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:35,061]\u001b[0m Trial 46 finished with value: 0.6919187673517487 and parameters: {'lambda_l1': 2.966009446936206e-06, 'lambda_l2': 0.00019250804864698575}. Best is trial 43 with value: 0.6919187588697477.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  20%|##        | 4/20 [00:02<00:10,  1.55it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  20%|##        | 4/20 [00:03<00:10,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  25%|##5       | 5/20 [00:03<00:09,  1.53it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:35,740]\u001b[0m Trial 47 finished with value: 0.691918760855928 and parameters: {'lambda_l1': 2.497922189145173e-06, 'lambda_l2': 7.775840447229186e-05}. Best is trial 43 with value: 0.6919187588697477.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  25%|##5       | 5/20 [00:03<00:09,  1.53it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  25%|##5       | 5/20 [00:04<00:09,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  30%|###       | 6/20 [00:04<00:09,  1.42it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:36,563]\u001b[0m Trial 48 finished with value: 0.6919187592606206 and parameters: {'lambda_l1': 3.2532550172717142e-06, 'lambda_l2': 4.866636809452775e-05}. Best is trial 43 with value: 0.6919187588697477.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  30%|###       | 6/20 [00:04<00:09,  1.42it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  30%|###       | 6/20 [00:04<00:09,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  35%|###5      | 7/20 [00:04<00:09,  1.42it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:37,256]\u001b[0m Trial 49 finished with value: 0.6919187577087592 and parameters: {'lambda_l1': 3.489674164611078e-06, 'lambda_l2': 2.074103719046438e-05}. Best is trial 49 with value: 0.6919187577087592.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  35%|###5      | 7/20 [00:04<00:09,  1.42it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  35%|###5      | 7/20 [00:05<00:09,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  40%|####      | 8/20 [00:05<00:08,  1.45it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:37,911]\u001b[0m Trial 50 finished with value: 0.6919187570858814 and parameters: {'lambda_l1': 4.636583386476074e-06, 'lambda_l2': 8.444586161766668e-06}. Best is trial 50 with value: 0.6919187570858814.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  40%|####      | 8/20 [00:05<00:08,  1.45it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  40%|####      | 8/20 [00:06<00:08,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  45%|####5     | 9/20 [00:06<00:07,  1.48it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:38,563]\u001b[0m Trial 51 finished with value: 0.6919187570775519 and parameters: {'lambda_l1': 5.375129085323616e-06, 'lambda_l2': 7.430104336363313e-06}. Best is trial 51 with value: 0.6919187570775519.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  45%|####5     | 9/20 [00:06<00:07,  1.48it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  45%|####5     | 9/20 [00:06<00:07,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  50%|#####     | 10/20 [00:06<00:06,  1.49it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:39,214]\u001b[0m Trial 52 finished with value: 0.6919187569959766 and parameters: {'lambda_l1': 1.0337541095097134e-05, 'lambda_l2': 4.938787126084166e-07}. Best is trial 52 with value: 0.6919187569959766.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  50%|#####     | 10/20 [00:06<00:06,  1.49it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  50%|#####     | 10/20 [00:07<00:06,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  55%|#####5    | 11/20 [00:07<00:06,  1.40it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:40,036]\u001b[0m Trial 53 finished with value: 0.6919187981105088 and parameters: {'lambda_l1': 0.0006728919456720386, 'lambda_l2': 1.280175801409602e-08}. Best is trial 52 with value: 0.6919187569959766.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  55%|#####5    | 11/20 [00:07<00:06,  1.40it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  55%|#####5    | 11/20 [00:08<00:06,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  60%|######    | 12/20 [00:08<00:05,  1.44it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:40,679]\u001b[0m Trial 54 finished with value: 0.6919187582832931 and parameters: {'lambda_l1': 3.1494523850710504e-05, 'lambda_l2': 1.691229584151336e-07}. Best is trial 52 with value: 0.6919187569959766.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  60%|######    | 12/20 [00:08<00:05,  1.44it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  60%|######    | 12/20 [00:08<00:05,  1.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  65%|######5   | 13/20 [00:08<00:04,  1.43it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:41,391]\u001b[0m Trial 55 finished with value: 0.6919187653047798 and parameters: {'lambda_l1': 0.0001446787375890189, 'lambda_l2': 1.5587928317053236e-07}. Best is trial 52 with value: 0.6919187569959766.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  65%|######5   | 13/20 [00:08<00:04,  1.43it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  65%|######5   | 13/20 [00:09<00:04,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  70%|#######   | 14/20 [00:09<00:04,  1.43it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:42,091]\u001b[0m Trial 56 finished with value: 0.691918756351217 and parameters: {'lambda_l1': 3.612193148456089e-08, 'lambda_l2': 5.610036601694322e-07}. Best is trial 56 with value: 0.691918756351217.\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691919:  70%|#######   | 14/20 [00:09<00:04,  1.43it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  70%|#######   | 14/20 [00:10<00:04,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  75%|#######5  | 15/20 [00:10<00:03,  1.42it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:42,810]\u001b[0m Trial 57 finished with value: 0.6919187563763325 and parameters: {'lambda_l1': 1.2935308731893726e-08, 'lambda_l2': 1.0341666997214468e-06}. Best is trial 56 with value: 0.691918756351217.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  75%|#######5  | 15/20 [00:10<00:03,  1.42it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  75%|#######5  | 15/20 [00:11<00:03,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  80%|########  | 16/20 [00:11<00:02,  1.36it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:43,611]\u001b[0m Trial 58 finished with value: 0.691918756355785 and parameters: {'lambda_l1': 1.0336579944164923e-08, 'lambda_l2': 6.710037333131714e-07}. Best is trial 56 with value: 0.691918756351217.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  80%|########  | 16/20 [00:11<00:02,  1.36it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  80%|########  | 16/20 [00:11<00:02,  1.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  85%|########5 | 17/20 [00:11<00:02,  1.36it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:44,354]\u001b[0m Trial 59 finished with value: 0.6919187563507183 and parameters: {'lambda_l1': 1.2539736127469102e-08, 'lambda_l2': 5.782935241268126e-07}. Best is trial 59 with value: 0.6919187563507183.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  85%|########5 | 17/20 [00:11<00:02,  1.36it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  85%|########5 | 17/20 [00:12<00:02,  1.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  90%|######### | 18/20 [00:12<00:01,  1.36it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:45,079]\u001b[0m Trial 60 finished with value: 0.6919187563268588 and parameters: {'lambda_l1': 1.0462769879353281e-08, 'lambda_l2': 1.6401752206503103e-07}. Best is trial 60 with value: 0.6919187563268588.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  90%|######### | 18/20 [00:12<00:01,  1.36it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  90%|######### | 18/20 [00:13<00:01,  1.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  95%|#########5| 19/20 [00:13<00:00,  1.39it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:45,766]\u001b[0m Trial 61 finished with value: 0.6919187563407353 and parameters: {'lambda_l1': 1.2555339418970803e-08, 'lambda_l2': 4.0043176583742213e-07}. Best is trial 60 with value: 0.6919187563268588.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  95%|#########5| 19/20 [00:13<00:00,  1.39it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.691919:  95%|#########5| 19/20 [00:13<00:00,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.691919: 100%|##########| 20/20 [00:13<00:00,  1.42it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:46,428]\u001b[0m Trial 62 finished with value: 0.6919193215368757 and parameters: {'lambda_l1': 1.0587311935334422e-08, 'lambda_l2': 0.010032797101034737}. Best is trial 60 with value: 0.6919187563268588.\u001b[0m\n",
      "regularization_factors, val_score: 0.691919: 100%|##########| 20/20 [00:13<00:00,  1.43it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.691919:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.691919:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.691919:  20%|##        | 1/5 [00:00<00:02,  1.56it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:47,080]\u001b[0m Trial 63 finished with value: 0.6930113549233399 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.6930113549233399.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.691919:  20%|##        | 1/5 [00:00<00:02,  1.56it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.691919:  20%|##        | 1/5 [00:01<00:02,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.691919:  40%|####      | 2/5 [00:01<00:01,  1.57it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:47,710]\u001b[0m Trial 64 finished with value: 0.6927864044464275 and parameters: {'min_child_samples': 10}. Best is trial 64 with value: 0.6927864044464275.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.691919:  40%|####      | 2/5 [00:01<00:01,  1.57it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.691919:  40%|####      | 2/5 [00:01<00:01,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.691919:  60%|######    | 3/5 [00:01<00:01,  1.59it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:48,312]\u001b[0m Trial 65 finished with value: 0.6934743777752695 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 0.6927864044464275.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.691919:  60%|######    | 3/5 [00:01<00:01,  1.59it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.691919:  60%|######    | 3/5 [00:02<00:01,  1.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.691919:  80%|########  | 4/5 [00:02<00:00,  1.60it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:48,934]\u001b[0m Trial 66 finished with value: 0.6927467652502507 and parameters: {'min_child_samples': 5}. Best is trial 66 with value: 0.6927467652502507.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.691919:  80%|########  | 4/5 [00:02<00:00,  1.60it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164185\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.691919:  80%|########  | 4/5 [00:03<00:00,  1.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.691919: 100%|##########| 5/5 [00:03<00:00,  1.61it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:49,548]\u001b[0m Trial 67 finished with value: 0.6926951271483416 and parameters: {'min_child_samples': 50}. Best is trial 67 with value: 0.6926951271483416.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.691919: 100%|##########| 5/5 [00:03<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_paint</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_painting</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_paintings</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_paper</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_expand</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_idea</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_don</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_does</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_try</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 importance\n",
       "country                   0\n",
       "tfidf_paint               0\n",
       "tfidf_painting            0\n",
       "tfidf_paintings           0\n",
       "tfidf_paper               0\n",
       "...                     ...\n",
       "tfidf_expand              2\n",
       "tfidf_idea                2\n",
       "tfidf_don                 2\n",
       "tfidf_does                2\n",
       "tfidf_try                 2\n",
       "\n",
       "[1128 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:40:49,592]\u001b[0m A new study created in memory with name: no-name-69ba0b3f-5cba-4e60-86cb-6d85eeeb880a\u001b[0m\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.693188:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.693188:  14%|#4        | 1/7 [00:00<00:03,  1.62it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:50,219]\u001b[0m Trial 0 finished with value: 0.693187650752738 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.693187650752738.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.693188:  14%|#4        | 1/7 [00:00<00:03,  1.62it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692914:  14%|#4        | 1/7 [00:01<00:03,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.692914:  29%|##8       | 2/7 [00:01<00:03,  1.63it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:50,825]\u001b[0m Trial 1 finished with value: 0.6929144079090971 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.6929144079090971.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692914:  29%|##8       | 2/7 [00:01<00:03,  1.63it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692914:  29%|##8       | 2/7 [00:01<00:03,  1.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.692914:  43%|####2     | 3/7 [00:01<00:02,  1.64it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:51,429]\u001b[0m Trial 2 finished with value: 0.6929440803124072 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.6929144079090971.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692914:  43%|####2     | 3/7 [00:01<00:02,  1.64it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692914:  43%|####2     | 3/7 [00:02<00:02,  1.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.692914:  57%|#####7    | 4/7 [00:02<00:01,  1.69it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:51,971]\u001b[0m Trial 3 finished with value: 0.6939222598747707 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.6929144079090971.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692914:  57%|#####7    | 4/7 [00:02<00:01,  1.69it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692887:  57%|#####7    | 4/7 [00:02<00:01,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.692887:  71%|#######1  | 5/7 [00:02<00:01,  1.68it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:52,575]\u001b[0m Trial 4 finished with value: 0.6928866662094617 and parameters: {'feature_fraction': 1.0}. Best is trial 4 with value: 0.6928866662094617.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692887:  71%|#######1  | 5/7 [00:02<00:01,  1.68it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692887:  71%|#######1  | 5/7 [00:03<00:01,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.692887:  86%|########5 | 6/7 [00:03<00:00,  1.71it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:53,137]\u001b[0m Trial 5 finished with value: 0.6934988810947872 and parameters: {'feature_fraction': 0.6}. Best is trial 4 with value: 0.6928866662094617.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692887:  86%|########5 | 6/7 [00:03<00:00,  1.71it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692887:  86%|########5 | 6/7 [00:04<00:00,  1.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.692887: 100%|##########| 7/7 [00:04<00:00,  1.76it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:53,665]\u001b[0m Trial 6 finished with value: 0.6937274727224363 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 0.6928866662094617.\u001b[0m\n",
      "feature_fraction, val_score: 0.692887: 100%|##########| 7/7 [00:04<00:00,  1.72it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692887:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692887:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692887:   5%|5         | 1/20 [00:00<00:18,  1.01it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:54,669]\u001b[0m Trial 7 finished with value: 0.6945818580592645 and parameters: {'num_leaves': 243}. Best is trial 7 with value: 0.6945818580592645.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692887:   5%|5         | 1/20 [00:01<00:18,  1.01it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692887:   5%|5         | 1/20 [00:01<00:18,  1.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692887:  10%|#         | 2/20 [00:01<00:16,  1.07it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:55,467]\u001b[0m Trial 8 finished with value: 0.6932915199524265 and parameters: {'num_leaves': 113}. Best is trial 8 with value: 0.6932915199524265.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692887:  10%|#         | 2/20 [00:01<00:16,  1.07it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692887:  10%|#         | 2/20 [00:02<00:16,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692887:  15%|#5        | 3/20 [00:02<00:16,  1.05it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:56,452]\u001b[0m Trial 9 finished with value: 0.694487993514041 and parameters: {'num_leaves': 179}. Best is trial 8 with value: 0.6932915199524265.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692887:  15%|#5        | 3/20 [00:02<00:16,  1.05it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692702:  15%|#5        | 3/20 [00:03<00:16,  1.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692702:  20%|##        | 4/20 [00:03<00:13,  1.20it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:57,013]\u001b[0m Trial 10 finished with value: 0.692702161712744 and parameters: {'num_leaves': 2}. Best is trial 10 with value: 0.692702161712744.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692702:  20%|##        | 4/20 [00:03<00:13,  1.20it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692702:  20%|##        | 4/20 [00:03<00:13,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692702:  25%|##5       | 5/20 [00:03<00:11,  1.31it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:57,607]\u001b[0m Trial 11 finished with value: 0.6927252656843831 and parameters: {'num_leaves': 15}. Best is trial 10 with value: 0.692702161712744.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692702:  25%|##5       | 5/20 [00:03<00:11,  1.31it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692584:  25%|##5       | 5/20 [00:04<00:11,  1.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692584:  30%|###       | 6/20 [00:04<00:09,  1.44it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:58,145]\u001b[0m Trial 12 finished with value: 0.6925835576074074 and parameters: {'num_leaves': 6}. Best is trial 12 with value: 0.6925835576074074.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692584:  30%|###       | 6/20 [00:04<00:09,  1.44it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692584:  30%|###       | 6/20 [00:05<00:09,  1.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692584:  35%|###5      | 7/20 [00:05<00:08,  1.53it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:58,708]\u001b[0m Trial 13 finished with value: 0.6927021617127441 and parameters: {'num_leaves': 2}. Best is trial 12 with value: 0.6925835576074074.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692584:  35%|###5      | 7/20 [00:05<00:08,  1.53it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692584:  35%|###5      | 7/20 [00:05<00:08,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692584:  40%|####      | 8/20 [00:05<00:08,  1.48it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:59,436]\u001b[0m Trial 14 finished with value: 0.6933000028646181 and parameters: {'num_leaves': 58}. Best is trial 12 with value: 0.6925835576074074.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692584:  40%|####      | 8/20 [00:05<00:08,  1.48it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692584:  40%|####      | 8/20 [00:06<00:08,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692584:  45%|####5     | 9/20 [00:06<00:06,  1.57it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:40:59,975]\u001b[0m Trial 15 finished with value: 0.6926490853503124 and parameters: {'num_leaves': 3}. Best is trial 12 with value: 0.6925835576074074.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692584:  45%|####5     | 9/20 [00:06<00:06,  1.57it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  45%|####5     | 9/20 [00:07<00:06,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692582:  50%|#####     | 10/20 [00:07<00:06,  1.46it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:00,768]\u001b[0m Trial 16 finished with value: 0.6925821731656369 and parameters: {'num_leaves': 75}. Best is trial 16 with value: 0.6925821731656369.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  50%|#####     | 10/20 [00:07<00:06,  1.46it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  50%|#####     | 10/20 [00:07<00:06,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692582:  55%|#####5    | 11/20 [00:07<00:06,  1.40it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:01,555]\u001b[0m Trial 17 finished with value: 0.6935690393739904 and parameters: {'num_leaves': 79}. Best is trial 16 with value: 0.6925821731656369.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  55%|#####5    | 11/20 [00:07<00:06,  1.40it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  55%|#####5    | 11/20 [00:08<00:06,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692582:  60%|######    | 12/20 [00:08<00:05,  1.40it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:02,271]\u001b[0m Trial 18 finished with value: 0.6936884646242081 and parameters: {'num_leaves': 55}. Best is trial 16 with value: 0.6925821731656369.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  60%|######    | 12/20 [00:08<00:05,  1.40it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  60%|######    | 12/20 [00:09<00:05,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692582:  65%|######5   | 13/20 [00:09<00:05,  1.30it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:03,177]\u001b[0m Trial 19 finished with value: 0.6940585936304757 and parameters: {'num_leaves': 146}. Best is trial 16 with value: 0.6925821731656369.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  65%|######5   | 13/20 [00:09<00:05,  1.30it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  65%|######5   | 13/20 [00:10<00:05,  1.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692582:  70%|#######   | 14/20 [00:10<00:04,  1.28it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:03,989]\u001b[0m Trial 20 finished with value: 0.693270015691124 and parameters: {'num_leaves': 94}. Best is trial 16 with value: 0.6925821731656369.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  70%|#######   | 14/20 [00:10<00:04,  1.28it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  70%|#######   | 14/20 [00:10<00:04,  1.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692582:  75%|#######5  | 15/20 [00:10<00:03,  1.35it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:04,620]\u001b[0m Trial 21 finished with value: 0.6931120458451067 and parameters: {'num_leaves': 33}. Best is trial 16 with value: 0.6925821731656369.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  75%|#######5  | 15/20 [00:10<00:03,  1.35it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  75%|#######5  | 15/20 [00:11<00:03,  1.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692582:  80%|########  | 16/20 [00:11<00:02,  1.42it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:05,251]\u001b[0m Trial 22 finished with value: 0.6931117431124888 and parameters: {'num_leaves': 36}. Best is trial 16 with value: 0.6925821731656369.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  80%|########  | 16/20 [00:11<00:02,  1.42it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  80%|########  | 16/20 [00:12<00:02,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692582:  85%|########5 | 17/20 [00:12<00:01,  1.53it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:05,786]\u001b[0m Trial 23 finished with value: 0.6925835576074076 and parameters: {'num_leaves': 6}. Best is trial 16 with value: 0.6925821731656369.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  85%|########5 | 17/20 [00:12<00:01,  1.53it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  85%|########5 | 17/20 [00:13<00:01,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692582:  90%|######### | 18/20 [00:13<00:01,  1.35it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:06,728]\u001b[0m Trial 24 finished with value: 0.6940675892556691 and parameters: {'num_leaves': 152}. Best is trial 16 with value: 0.6925821731656369.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  90%|######### | 18/20 [00:13<00:01,  1.35it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  90%|######### | 18/20 [00:13<00:01,  1.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692582:  95%|#########5| 19/20 [00:13<00:00,  1.37it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:07,429]\u001b[0m Trial 25 finished with value: 0.6932690591068904 and parameters: {'num_leaves': 66}. Best is trial 16 with value: 0.6925821731656369.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  95%|#########5| 19/20 [00:13<00:00,  1.37it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.692582:  95%|#########5| 19/20 [00:14<00:00,  1.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.692582: 100%|##########| 20/20 [00:14<00:00,  1.44it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:08,044]\u001b[0m Trial 26 finished with value: 0.6928764310365002 and parameters: {'num_leaves': 29}. Best is trial 16 with value: 0.6925821731656369.\u001b[0m\n",
      "num_leaves, val_score: 0.692582: 100%|##########| 20/20 [00:14<00:00,  1.39it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.692582:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.692582:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.692582:  10%|#         | 1/10 [00:00<00:06,  1.44it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:08,748]\u001b[0m Trial 27 finished with value: 0.693066800253796 and parameters: {'bagging_fraction': 0.8863591875382575, 'bagging_freq': 6}. Best is trial 27 with value: 0.693066800253796.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  10%|#         | 1/10 [00:00<00:06,  1.44it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  10%|#         | 1/10 [00:01<00:06,  1.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.692582:  20%|##        | 2/10 [00:01<00:05,  1.44it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:09,435]\u001b[0m Trial 28 finished with value: 0.6942807550679055 and parameters: {'bagging_fraction': 0.43661920042304136, 'bagging_freq': 1}. Best is trial 27 with value: 0.693066800253796.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  20%|##        | 2/10 [00:01<00:05,  1.44it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  20%|##        | 2/10 [00:02<00:05,  1.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.692582:  30%|###       | 3/10 [00:02<00:04,  1.47it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:10,092]\u001b[0m Trial 29 finished with value: 0.6936490782767116 and parameters: {'bagging_fraction': 0.4086861016508453, 'bagging_freq': 1}. Best is trial 27 with value: 0.693066800253796.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  30%|###       | 3/10 [00:02<00:04,  1.47it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  30%|###       | 3/10 [00:02<00:04,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.692582:  40%|####      | 4/10 [00:02<00:04,  1.42it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:10,851]\u001b[0m Trial 30 finished with value: 0.6936674448061656 and parameters: {'bagging_fraction': 0.9958551295538398, 'bagging_freq': 7}. Best is trial 27 with value: 0.693066800253796.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  40%|####      | 4/10 [00:02<00:04,  1.42it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  40%|####      | 4/10 [00:03<00:04,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.692582:  50%|#####     | 5/10 [00:03<00:03,  1.44it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:11,523]\u001b[0m Trial 31 finished with value: 0.6933629322423681 and parameters: {'bagging_fraction': 0.679265578614589, 'bagging_freq': 4}. Best is trial 27 with value: 0.693066800253796.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  50%|#####     | 5/10 [00:03<00:03,  1.44it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  50%|#####     | 5/10 [00:04<00:03,  1.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.692582:  60%|######    | 6/10 [00:04<00:02,  1.44it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:12,220]\u001b[0m Trial 32 finished with value: 0.6929669105282549 and parameters: {'bagging_fraction': 0.6438606585806356, 'bagging_freq': 4}. Best is trial 32 with value: 0.6929669105282549.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  60%|######    | 6/10 [00:04<00:02,  1.44it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  60%|######    | 6/10 [00:04<00:02,  1.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.692582:  70%|#######   | 7/10 [00:04<00:02,  1.44it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:12,918]\u001b[0m Trial 33 finished with value: 0.6930115379880677 and parameters: {'bagging_fraction': 0.8451105286172975, 'bagging_freq': 2}. Best is trial 32 with value: 0.6929669105282549.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  70%|#######   | 7/10 [00:04<00:02,  1.44it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  70%|#######   | 7/10 [00:05<00:02,  1.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.692582:  80%|########  | 8/10 [00:05<00:01,  1.45it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:13,593]\u001b[0m Trial 34 finished with value: 0.6937540337863897 and parameters: {'bagging_fraction': 0.5326785777612668, 'bagging_freq': 6}. Best is trial 32 with value: 0.6929669105282549.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  80%|########  | 8/10 [00:05<00:01,  1.45it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  80%|########  | 8/10 [00:06<00:01,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.692582:  90%|######### | 9/10 [00:06<00:00,  1.45it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:14,281]\u001b[0m Trial 35 finished with value: 0.693374025716139 and parameters: {'bagging_fraction': 0.8223417059465876, 'bagging_freq': 3}. Best is trial 32 with value: 0.6929669105282549.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.692582:  90%|######### | 9/10 [00:06<00:00,  1.45it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.692459:  90%|######### | 9/10 [00:06<00:00,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.692459: 100%|##########| 10/10 [00:06<00:00,  1.45it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:14,965]\u001b[0m Trial 36 finished with value: 0.6924591543626517 and parameters: {'bagging_fraction': 0.5451219753450566, 'bagging_freq': 5}. Best is trial 36 with value: 0.6924591543626517.\u001b[0m\n",
      "bagging, val_score: 0.692459: 100%|##########| 10/10 [00:06<00:00,  1.45it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.692459:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.692459:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.692459:  33%|###3      | 1/3 [00:00<00:01,  1.51it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:15,636]\u001b[0m Trial 37 finished with value: 0.6924681265021069 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 37 with value: 0.6924681265021069.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.692459:  33%|###3      | 1/3 [00:00<00:01,  1.51it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.692120:  33%|###3      | 1/3 [00:01<00:01,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.692120:  67%|######6   | 2/3 [00:01<00:00,  1.51it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:16,302]\u001b[0m Trial 38 finished with value: 0.6921197523978846 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 38 with value: 0.6921197523978846.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.692120:  67%|######6   | 2/3 [00:01<00:00,  1.51it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.692120:  67%|######6   | 2/3 [00:02<00:00,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.692120: 100%|##########| 3/3 [00:02<00:00,  1.50it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:16,984]\u001b[0m Trial 39 finished with value: 0.6933170204618334 and parameters: {'feature_fraction': 0.92}. Best is trial 38 with value: 0.6921197523978846.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.692120: 100%|##########| 3/3 [00:02<00:00,  1.49it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692120:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692120:   5%|5         | 1/20 [00:00<00:13,  1.42it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:41:17,696]\u001b[0m Trial 40 finished with value: 0.6921197485831763 and parameters: {'lambda_l1': 1.3910814196027914e-05, 'lambda_l2': 0.0002313473419653273}. Best is trial 40 with value: 0.6921197485831763.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:   5%|5         | 1/20 [00:00<00:13,  1.42it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:   5%|5         | 1/20 [00:01<00:13,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  10%|#         | 2/20 [00:01<00:12,  1.41it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:18,412]\u001b[0m Trial 41 finished with value: 0.6921197480941741 and parameters: {'lambda_l1': 7.538107064461049e-06, 'lambda_l2': 0.00023872664530264756}. Best is trial 41 with value: 0.6921197480941741.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  10%|#         | 2/20 [00:01<00:12,  1.41it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  10%|#         | 2/20 [00:02<00:12,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  15%|#5        | 3/20 [00:02<00:12,  1.41it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:19,124]\u001b[0m Trial 42 finished with value: 0.692119751652883 and parameters: {'lambda_l1': 8.931527685345252e-06, 'lambda_l2': 6.214557287407697e-05}. Best is trial 41 with value: 0.6921197480941741.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  15%|#5        | 3/20 [00:02<00:12,  1.41it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  15%|#5        | 3/20 [00:02<00:12,  1.41it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  20%|##        | 4/20 [00:02<00:11,  1.40it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:19,849]\u001b[0m Trial 43 finished with value: 0.692119749742811 and parameters: {'lambda_l1': 6.419476390188733e-06, 'lambda_l2': 0.00015209496312829998}. Best is trial 41 with value: 0.6921197480941741.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  20%|##        | 4/20 [00:02<00:11,  1.40it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  20%|##        | 4/20 [00:03<00:11,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  25%|##5       | 5/20 [00:03<00:10,  1.41it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:20,552]\u001b[0m Trial 44 finished with value: 0.6921197506419923 and parameters: {'lambda_l1': 9.446203572471765e-06, 'lambda_l2': 0.00011478583939224883}. Best is trial 41 with value: 0.6921197480941741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  25%|##5       | 5/20 [00:03<00:10,  1.41it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  25%|##5       | 5/20 [00:04<00:10,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  30%|###       | 6/20 [00:04<00:10,  1.38it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:21,306]\u001b[0m Trial 45 finished with value: 0.6921197501831613 and parameters: {'lambda_l1': 6.703362313747597e-06, 'lambda_l2': 0.0001305499527487433}. Best is trial 41 with value: 0.6921197480941741.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  30%|###       | 6/20 [00:04<00:10,  1.38it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  30%|###       | 6/20 [00:05<00:10,  1.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  35%|###5      | 7/20 [00:05<00:09,  1.35it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:22,079]\u001b[0m Trial 46 finished with value: 0.6921197486768809 and parameters: {'lambda_l1': 6.5202386690857446e-06, 'lambda_l2': 0.0002064043698143583}. Best is trial 41 with value: 0.6921197480941741.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  35%|###5      | 7/20 [00:05<00:09,  1.35it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  35%|###5      | 7/20 [00:05<00:09,  1.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  40%|####      | 8/20 [00:05<00:08,  1.37it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:22,790]\u001b[0m Trial 47 finished with value: 0.6921197494416279 and parameters: {'lambda_l1': 5.851726993578305e-06, 'lambda_l2': 0.00016581091223874658}. Best is trial 41 with value: 0.6921197480941741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  40%|####      | 8/20 [00:05<00:08,  1.37it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  40%|####      | 8/20 [00:06<00:08,  1.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  45%|####5     | 9/20 [00:06<00:07,  1.38it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:23,506]\u001b[0m Trial 48 finished with value: 0.6921197430700811 and parameters: {'lambda_l1': 4.098982589213595e-06, 'lambda_l2': 0.0004841049137315549}. Best is trial 48 with value: 0.6921197430700811.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  45%|####5     | 9/20 [00:06<00:07,  1.38it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  45%|####5     | 9/20 [00:07<00:07,  1.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  50%|#####     | 10/20 [00:07<00:07,  1.38it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:41:24,225]\u001b[0m Trial 49 finished with value: 0.6921197068276195 and parameters: {'lambda_l1': 4.9721265183993575e-06, 'lambda_l2': 0.002328395393772755}. Best is trial 49 with value: 0.6921197068276195.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  50%|#####     | 10/20 [00:07<00:07,  1.38it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  50%|#####     | 10/20 [00:07<00:07,  1.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  55%|#####5    | 11/20 [00:07<00:06,  1.39it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:24,936]\u001b[0m Trial 50 finished with value: 0.692362725151704 and parameters: {'lambda_l1': 1.7486637326351915e-07, 'lambda_l2': 0.04002003312697456}. Best is trial 49 with value: 0.6921197068276195.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  55%|#####5    | 11/20 [00:07<00:06,  1.39it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  55%|#####5    | 11/20 [00:08<00:06,  1.39it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  60%|######    | 12/20 [00:08<00:05,  1.38it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:25,667]\u001b[0m Trial 51 finished with value: 0.6921196975887514 and parameters: {'lambda_l1': 7.613317366051885e-06, 'lambda_l2': 0.0028063241933793098}. Best is trial 51 with value: 0.6921196975887514.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  60%|######    | 12/20 [00:08<00:05,  1.38it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  60%|######    | 12/20 [00:09<00:05,  1.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  65%|######5   | 13/20 [00:09<00:05,  1.39it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:26,377]\u001b[0m Trial 52 finished with value: 0.6921195123249669 and parameters: {'lambda_l1': 8.838742492505498e-06, 'lambda_l2': 0.01234735653884891}. Best is trial 52 with value: 0.6921195123249669.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  65%|######5   | 13/20 [00:09<00:05,  1.39it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  65%|######5   | 13/20 [00:10<00:05,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  70%|#######   | 14/20 [00:10<00:04,  1.39it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:27,092]\u001b[0m Trial 53 finished with value: 0.6923626552055672 and parameters: {'lambda_l1': 0.0022567243330238332, 'lambda_l2': 0.043329256999127694}. Best is trial 52 with value: 0.6921195123249669.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  70%|#######   | 14/20 [00:10<00:04,  1.39it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  70%|#######   | 14/20 [00:10<00:04,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  75%|#######5  | 15/20 [00:10<00:03,  1.40it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:41:27,805]\u001b[0m Trial 54 finished with value: 0.6921195599698443 and parameters: {'lambda_l1': 7.691180149449985e-05, 'lambda_l2': 0.010066584552633165}. Best is trial 52 with value: 0.6921195123249669.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  75%|#######5  | 15/20 [00:10<00:03,  1.40it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  75%|#######5  | 15/20 [00:11<00:03,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  80%|########  | 16/20 [00:11<00:02,  1.40it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:28,509]\u001b[0m Trial 55 finished with value: 0.6921195550784196 and parameters: {'lambda_l1': 0.0002252925248050003, 'lambda_l2': 0.010735372765204995}. Best is trial 52 with value: 0.6921195123249669.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  80%|########  | 16/20 [00:11<00:02,  1.40it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  80%|########  | 16/20 [00:12<00:02,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  85%|########5 | 17/20 [00:12<00:02,  1.40it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:41:29,231]\u001b[0m Trial 56 finished with value: 0.6921196307725119 and parameters: {'lambda_l1': 0.000374403230347814, 'lambda_l2': 0.007242160081422396}. Best is trial 52 with value: 0.6921195123249669.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692120:  85%|########5 | 17/20 [00:12<00:02,  1.40it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692119:  85%|########5 | 17/20 [00:12<00:02,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692119:  90%|######### | 18/20 [00:12<00:01,  1.40it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:29,946]\u001b[0m Trial 57 finished with value: 0.6921194338199399 and parameters: {'lambda_l1': 0.00026123345647143724, 'lambda_l2': 0.01716506386261202}. Best is trial 57 with value: 0.6921194338199399.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692119:  90%|######### | 18/20 [00:12<00:01,  1.40it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692119:  90%|######### | 18/20 [00:13<00:01,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692119:  95%|#########5| 19/20 [00:13<00:00,  1.35it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:30,737]\u001b[0m Trial 58 finished with value: 0.6921195312151545 and parameters: {'lambda_l1': 0.00032631291536142147, 'lambda_l2': 0.012257962426078323}. Best is trial 57 with value: 0.6921194338199399.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692119:  95%|#########5| 19/20 [00:13<00:00,  1.35it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.692119:  95%|#########5| 19/20 [00:14<00:00,  1.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.692119: 100%|##########| 20/20 [00:14<00:00,  1.37it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:41:31,450]\u001b[0m Trial 59 finished with value: 0.6941859798635681 and parameters: {'lambda_l1': 0.0005039103507169789, 'lambda_l2': 1.2962991588157284}. Best is trial 57 with value: 0.6921194338199399.\u001b[0m\n",
      "regularization_factors, val_score: 0.692119: 100%|##########| 20/20 [00:14<00:00,  1.38it/s]\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.692119:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.692119:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.692119:  20%|##        | 1/5 [00:00<00:02,  1.47it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:32,139]\u001b[0m Trial 60 finished with value: 0.6935945827921928 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.6935945827921928.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.692119:  20%|##        | 1/5 [00:00<00:02,  1.47it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.692119:  20%|##        | 1/5 [00:01<00:02,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.692119:  40%|####      | 2/5 [00:01<00:02,  1.46it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:32,839]\u001b[0m Trial 61 finished with value: 0.6936586099892378 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.6935945827921928.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.692119:  40%|####      | 2/5 [00:01<00:02,  1.46it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.692119:  40%|####      | 2/5 [00:02<00:02,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.692119:  60%|######    | 3/5 [00:02<00:01,  1.41it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:33,602]\u001b[0m Trial 62 finished with value: 0.6927014304903992 and parameters: {'min_child_samples': 5}. Best is trial 62 with value: 0.6927014304903992.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.692119:  60%|######    | 3/5 [00:02<00:01,  1.41it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.692119:  60%|######    | 3/5 [00:02<00:01,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.692119:  80%|########  | 4/5 [00:02<00:00,  1.48it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:34,202]\u001b[0m Trial 63 finished with value: 0.6932432408909539 and parameters: {'min_child_samples': 100}. Best is trial 62 with value: 0.6927014304903992.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.692119:  80%|########  | 4/5 [00:02<00:00,  1.48it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164821\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.692119:  80%|########  | 4/5 [00:03<00:00,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.692119: 100%|##########| 5/5 [00:03<00:00,  1.44it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:34,943]\u001b[0m Trial 64 finished with value: 0.6924691724873562 and parameters: {'min_child_samples': 10}. Best is trial 64 with value: 0.6924691724873562.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.692119: 100%|##########| 5/5 [00:03<00:00,  1.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_pen</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_people</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_perfect</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_perform</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_per_&lt;p&gt;</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_good</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_24</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_place</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_per_&lt;p&gt;</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  importance\n",
       "country                    0\n",
       "tfidf_pen                  0\n",
       "tfidf_people               0\n",
       "tfidf_perfect              0\n",
       "tfidf_perform              0\n",
       "...                      ...\n",
       "sentence_per_<p>           1\n",
       "tfidf_good                 1\n",
       "wordvec_24                 1\n",
       "tfidf_place                2\n",
       "duration_per_<p>           3\n",
       "\n",
       "[1128 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:41:34,985]\u001b[0m A new study created in memory with name: no-name-ea561976-4e36-4521-880d-94569cf157c5\u001b[0m\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [06:21<?, ?it/s]\n",
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.693388:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.693388:  14%|#4        | 1/7 [00:00<00:04,  1.48it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:35,672]\u001b[0m Trial 0 finished with value: 0.6933884686706288 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.6933884686706288.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.693388:  14%|#4        | 1/7 [00:00<00:04,  1.48it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.693002:  14%|#4        | 1/7 [00:01<00:04,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.693002:  29%|##8       | 2/7 [00:01<00:03,  1.53it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:36,263]\u001b[0m Trial 1 finished with value: 0.6930015917067506 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.6930015917067506.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.693002:  29%|##8       | 2/7 [00:01<00:03,  1.53it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.693002:  29%|##8       | 2/7 [00:01<00:03,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.693002:  43%|####2     | 3/7 [00:01<00:02,  1.63it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:36,786]\u001b[0m Trial 2 finished with value: 0.6937277862695055 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.6930015917067506.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.693002:  43%|####2     | 3/7 [00:01<00:02,  1.63it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.693002:  43%|####2     | 3/7 [00:02<00:02,  1.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.693002:  57%|#####7    | 4/7 [00:02<00:01,  1.65it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:37,375]\u001b[0m Trial 3 finished with value: 0.6936445303673051 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.6930015917067506.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.693002:  57%|#####7    | 4/7 [00:02<00:01,  1.65it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692878:  57%|#####7    | 4/7 [00:02<00:01,  1.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.692878:  71%|#######1  | 5/7 [00:02<00:01,  1.67it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:37,959]\u001b[0m Trial 4 finished with value: 0.6928780493405698 and parameters: {'feature_fraction': 0.8}. Best is trial 4 with value: 0.6928780493405698.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692878:  71%|#######1  | 5/7 [00:02<00:01,  1.67it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692878:  71%|#######1  | 5/7 [00:03<00:01,  1.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.692878:  86%|########5 | 6/7 [00:03<00:00,  1.68it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:38,550]\u001b[0m Trial 5 finished with value: 0.693546858296585 and parameters: {'feature_fraction': 1.0}. Best is trial 4 with value: 0.6928780493405698.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692878:  86%|########5 | 6/7 [00:03<00:00,  1.68it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.692878:  86%|########5 | 6/7 [00:04<00:00,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.692878: 100%|##########| 7/7 [00:04<00:00,  1.69it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-08 16:41:39,127]\u001b[0m Trial 6 finished with value: 0.6933350230260553 and parameters: {'feature_fraction': 0.7}. Best is trial 4 with value: 0.6928780493405698.\u001b[0m\n",
      "feature_fraction, val_score: 0.692878: 100%|##########| 7/7 [00:04<00:00,  1.69it/s]\n",
      "num_leaves, val_score: 0.692878:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692878:   5%|5         | 1/20 [00:00<00:18,  1.05it/s]\u001b[32m[I 2021-01-08 16:41:40,084]\u001b[0m Trial 7 finished with value: 0.6950026354211692 and parameters: {'num_leaves': 235}. Best is trial 7 with value: 0.6950026354211692.\u001b[0m\n",
      "num_leaves, val_score: 0.692878:   5%|5         | 1/20 [00:00<00:18,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692878:  10%|#         | 2/20 [00:01<00:16,  1.11it/s]\u001b[32m[I 2021-01-08 16:41:40,868]\u001b[0m Trial 8 finished with value: 0.6944069385115773 and parameters: {'num_leaves': 114}. Best is trial 8 with value: 0.6944069385115773.\u001b[0m\n",
      "num_leaves, val_score: 0.692878:  10%|#         | 2/20 [00:01<00:16,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692878:  15%|#5        | 3/20 [00:02<00:13,  1.27it/s]\u001b[32m[I 2021-01-08 16:41:41,394]\u001b[0m Trial 9 finished with value: 0.6931322596058275 and parameters: {'num_leaves': 13}. Best is trial 9 with value: 0.6931322596058275.\u001b[0m\n",
      "num_leaves, val_score: 0.692878:  15%|#5        | 3/20 [00:02<00:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692878:  20%|##        | 4/20 [00:03<00:13,  1.16it/s]\u001b[32m[I 2021-01-08 16:41:42,435]\u001b[0m Trial 10 finished with value: 0.6941051478129766 and parameters: {'num_leaves': 242}. Best is trial 9 with value: 0.6931322596058275.\u001b[0m\n",
      "num_leaves, val_score: 0.692878:  20%|##        | 4/20 [00:03<00:13,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692878:  25%|##5       | 5/20 [00:03<00:11,  1.30it/s]\u001b[32m[I 2021-01-08 16:41:42,989]\u001b[0m Trial 11 finished with value: 0.6932756743393667 and parameters: {'num_leaves': 28}. Best is trial 9 with value: 0.6931322596058275.\u001b[0m\n",
      "num_leaves, val_score: 0.692878:  25%|##5       | 5/20 [00:03<00:11,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692878:  30%|###       | 6/20 [00:04<00:10,  1.27it/s]\u001b[32m[I 2021-01-08 16:41:43,806]\u001b[0m Trial 12 finished with value: 0.6948788153182236 and parameters: {'num_leaves': 144}. Best is trial 9 with value: 0.6931322596058275.\u001b[0m\n",
      "num_leaves, val_score: 0.692878:  30%|###       | 6/20 [00:04<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692878:  35%|###5      | 7/20 [00:05<00:10,  1.20it/s]\u001b[32m[I 2021-01-08 16:41:44,750]\u001b[0m Trial 13 finished with value: 0.6940830527911958 and parameters: {'num_leaves': 155}. Best is trial 9 with value: 0.6931322596058275.\u001b[0m\n",
      "num_leaves, val_score: 0.692878:  35%|###5      | 7/20 [00:05<00:10,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692878:  40%|####      | 8/20 [00:06<00:09,  1.24it/s]\u001b[32m[I 2021-01-08 16:41:45,505]\u001b[0m Trial 14 finished with value: 0.6936681380131201 and parameters: {'num_leaves': 79}. Best is trial 9 with value: 0.6931322596058275.\u001b[0m\n",
      "num_leaves, val_score: 0.692878:  40%|####      | 8/20 [00:06<00:09,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692878:  45%|####5     | 9/20 [00:07<00:09,  1.18it/s]\u001b[32m[I 2021-01-08 16:41:46,445]\u001b[0m Trial 15 finished with value: 0.6944988373157469 and parameters: {'num_leaves': 196}. Best is trial 9 with value: 0.6931322596058275.\u001b[0m\n",
      "num_leaves, val_score: 0.692878:  45%|####5     | 9/20 [00:07<00:09,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692878:  50%|#####     | 10/20 [00:08<00:08,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:41:47,148]\u001b[0m Trial 16 finished with value: 0.6930976906536641 and parameters: {'num_leaves': 77}. Best is trial 16 with value: 0.6930976906536641.\u001b[0m\n",
      "num_leaves, val_score: 0.692878:  50%|#####     | 10/20 [00:08<00:08,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692878:  55%|#####5    | 11/20 [00:08<00:07,  1.18it/s]\u001b[32m[I 2021-01-08 16:41:48,091]\u001b[0m Trial 17 finished with value: 0.6944770010210425 and parameters: {'num_leaves': 193}. Best is trial 16 with value: 0.6930976906536641.\u001b[0m\n",
      "num_leaves, val_score: 0.692878:  55%|#####5    | 11/20 [00:08<00:07,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692329:  60%|######    | 12/20 [00:09<00:06,  1.28it/s]\u001b[32m[I 2021-01-08 16:41:48,728]\u001b[0m Trial 18 finished with value: 0.6923285075136871 and parameters: {'num_leaves': 51}. Best is trial 18 with value: 0.6923285075136871.\u001b[0m\n",
      "num_leaves, val_score: 0.692329:  60%|######    | 12/20 [00:09<00:06,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692037:  65%|######5   | 13/20 [00:10<00:05,  1.30it/s]\u001b[32m[I 2021-01-08 16:41:49,466]\u001b[0m Trial 19 finished with value: 0.6920366489284436 and parameters: {'num_leaves': 48}. Best is trial 19 with value: 0.6920366489284436.\u001b[0m\n",
      "num_leaves, val_score: 0.692037:  65%|######5   | 13/20 [00:10<00:05,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692037:  70%|#######   | 14/20 [00:10<00:04,  1.37it/s]\u001b[32m[I 2021-01-08 16:41:50,104]\u001b[0m Trial 20 finished with value: 0.6923285075136871 and parameters: {'num_leaves': 51}. Best is trial 19 with value: 0.6920366489284436.\u001b[0m\n",
      "num_leaves, val_score: 0.692037:  70%|#######   | 14/20 [00:10<00:04,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.691928:  75%|#######5  | 15/20 [00:11<00:03,  1.41it/s]\u001b[32m[I 2021-01-08 16:41:50,764]\u001b[0m Trial 21 finished with value: 0.6919281372826089 and parameters: {'num_leaves': 54}. Best is trial 21 with value: 0.6919281372826089.\u001b[0m\n",
      "num_leaves, val_score: 0.691928:  75%|#######5  | 15/20 [00:11<00:03,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.691916:  80%|########  | 16/20 [00:12<00:02,  1.44it/s]\u001b[32m[I 2021-01-08 16:41:51,424]\u001b[0m Trial 22 finished with value: 0.6919159420967318 and parameters: {'num_leaves': 53}. Best is trial 22 with value: 0.6919159420967318.\u001b[0m\n",
      "num_leaves, val_score: 0.691916:  80%|########  | 16/20 [00:12<00:02,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.691916:  85%|########5 | 17/20 [00:13<00:02,  1.40it/s]\u001b[32m[I 2021-01-08 16:41:52,187]\u001b[0m Trial 23 finished with value: 0.6939865619038165 and parameters: {'num_leaves': 97}. Best is trial 22 with value: 0.6919159420967318.\u001b[0m\n",
      "num_leaves, val_score: 0.691916:  85%|########5 | 17/20 [00:13<00:02,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.691916:  90%|######### | 18/20 [00:13<00:01,  1.46it/s]\u001b[32m[I 2021-01-08 16:41:52,802]\u001b[0m Trial 24 finished with value: 0.6929950490016614 and parameters: {'num_leaves': 44}. Best is trial 22 with value: 0.6919159420967318.\u001b[0m\n",
      "num_leaves, val_score: 0.691916:  90%|######### | 18/20 [00:13<00:01,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.691916:  95%|#########5| 19/20 [00:14<00:00,  1.43it/s]\u001b[32m[I 2021-01-08 16:41:53,538]\u001b[0m Trial 25 finished with value: 0.6934221932408193 and parameters: {'num_leaves': 72}. Best is trial 22 with value: 0.6919159420967318.\u001b[0m\n",
      "num_leaves, val_score: 0.691916:  95%|#########5| 19/20 [00:14<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.691916: 100%|##########| 20/20 [00:14<00:00,  1.56it/s]\u001b[32m[I 2021-01-08 16:41:54,037]\u001b[0m Trial 26 finished with value: 0.6931388718636773 and parameters: {'num_leaves': 2}. Best is trial 22 with value: 0.6919159420967318.\u001b[0m\n",
      "num_leaves, val_score: 0.691916: 100%|##########| 20/20 [00:14<00:00,  1.34it/s]\n",
      "bagging, val_score: 0.691916:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.691916:  10%|#         | 1/10 [00:00<00:06,  1.47it/s]\u001b[32m[I 2021-01-08 16:41:54,728]\u001b[0m Trial 27 finished with value: 0.6930294976160126 and parameters: {'bagging_fraction': 0.8636753197673724, 'bagging_freq': 6}. Best is trial 27 with value: 0.6930294976160126.\u001b[0m\n",
      "bagging, val_score: 0.691916:  10%|#         | 1/10 [00:00<00:06,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.691916:  20%|##        | 2/10 [00:01<00:05,  1.52it/s]\u001b[32m[I 2021-01-08 16:41:55,324]\u001b[0m Trial 28 finished with value: 0.6947861892265456 and parameters: {'bagging_fraction': 0.4284456900331437, 'bagging_freq': 1}. Best is trial 27 with value: 0.6930294976160126.\u001b[0m\n",
      "bagging, val_score: 0.691916:  20%|##        | 2/10 [00:01<00:05,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.691916:  30%|###       | 3/10 [00:01<00:04,  1.55it/s]\u001b[32m[I 2021-01-08 16:41:55,949]\u001b[0m Trial 29 finished with value: 0.6939093599682122 and parameters: {'bagging_fraction': 0.40524263997797844, 'bagging_freq': 1}. Best is trial 27 with value: 0.6930294976160126.\u001b[0m\n",
      "bagging, val_score: 0.691916:  30%|###       | 3/10 [00:01<00:04,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.691916:  40%|####      | 4/10 [00:02<00:03,  1.55it/s]\u001b[32m[I 2021-01-08 16:41:56,587]\u001b[0m Trial 30 finished with value: 0.6939491663276766 and parameters: {'bagging_fraction': 0.9835352266081453, 'bagging_freq': 7}. Best is trial 27 with value: 0.6930294976160126.\u001b[0m\n",
      "bagging, val_score: 0.691916:  40%|####      | 4/10 [00:02<00:03,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.691916:  50%|#####     | 5/10 [00:03<00:03,  1.57it/s]\u001b[32m[I 2021-01-08 16:41:57,206]\u001b[0m Trial 31 finished with value: 0.693808428431895 and parameters: {'bagging_fraction': 0.6597781702041258, 'bagging_freq': 4}. Best is trial 27 with value: 0.6930294976160126.\u001b[0m\n",
      "bagging, val_score: 0.691916:  50%|#####     | 5/10 [00:03<00:03,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.691916:  60%|######    | 6/10 [00:03<00:02,  1.55it/s]\u001b[32m[I 2021-01-08 16:41:57,869]\u001b[0m Trial 32 finished with value: 0.6937706978236531 and parameters: {'bagging_fraction': 0.6258544715529571, 'bagging_freq': 4}. Best is trial 27 with value: 0.6930294976160126.\u001b[0m\n",
      "bagging, val_score: 0.691916:  60%|######    | 6/10 [00:03<00:02,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.691916:  70%|#######   | 7/10 [00:04<00:01,  1.57it/s]\u001b[32m[I 2021-01-08 16:41:58,485]\u001b[0m Trial 33 finished with value: 0.6939915523086633 and parameters: {'bagging_fraction': 0.8227148567736857, 'bagging_freq': 2}. Best is trial 27 with value: 0.6930294976160126.\u001b[0m\n",
      "bagging, val_score: 0.691916:  70%|#######   | 7/10 [00:04<00:01,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.691916:  80%|########  | 8/10 [00:05<00:01,  1.60it/s]\u001b[32m[I 2021-01-08 16:41:59,087]\u001b[0m Trial 34 finished with value: 0.693474609868293 and parameters: {'bagging_fraction': 0.5369442323557714, 'bagging_freq': 6}. Best is trial 27 with value: 0.6930294976160126.\u001b[0m\n",
      "bagging, val_score: 0.691916:  80%|########  | 8/10 [00:05<00:01,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.691916:  90%|######### | 9/10 [00:05<00:00,  1.59it/s]\u001b[32m[I 2021-01-08 16:41:59,726]\u001b[0m Trial 35 finished with value: 0.6932381898560073 and parameters: {'bagging_fraction': 0.9663357976371559, 'bagging_freq': 3}. Best is trial 27 with value: 0.6930294976160126.\u001b[0m\n",
      "bagging, val_score: 0.691916:  90%|######### | 9/10 [00:05<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.691916: 100%|##########| 10/10 [00:06<00:00,  1.59it/s]\u001b[32m[I 2021-01-08 16:42:00,357]\u001b[0m Trial 36 finished with value: 0.6932216064701545 and parameters: {'bagging_fraction': 0.7706397767163291, 'bagging_freq': 5}. Best is trial 27 with value: 0.6930294976160126.\u001b[0m\n",
      "bagging, val_score: 0.691916: 100%|##########| 10/10 [00:06<00:00,  1.58it/s]\n",
      "feature_fraction_stage2, val_score: 0.691916:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.691916:  17%|#6        | 1/6 [00:00<00:03,  1.59it/s]\u001b[32m[I 2021-01-08 16:42:00,995]\u001b[0m Trial 37 finished with value: 0.6920766831137403 and parameters: {'feature_fraction': 0.784}. Best is trial 37 with value: 0.6920766831137403.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.691916:  17%|#6        | 1/6 [00:00<00:03,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.691916:  33%|###3      | 2/6 [00:01<00:02,  1.59it/s]\u001b[32m[I 2021-01-08 16:42:01,624]\u001b[0m Trial 38 finished with value: 0.6943609803202128 and parameters: {'feature_fraction': 0.8480000000000001}. Best is trial 37 with value: 0.6920766831137403.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.691916:  33%|###3      | 2/6 [00:01<00:02,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.691916:  50%|#####     | 3/6 [00:01<00:01,  1.55it/s]\u001b[32m[I 2021-01-08 16:42:02,309]\u001b[0m Trial 39 finished with value: 0.6929384080858008 and parameters: {'feature_fraction': 0.7520000000000001}. Best is trial 37 with value: 0.6920766831137403.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.691916:  50%|#####     | 3/6 [00:01<00:01,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.691916:  67%|######6   | 4/6 [00:02<00:01,  1.57it/s]\u001b[32m[I 2021-01-08 16:42:02,924]\u001b[0m Trial 40 finished with value: 0.6938190520818415 and parameters: {'feature_fraction': 0.8160000000000001}. Best is trial 37 with value: 0.6920766831137403.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.691916:  67%|######6   | 4/6 [00:02<00:01,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.691916:  83%|########3 | 5/6 [00:03<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:42:03,619]\u001b[0m Trial 41 finished with value: 0.6928538033968616 and parameters: {'feature_fraction': 0.88}. Best is trial 37 with value: 0.6920766831137403.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.691916:  83%|########3 | 5/6 [00:03<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.691916: 100%|##########| 6/6 [00:03<00:00,  1.56it/s]\u001b[32m[I 2021-01-08 16:42:04,231]\u001b[0m Trial 42 finished with value: 0.6932788167095325 and parameters: {'feature_fraction': 0.7200000000000001}. Best is trial 37 with value: 0.6920766831137403.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.691916: 100%|##########| 6/6 [00:03<00:00,  1.55it/s]\n",
      "regularization_factors, val_score: 0.691916:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:   5%|5         | 1/20 [00:00<00:12,  1.57it/s]\u001b[32m[I 2021-01-08 16:42:04,880]\u001b[0m Trial 43 finished with value: 0.6942599630553116 and parameters: {'lambda_l1': 5.36769873423519, 'lambda_l2': 1.9705233191405753}. Best is trial 43 with value: 0.6942599630553116.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:   5%|5         | 1/20 [00:00<00:12,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  10%|#         | 2/20 [00:01<00:11,  1.53it/s]\u001b[32m[I 2021-01-08 16:42:05,594]\u001b[0m Trial 44 finished with value: 0.6919159420978085 and parameters: {'lambda_l1': 1.2937423535146446e-08, 'lambda_l2': 1.22349114823372e-08}. Best is trial 44 with value: 0.6919159420978085.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  10%|#         | 2/20 [00:01<00:11,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  15%|#5        | 3/20 [00:02<00:11,  1.48it/s]\u001b[32m[I 2021-01-08 16:42:06,321]\u001b[0m Trial 45 finished with value: 0.691915942098979 and parameters: {'lambda_l1': 2.370288142775543e-08, 'lambda_l2': 2.9081398569620232e-08}. Best is trial 44 with value: 0.6919159420978085.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  15%|#5        | 3/20 [00:02<00:11,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  20%|##        | 4/20 [00:02<00:10,  1.46it/s]\u001b[32m[I 2021-01-08 16:42:07,015]\u001b[0m Trial 46 finished with value: 0.6919159420982062 and parameters: {'lambda_l1': 1.0344988631312747e-08, 'lambda_l2': 2.4671550307226344e-08}. Best is trial 44 with value: 0.6919159420978085.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  20%|##        | 4/20 [00:02<00:10,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  25%|##5       | 5/20 [00:03<00:10,  1.46it/s]\u001b[32m[I 2021-01-08 16:42:07,695]\u001b[0m Trial 47 finished with value: 0.6919159420979709 and parameters: {'lambda_l1': 1.4165321817465796e-08, 'lambda_l2': 1.4859473593697012e-08}. Best is trial 44 with value: 0.6919159420978085.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  25%|##5       | 5/20 [00:03<00:10,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  30%|###       | 6/20 [00:04<00:09,  1.47it/s]\u001b[32m[I 2021-01-08 16:42:08,371]\u001b[0m Trial 48 finished with value: 0.6919159420986419 and parameters: {'lambda_l1': 2.8608364769033694e-08, 'lambda_l2': 1.564733126801424e-08}. Best is trial 44 with value: 0.6919159420978085.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  30%|###       | 6/20 [00:04<00:09,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  35%|###5      | 7/20 [00:04<00:08,  1.47it/s]\u001b[32m[I 2021-01-08 16:42:09,050]\u001b[0m Trial 49 finished with value: 0.6919159420976423 and parameters: {'lambda_l1': 1.012497128247155e-08, 'lambda_l2': 1.1227054329480149e-08}. Best is trial 49 with value: 0.6919159420976423.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  35%|###5      | 7/20 [00:04<00:08,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  40%|####      | 8/20 [00:05<00:08,  1.41it/s]\u001b[32m[I 2021-01-08 16:42:09,824]\u001b[0m Trial 50 finished with value: 0.6919159420976846 and parameters: {'lambda_l1': 1.113681882129116e-08, 'lambda_l2': 1.1166273751850531e-08}. Best is trial 49 with value: 0.6919159420976423.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  40%|####      | 8/20 [00:05<00:08,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  45%|####5     | 9/20 [00:06<00:07,  1.39it/s]\u001b[32m[I 2021-01-08 16:42:10,562]\u001b[0m Trial 51 finished with value: 0.6919159420977048 and parameters: {'lambda_l1': 1.1735224283109585e-08, 'lambda_l2': 1.1012481345906993e-08}. Best is trial 49 with value: 0.6919159420976423.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  45%|####5     | 9/20 [00:06<00:07,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  50%|#####     | 10/20 [00:07<00:07,  1.37it/s]\u001b[32m[I 2021-01-08 16:42:11,325]\u001b[0m Trial 52 finished with value: 0.6919159420976775 and parameters: {'lambda_l1': 1.1600923752412564e-08, 'lambda_l2': 1.0501259836039756e-08}. Best is trial 49 with value: 0.6919159420976423.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  50%|#####     | 10/20 [00:07<00:07,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  55%|#####5    | 11/20 [00:07<00:06,  1.36it/s]\u001b[32m[I 2021-01-08 16:42:12,065]\u001b[0m Trial 53 finished with value: 0.6919159420977838 and parameters: {'lambda_l1': 1.3717920301941534e-08, 'lambda_l2': 1.080149250193576e-08}. Best is trial 49 with value: 0.6919159420976423.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  55%|#####5    | 11/20 [00:07<00:06,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  60%|######    | 12/20 [00:09<00:07,  1.12it/s]\u001b[32m[I 2021-01-08 16:42:13,337]\u001b[0m Trial 54 finished with value: 0.6919159422471212 and parameters: {'lambda_l1': 1.7120709887314228e-06, 'lambda_l2': 1.7632554074801036e-06}. Best is trial 49 with value: 0.6919159420976423.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  60%|######    | 12/20 [00:09<00:07,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  65%|######5   | 13/20 [00:09<00:06,  1.14it/s]\u001b[32m[I 2021-01-08 16:42:14,164]\u001b[0m Trial 55 finished with value: 0.6919159421582812 and parameters: {'lambda_l1': 4.6575393649086537e-07, 'lambda_l2': 8.872779259742942e-07}. Best is trial 49 with value: 0.6919159420976423.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  65%|######5   | 13/20 [00:09<00:06,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  70%|#######   | 14/20 [00:10<00:04,  1.23it/s]\u001b[32m[I 2021-01-08 16:42:14,835]\u001b[0m Trial 56 finished with value: 0.6919159420977977 and parameters: {'lambda_l1': 1.0028173807865835e-08, 'lambda_l2': 1.5095840361772388e-08}. Best is trial 49 with value: 0.6919159420976423.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  70%|#######   | 14/20 [00:10<00:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  75%|#######5  | 15/20 [00:11<00:04,  1.14it/s]\u001b[32m[I 2021-01-08 16:42:15,851]\u001b[0m Trial 57 finished with value: 0.6919159421664236 and parameters: {'lambda_l1': 8.503382742481321e-07, 'lambda_l2': 6.7939668858303e-07}. Best is trial 49 with value: 0.6919159420976423.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  75%|#######5  | 15/20 [00:11<00:04,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  80%|########  | 16/20 [00:12<00:03,  1.21it/s]\u001b[32m[I 2021-01-08 16:42:16,570]\u001b[0m Trial 58 finished with value: 0.6927636761535524 and parameters: {'lambda_l1': 1.7619603408055025e-07, 'lambda_l2': 0.026614584194619005}. Best is trial 49 with value: 0.6919159420976423.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  80%|########  | 16/20 [00:12<00:03,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  85%|########5 | 17/20 [00:13<00:02,  1.21it/s]\u001b[32m[I 2021-01-08 16:42:17,388]\u001b[0m Trial 59 finished with value: 0.6919159480102406 and parameters: {'lambda_l1': 0.000130835691135977, 'lambda_l2': 1.4967930379576004e-07}. Best is trial 49 with value: 0.6919159420976423.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  85%|########5 | 17/20 [00:13<00:02,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  90%|######### | 18/20 [00:14<00:01,  1.18it/s]\u001b[32m[I 2021-01-08 16:42:18,281]\u001b[0m Trial 60 finished with value: 0.6919159439117557 and parameters: {'lambda_l1': 1.0259857127223177e-08, 'lambda_l2': 4.2002620988495125e-05}. Best is trial 49 with value: 0.6919159420976423.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  90%|######### | 18/20 [00:14<00:01,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916:  95%|#########5| 19/20 [00:14<00:00,  1.17it/s]\u001b[32m[I 2021-01-08 16:42:19,167]\u001b[0m Trial 61 finished with value: 0.6919159420977719 and parameters: {'lambda_l1': 1.1774310011001833e-08, 'lambda_l2': 1.2604272832255489e-08}. Best is trial 49 with value: 0.6919159420976423.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916:  95%|#########5| 19/20 [00:14<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691916: 100%|##########| 20/20 [00:15<00:00,  1.25it/s]\u001b[32m[I 2021-01-08 16:42:19,839]\u001b[0m Trial 62 finished with value: 0.6919159421010181 and parameters: {'lambda_l1': 8.439560444224877e-08, 'lambda_l2': 1.3415582971320649e-08}. Best is trial 49 with value: 0.6919159420976423.\u001b[0m\n",
      "regularization_factors, val_score: 0.691916: 100%|##########| 20/20 [00:15<00:00,  1.28it/s]\n",
      "min_data_in_leaf, val_score: 0.691916:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.691916:  20%|##        | 1/5 [00:00<00:02,  1.62it/s]\u001b[32m[I 2021-01-08 16:42:20,465]\u001b[0m Trial 63 finished with value: 0.6931311214962993 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.6931311214962993.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.691916:  20%|##        | 1/5 [00:00<00:02,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.691916:  40%|####      | 2/5 [00:01<00:01,  1.54it/s]\u001b[32m[I 2021-01-08 16:42:21,192]\u001b[0m Trial 64 finished with value: 0.6930775982146292 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.6930775982146292.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.691916:  40%|####      | 2/5 [00:01<00:01,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.691916:  60%|######    | 3/5 [00:01<00:01,  1.56it/s]\u001b[32m[I 2021-01-08 16:42:21,809]\u001b[0m Trial 65 finished with value: 0.6933732331201666 and parameters: {'min_child_samples': 50}. Best is trial 64 with value: 0.6930775982146292.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.691916:  60%|######    | 3/5 [00:01<00:01,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.691916:  80%|########  | 4/5 [00:02<00:00,  1.44it/s]\u001b[32m[I 2021-01-08 16:42:22,637]\u001b[0m Trial 66 finished with value: 0.6952280443881041 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 0.6930775982146292.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.691916:  80%|########  | 4/5 [00:02<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163680\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.691916: 100%|##########| 5/5 [00:03<00:00,  1.37it/s]\u001b[32m[I 2021-01-08 16:42:23,436]\u001b[0m Trial 67 finished with value: 0.6928674449763068 and parameters: {'min_child_samples': 25}. Best is trial 67 with value: 0.6928674449763068.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.691916: 100%|##########| 5/5 [00:03<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tfidf_john</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_parents</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_park</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_parts</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_party</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_purpose</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_make</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               importance\n",
       "tfidf_john              0\n",
       "tfidf_parents           0\n",
       "tfidf_park              0\n",
       "tfidf_parts             0\n",
       "tfidf_party             0\n",
       "...                   ...\n",
       "tfidf_purpose           2\n",
       "72                      2\n",
       "tfidf_make              2\n",
       "66                      2\n",
       "73                      2\n",
       "\n",
       "[1128 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:42:23,475]\u001b[0m A new study created in memory with name: no-name-ab639cb5-d4bd-42ca-a5e7-087d71b4c3ee\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n",
      "feature_fraction, val_score: 0.693798:  14%|#4        | 1/7 [00:00<00:03,  1.58it/s]\u001b[32m[I 2021-01-08 16:42:24,113]\u001b[0m Trial 0 finished with value: 0.6937979164168826 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.6937979164168826.\u001b[0m\n",
      "feature_fraction, val_score: 0.693798:  14%|#4        | 1/7 [00:00<00:03,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.693200:  29%|##8       | 2/7 [00:01<00:03,  1.48it/s]\u001b[32m[I 2021-01-08 16:42:24,886]\u001b[0m Trial 1 finished with value: 0.6932004150893593 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.6932004150893593.\u001b[0m\n",
      "feature_fraction, val_score: 0.693200:  29%|##8       | 2/7 [00:01<00:03,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.693200:  43%|####2     | 3/7 [00:02<00:02,  1.51it/s]\u001b[32m[I 2021-01-08 16:42:25,529]\u001b[0m Trial 2 finished with value: 0.6932872238329723 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.6932004150893593.\u001b[0m\n",
      "feature_fraction, val_score: 0.693200:  43%|####2     | 3/7 [00:02<00:02,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.692069:  57%|#####7    | 4/7 [00:02<00:02,  1.47it/s]\u001b[32m[I 2021-01-08 16:42:26,247]\u001b[0m Trial 3 finished with value: 0.6920689301185617 and parameters: {'feature_fraction': 0.4}. Best is trial 3 with value: 0.6920689301185617.\u001b[0m\n",
      "feature_fraction, val_score: 0.692069:  57%|#####7    | 4/7 [00:02<00:02,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.692069:  71%|#######1  | 5/7 [00:03<00:01,  1.48it/s]\u001b[32m[I 2021-01-08 16:42:26,910]\u001b[0m Trial 4 finished with value: 0.6924038135673919 and parameters: {'feature_fraction': 0.6}. Best is trial 3 with value: 0.6920689301185617.\u001b[0m\n",
      "feature_fraction, val_score: 0.692069:  71%|#######1  | 5/7 [00:03<00:01,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.692069:  86%|########5 | 6/7 [00:04<00:00,  1.31it/s]\u001b[32m[I 2021-01-08 16:42:27,885]\u001b[0m Trial 5 finished with value: 0.6926364120164262 and parameters: {'feature_fraction': 1.0}. Best is trial 3 with value: 0.6920689301185617.\u001b[0m\n",
      "feature_fraction, val_score: 0.692069:  86%|########5 | 6/7 [00:04<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.692069: 100%|##########| 7/7 [00:05<00:00,  1.34it/s]\u001b[32m[I 2021-01-08 16:42:28,592]\u001b[0m Trial 6 finished with value: 0.6925846642389858 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 3 with value: 0.6920689301185617.\u001b[0m\n",
      "feature_fraction, val_score: 0.692069: 100%|##########| 7/7 [00:05<00:00,  1.37it/s]\n",
      "num_leaves, val_score: 0.692069:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:   5%|5         | 1/20 [00:01<00:21,  1.15s/it]\u001b[32m[I 2021-01-08 16:42:29,751]\u001b[0m Trial 7 finished with value: 0.6939415072630701 and parameters: {'num_leaves': 241}. Best is trial 7 with value: 0.6939415072630701.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:   5%|5         | 1/20 [00:01<00:21,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  10%|#         | 2/20 [00:02<00:21,  1.17s/it]\u001b[32m[I 2021-01-08 16:42:30,987]\u001b[0m Trial 8 finished with value: 0.694034067678668 and parameters: {'num_leaves': 203}. Best is trial 7 with value: 0.6939415072630701.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  10%|#         | 2/20 [00:02<00:21,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  15%|#5        | 3/20 [00:03<00:17,  1.02s/it]\u001b[32m[I 2021-01-08 16:42:31,625]\u001b[0m Trial 9 finished with value: 0.693544098195582 and parameters: {'num_leaves': 57}. Best is trial 9 with value: 0.693544098195582.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  15%|#5        | 3/20 [00:03<00:17,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  20%|##        | 4/20 [00:03<00:14,  1.13it/s]\u001b[32m[I 2021-01-08 16:42:32,210]\u001b[0m Trial 10 finished with value: 0.6931852478573095 and parameters: {'num_leaves': 2}. Best is trial 10 with value: 0.6931852478573095.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  20%|##        | 4/20 [00:03<00:14,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  25%|##5       | 5/20 [00:04<00:12,  1.18it/s]\u001b[32m[I 2021-01-08 16:42:32,964]\u001b[0m Trial 11 finished with value: 0.6935710389151098 and parameters: {'num_leaves': 131}. Best is trial 10 with value: 0.6931852478573095.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  25%|##5       | 5/20 [00:04<00:12,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  30%|###       | 6/20 [00:05<00:11,  1.21it/s]\u001b[32m[I 2021-01-08 16:42:33,739]\u001b[0m Trial 12 finished with value: 0.6937788868048708 and parameters: {'num_leaves': 136}. Best is trial 10 with value: 0.6931852478573095.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  30%|###       | 6/20 [00:05<00:11,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  35%|###5      | 7/20 [00:05<00:09,  1.36it/s]\u001b[32m[I 2021-01-08 16:42:34,271]\u001b[0m Trial 13 finished with value: 0.6931022312968623 and parameters: {'num_leaves': 6}. Best is trial 13 with value: 0.6931022312968623.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  35%|###5      | 7/20 [00:05<00:09,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  40%|####      | 8/20 [00:06<00:08,  1.41it/s]\u001b[32m[I 2021-01-08 16:42:34,913]\u001b[0m Trial 14 finished with value: 0.6937830869681679 and parameters: {'num_leaves': 58}. Best is trial 13 with value: 0.6931022312968623.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  40%|####      | 8/20 [00:06<00:08,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  45%|####5     | 9/20 [00:07<00:08,  1.29it/s]\u001b[32m[I 2021-01-08 16:42:35,843]\u001b[0m Trial 15 finished with value: 0.6938188011808759 and parameters: {'num_leaves': 196}. Best is trial 13 with value: 0.6931022312968623.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  45%|####5     | 9/20 [00:07<00:08,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  50%|#####     | 10/20 [00:08<00:08,  1.20it/s]\u001b[32m[I 2021-01-08 16:42:36,801]\u001b[0m Trial 16 finished with value: 0.6938532170655385 and parameters: {'num_leaves': 255}. Best is trial 13 with value: 0.6931022312968623.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  50%|#####     | 10/20 [00:08<00:08,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  55%|#####5    | 11/20 [00:08<00:07,  1.28it/s]\u001b[32m[I 2021-01-08 16:42:37,470]\u001b[0m Trial 17 finished with value: 0.6936212859898063 and parameters: {'num_leaves': 70}. Best is trial 13 with value: 0.6931022312968623.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  55%|#####5    | 11/20 [00:08<00:07,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  60%|######    | 12/20 [00:09<00:06,  1.28it/s]\u001b[32m[I 2021-01-08 16:42:38,241]\u001b[0m Trial 18 finished with value: 0.6939382695757681 and parameters: {'num_leaves': 176}. Best is trial 13 with value: 0.6931022312968623.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  60%|######    | 12/20 [00:09<00:06,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  65%|######5   | 13/20 [00:10<00:05,  1.27it/s]\u001b[32m[I 2021-01-08 16:42:39,041]\u001b[0m Trial 19 finished with value: 0.694052545389287 and parameters: {'num_leaves': 96}. Best is trial 13 with value: 0.6931022312968623.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  65%|######5   | 13/20 [00:10<00:05,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  70%|#######   | 14/20 [00:11<00:04,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:42:39,776]\u001b[0m Trial 20 finished with value: 0.6938441004187371 and parameters: {'num_leaves': 160}. Best is trial 13 with value: 0.6931022312968623.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  70%|#######   | 14/20 [00:11<00:04,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  75%|#######5  | 15/20 [00:11<00:03,  1.41it/s]\u001b[32m[I 2021-01-08 16:42:40,347]\u001b[0m Trial 21 finished with value: 0.6926754887102577 and parameters: {'num_leaves': 23}. Best is trial 21 with value: 0.6926754887102577.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  75%|#######5  | 15/20 [00:11<00:03,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  80%|########  | 16/20 [00:12<00:03,  1.31it/s]\u001b[32m[I 2021-01-08 16:42:41,239]\u001b[0m Trial 22 finished with value: 0.6940696041285782 and parameters: {'num_leaves': 222}. Best is trial 21 with value: 0.6926754887102577.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  80%|########  | 16/20 [00:12<00:03,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  85%|########5 | 17/20 [00:13<00:02,  1.35it/s]\u001b[32m[I 2021-01-08 16:42:41,927]\u001b[0m Trial 23 finished with value: 0.6937332201556845 and parameters: {'num_leaves': 106}. Best is trial 21 with value: 0.6926754887102577.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  85%|########5 | 17/20 [00:13<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  90%|######### | 18/20 [00:14<00:01,  1.31it/s]\u001b[32m[I 2021-01-08 16:42:42,737]\u001b[0m Trial 24 finished with value: 0.6937182151976617 and parameters: {'num_leaves': 158}. Best is trial 21 with value: 0.6926754887102577.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  90%|######### | 18/20 [00:14<00:01,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069:  95%|#########5| 19/20 [00:14<00:00,  1.41it/s]\u001b[32m[I 2021-01-08 16:42:43,331]\u001b[0m Trial 25 finished with value: 0.6920689301185617 and parameters: {'num_leaves': 31}. Best is trial 25 with value: 0.6920689301185617.\u001b[0m\n",
      "num_leaves, val_score: 0.692069:  95%|#########5| 19/20 [00:14<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692069: 100%|##########| 20/20 [00:15<00:00,  1.46it/s]\u001b[32m[I 2021-01-08 16:42:43,955]\u001b[0m Trial 26 finished with value: 0.6934365520954946 and parameters: {'num_leaves': 35}. Best is trial 25 with value: 0.6920689301185617.\u001b[0m\n",
      "num_leaves, val_score: 0.692069: 100%|##########| 20/20 [00:15<00:00,  1.30it/s]\n",
      "bagging, val_score: 0.692069:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.692069:  10%|#         | 1/10 [00:00<00:07,  1.16it/s]\u001b[32m[I 2021-01-08 16:42:44,832]\u001b[0m Trial 27 finished with value: 0.6940850536384334 and parameters: {'bagging_fraction': 0.9626037616549525, 'bagging_freq': 6}. Best is trial 27 with value: 0.6940850536384334.\u001b[0m\n",
      "bagging, val_score: 0.692069:  10%|#         | 1/10 [00:00<00:07,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.692069:  20%|##        | 2/10 [00:01<00:06,  1.30it/s]\u001b[32m[I 2021-01-08 16:42:45,377]\u001b[0m Trial 28 finished with value: 0.6941098057330461 and parameters: {'bagging_fraction': 0.41966456207535074, 'bagging_freq': 2}. Best is trial 27 with value: 0.6940850536384334.\u001b[0m\n",
      "bagging, val_score: 0.692069:  20%|##        | 2/10 [00:01<00:06,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.692069:  30%|###       | 3/10 [00:02<00:05,  1.38it/s]\u001b[32m[I 2021-01-08 16:42:46,001]\u001b[0m Trial 29 finished with value: 0.6933056448164748 and parameters: {'bagging_fraction': 0.639824760554338, 'bagging_freq': 7}. Best is trial 29 with value: 0.6933056448164748.\u001b[0m\n",
      "bagging, val_score: 0.692069:  30%|###       | 3/10 [00:02<00:05,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.692069:  40%|####      | 4/10 [00:02<00:04,  1.41it/s]\u001b[32m[I 2021-01-08 16:42:46,679]\u001b[0m Trial 30 finished with value: 0.693526361743967 and parameters: {'bagging_fraction': 0.9520357004382514, 'bagging_freq': 1}. Best is trial 29 with value: 0.6933056448164748.\u001b[0m\n",
      "bagging, val_score: 0.692069:  40%|####      | 4/10 [00:02<00:04,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.691210:  50%|#####     | 5/10 [00:03<00:03,  1.40it/s]\u001b[32m[I 2021-01-08 16:42:47,427]\u001b[0m Trial 31 finished with value: 0.6912095935402974 and parameters: {'bagging_fraction': 0.43520033637289773, 'bagging_freq': 4}. Best is trial 31 with value: 0.6912095935402974.\u001b[0m\n",
      "bagging, val_score: 0.691210:  50%|#####     | 5/10 [00:03<00:03,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.691210:  60%|######    | 6/10 [00:04<00:02,  1.38it/s]\u001b[32m[I 2021-01-08 16:42:48,156]\u001b[0m Trial 32 finished with value: 0.6914935741796941 and parameters: {'bagging_fraction': 0.4097255398676599, 'bagging_freq': 4}. Best is trial 31 with value: 0.6912095935402974.\u001b[0m\n",
      "bagging, val_score: 0.691210:  60%|######    | 6/10 [00:04<00:02,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.691210:  70%|#######   | 7/10 [00:04<00:02,  1.45it/s]\u001b[32m[I 2021-01-08 16:42:48,769]\u001b[0m Trial 33 finished with value: 0.6924760376079155 and parameters: {'bagging_fraction': 0.4004307245389826, 'bagging_freq': 4}. Best is trial 31 with value: 0.6912095935402974.\u001b[0m\n",
      "bagging, val_score: 0.691210:  70%|#######   | 7/10 [00:04<00:02,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.691210:  80%|########  | 8/10 [00:05<00:01,  1.46it/s]\u001b[32m[I 2021-01-08 16:42:49,433]\u001b[0m Trial 34 finished with value: 0.6924937382813654 and parameters: {'bagging_fraction': 0.550061943663025, 'bagging_freq': 4}. Best is trial 31 with value: 0.6912095935402974.\u001b[0m\n",
      "bagging, val_score: 0.691210:  80%|########  | 8/10 [00:05<00:01,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.691210:  90%|######### | 9/10 [00:06<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:42:50,307]\u001b[0m Trial 35 finished with value: 0.6922333314466965 and parameters: {'bagging_fraction': 0.4597429833287011, 'bagging_freq': 3}. Best is trial 31 with value: 0.6912095935402974.\u001b[0m\n",
      "bagging, val_score: 0.691210:  90%|######### | 9/10 [00:06<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.691210: 100%|##########| 10/10 [00:06<00:00,  1.44it/s]\u001b[32m[I 2021-01-08 16:42:50,885]\u001b[0m Trial 36 finished with value: 0.6927612310788772 and parameters: {'bagging_fraction': 0.7768701321695703, 'bagging_freq': 5}. Best is trial 31 with value: 0.6912095935402974.\u001b[0m\n",
      "bagging, val_score: 0.691210: 100%|##########| 10/10 [00:06<00:00,  1.44it/s]\n",
      "feature_fraction_stage2, val_score: 0.691210:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.691210:  33%|###3      | 1/3 [00:00<00:01,  1.78it/s]\u001b[32m[I 2021-01-08 16:42:51,456]\u001b[0m Trial 37 finished with value: 0.6923307903808055 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.6923307903808055.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.691210:  33%|###3      | 1/3 [00:00<00:01,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.691210:  67%|######6   | 2/3 [00:01<00:00,  1.75it/s]\u001b[32m[I 2021-01-08 16:42:52,048]\u001b[0m Trial 38 finished with value: 0.691410884621226 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 38 with value: 0.691410884621226.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.691210:  67%|######6   | 2/3 [00:01<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.691210: 100%|##########| 3/3 [00:01<00:00,  1.67it/s]\u001b[32m[I 2021-01-08 16:42:52,715]\u001b[0m Trial 39 finished with value: 0.6912996568882562 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 39 with value: 0.6912996568882562.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.691210: 100%|##########| 3/3 [00:01<00:00,  1.64it/s]\n",
      "regularization_factors, val_score: 0.691210:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:   5%|5         | 1/20 [00:00<00:11,  1.67it/s]\u001b[32m[I 2021-01-08 16:42:53,321]\u001b[0m Trial 40 finished with value: 0.6912095938064144 and parameters: {'lambda_l1': 5.355337568710269e-06, 'lambda_l2': 2.3690790707836932e-08}. Best is trial 40 with value: 0.6912095938064144.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:   5%|5         | 1/20 [00:00<00:11,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  10%|#         | 2/20 [00:01<00:10,  1.66it/s]\u001b[32m[I 2021-01-08 16:42:53,939]\u001b[0m Trial 41 finished with value: 0.6912095936586579 and parameters: {'lambda_l1': 2.4423915188116745e-06, 'lambda_l2': 1.193912719962273e-08}. Best is trial 41 with value: 0.6912095936586579.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  10%|#         | 2/20 [00:01<00:10,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  15%|#5        | 3/20 [00:02<00:11,  1.47it/s]\u001b[32m[I 2021-01-08 16:42:54,791]\u001b[0m Trial 42 finished with value: 0.6912095937309887 and parameters: {'lambda_l1': 3.849060848109786e-06, 'lambda_l2': 2.7108081922600925e-08}. Best is trial 41 with value: 0.6912095936586579.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  15%|#5        | 3/20 [00:02<00:11,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  20%|##        | 4/20 [00:02<00:10,  1.49it/s]\u001b[32m[I 2021-01-08 16:42:55,445]\u001b[0m Trial 43 finished with value: 0.6912095936539949 and parameters: {'lambda_l1': 2.352541274722233e-06, 'lambda_l2': 1.0378863697961821e-08}. Best is trial 43 with value: 0.6912095936539949.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  20%|##        | 4/20 [00:02<00:10,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  25%|##5       | 5/20 [00:03<00:09,  1.57it/s]\u001b[32m[I 2021-01-08 16:42:55,998]\u001b[0m Trial 44 finished with value: 0.6912095936650902 and parameters: {'lambda_l1': 2.567187160197007e-06, 'lambda_l2': 1.3497881080205008e-08}. Best is trial 43 with value: 0.6912095936539949.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  25%|##5       | 5/20 [00:03<00:09,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  30%|###       | 6/20 [00:03<00:08,  1.61it/s]\u001b[32m[I 2021-01-08 16:42:56,582]\u001b[0m Trial 45 finished with value: 0.6912095936154204 and parameters: {'lambda_l1': 1.507789481425185e-06, 'lambda_l2': 2.026149363982775e-08}. Best is trial 45 with value: 0.6912095936154204.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  30%|###       | 6/20 [00:03<00:08,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  35%|###5      | 7/20 [00:04<00:07,  1.65it/s]\u001b[32m[I 2021-01-08 16:42:57,159]\u001b[0m Trial 46 finished with value: 0.6912095936110122 and parameters: {'lambda_l1': 1.4342092941838547e-06, 'lambda_l2': 1.0940093648941649e-08}. Best is trial 46 with value: 0.6912095936110122.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  35%|###5      | 7/20 [00:04<00:07,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  40%|####      | 8/20 [00:05<00:07,  1.67it/s]\u001b[32m[I 2021-01-08 16:42:57,736]\u001b[0m Trial 47 finished with value: 0.6912095935505894 and parameters: {'lambda_l1': 2.0280659825422203e-07, 'lambda_l2': 1.1265264573633378e-08}. Best is trial 47 with value: 0.6912095935505894.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  40%|####      | 8/20 [00:05<00:07,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  45%|####5     | 9/20 [00:05<00:07,  1.53it/s]\u001b[32m[I 2021-01-08 16:42:58,514]\u001b[0m Trial 48 finished with value: 0.6912095935415937 and parameters: {'lambda_l1': 1.0992290000135638e-08, 'lambda_l2': 1.0094298533299923e-08}. Best is trial 48 with value: 0.6912095935415937.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  45%|####5     | 9/20 [00:05<00:07,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  50%|#####     | 10/20 [00:06<00:06,  1.48it/s]\u001b[32m[I 2021-01-08 16:42:59,242]\u001b[0m Trial 49 finished with value: 0.6912095985378285 and parameters: {'lambda_l1': 2.1466642475463983e-08, 'lambda_l2': 6.849602652909159e-05}. Best is trial 48 with value: 0.6912095935415937.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  50%|#####     | 10/20 [00:06<00:06,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  55%|#####5    | 11/20 [00:07<00:06,  1.50it/s]\u001b[32m[I 2021-01-08 16:42:59,895]\u001b[0m Trial 50 finished with value: 0.6912095937964852 and parameters: {'lambda_l1': 1.381561966354557e-08, 'lambda_l2': 3.5743752244821315e-06}. Best is trial 48 with value: 0.6912095935415937.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  55%|#####5    | 11/20 [00:07<00:06,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031960 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  60%|######    | 12/20 [00:07<00:05,  1.41it/s]\u001b[32m[I 2021-01-08 16:43:00,707]\u001b[0m Trial 51 finished with value: 0.6912095935444464 and parameters: {'lambda_l1': 6.747112718370536e-08, 'lambda_l2': 1.0008075052302592e-08}. Best is trial 48 with value: 0.6912095935415937.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  60%|######    | 12/20 [00:07<00:05,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  65%|######5   | 13/20 [00:08<00:05,  1.31it/s]\u001b[32m[I 2021-01-08 16:43:01,582]\u001b[0m Trial 52 finished with value: 0.6919362170451703 and parameters: {'lambda_l1': 1.9582288870039655e-08, 'lambda_l2': 4.939585160080595}. Best is trial 48 with value: 0.6912095935415937.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  65%|######5   | 13/20 [00:08<00:05,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  70%|#######   | 14/20 [00:09<00:04,  1.29it/s]\u001b[32m[I 2021-01-08 16:43:02,398]\u001b[0m Trial 53 finished with value: 0.6926672645166766 and parameters: {'lambda_l1': 0.6705566081492145, 'lambda_l2': 5.210518421377696e-07}. Best is trial 48 with value: 0.6912095935415937.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  70%|#######   | 14/20 [00:09<00:04,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  75%|#######5  | 15/20 [00:10<00:03,  1.35it/s]\u001b[32m[I 2021-01-08 16:43:03,048]\u001b[0m Trial 54 finished with value: 0.6912095935565914 and parameters: {'lambda_l1': 8.7665218510305e-08, 'lambda_l2': 1.727172319582578e-07}. Best is trial 48 with value: 0.6912095935415937.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  75%|#######5  | 15/20 [00:10<00:03,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  80%|########  | 16/20 [00:11<00:02,  1.35it/s]\u001b[32m[I 2021-01-08 16:43:03,796]\u001b[0m Trial 55 finished with value: 0.6912095935871224 and parameters: {'lambda_l1': 8.825682404519511e-08, 'lambda_l2': 5.835787838772113e-07}. Best is trial 48 with value: 0.6912095935415937.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  80%|########  | 16/20 [00:11<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  85%|########5 | 17/20 [00:11<00:02,  1.34it/s]\u001b[32m[I 2021-01-08 16:43:04,551]\u001b[0m Trial 56 finished with value: 0.6912095935927655 and parameters: {'lambda_l1': 6.126161392273438e-08, 'lambda_l2': 6.792269853204584e-07}. Best is trial 48 with value: 0.6912095935415937.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  85%|########5 | 17/20 [00:11<00:02,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  90%|######### | 18/20 [00:12<00:01,  1.42it/s]\u001b[32m[I 2021-01-08 16:43:05,153]\u001b[0m Trial 57 finished with value: 0.6912095935689649 and parameters: {'lambda_l1': 1.2331712692873025e-07, 'lambda_l2': 3.115727690795998e-07}. Best is trial 48 with value: 0.6912095935415937.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  90%|######### | 18/20 [00:12<00:01,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210:  95%|#########5| 19/20 [00:13<00:00,  1.49it/s]\u001b[32m[I 2021-01-08 16:43:05,751]\u001b[0m Trial 58 finished with value: 0.6912095935620773 and parameters: {'lambda_l1': 1.9767355689344697e-07, 'lambda_l2': 1.662123038854909e-07}. Best is trial 48 with value: 0.6912095935415937.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210:  95%|#########5| 19/20 [00:13<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.691210: 100%|##########| 20/20 [00:13<00:00,  1.50it/s]\u001b[32m[I 2021-01-08 16:43:06,404]\u001b[0m Trial 59 finished with value: 0.6912096201639889 and parameters: {'lambda_l1': 0.0005257309926631274, 'lambda_l2': 1.2269886287084504e-07}. Best is trial 48 with value: 0.6912095935415937.\u001b[0m\n",
      "regularization_factors, val_score: 0.691210: 100%|##########| 20/20 [00:13<00:00,  1.46it/s]\n",
      "min_data_in_leaf, val_score: 0.691210:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.691210:  20%|##        | 1/5 [00:00<00:02,  1.41it/s]\u001b[32m[I 2021-01-08 16:43:07,125]\u001b[0m Trial 60 finished with value: 0.6916006316648873 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.6916006316648873.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.691210:  20%|##        | 1/5 [00:00<00:02,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.691210:  40%|####      | 2/5 [00:01<00:02,  1.46it/s]\u001b[32m[I 2021-01-08 16:43:07,749]\u001b[0m Trial 61 finished with value: 0.6932826166120228 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.6916006316648873.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.691210:  40%|####      | 2/5 [00:01<00:02,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.691210:  60%|######    | 3/5 [00:01<00:01,  1.52it/s]\u001b[32m[I 2021-01-08 16:43:08,344]\u001b[0m Trial 62 finished with value: 0.6931792626921723 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.6916006316648873.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.691210:  60%|######    | 3/5 [00:01<00:01,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.691210:  80%|########  | 4/5 [00:02<00:00,  1.59it/s]\u001b[32m[I 2021-01-08 16:43:08,903]\u001b[0m Trial 63 finished with value: 0.6919715326634971 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.6916006316648873.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.691210:  80%|########  | 4/5 [00:02<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 163521\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.691210: 100%|##########| 5/5 [00:03<00:00,  1.57it/s]\u001b[32m[I 2021-01-08 16:43:09,557]\u001b[0m Trial 64 finished with value: 0.6926891291151054 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.6916006316648873.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.691210: 100%|##########| 5/5 [00:03<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_parts</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_party</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_passion</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_passionate</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordvec_2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  importance\n",
       "country                    0\n",
       "tfidf_parts                0\n",
       "tfidf_party                0\n",
       "tfidf_passion              0\n",
       "tfidf_passionate           0\n",
       "...                      ...\n",
       "51                         1\n",
       "24                         2\n",
       "52                         2\n",
       "wordvec_2                  3\n",
       "61                         3\n",
       "\n",
       "[1128 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:43:09,666]\u001b[0m A new study created in memory with name: no-name-f2a931cc-73b2-4ac4-b0b6-5a7821f91bc8\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/teppei/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n",
      "feature_fraction, val_score: 0.694150:  14%|#4        | 1/7 [00:00<00:03,  1.52it/s]\u001b[32m[I 2021-01-08 16:43:10,355]\u001b[0m Trial 0 finished with value: 0.694150429413965 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.694150429413965.\u001b[0m\n",
      "feature_fraction, val_score: 0.694150:  14%|#4        | 1/7 [00:00<00:03,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.693348:  29%|##8       | 2/7 [00:01<00:03,  1.53it/s]\u001b[32m[I 2021-01-08 16:43:10,975]\u001b[0m Trial 1 finished with value: 0.6933481949792691 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.6933481949792691.\u001b[0m\n",
      "feature_fraction, val_score: 0.693348:  29%|##8       | 2/7 [00:01<00:03,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.693348:  43%|####2     | 3/7 [00:01<00:02,  1.56it/s]\u001b[32m[I 2021-01-08 16:43:11,584]\u001b[0m Trial 2 finished with value: 0.6937910831186054 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.6933481949792691.\u001b[0m\n",
      "feature_fraction, val_score: 0.693348:  43%|####2     | 3/7 [00:01<00:02,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.693348:  57%|#####7    | 4/7 [00:02<00:02,  1.46it/s]\u001b[32m[I 2021-01-08 16:43:12,374]\u001b[0m Trial 3 finished with value: 0.6943608429605553 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.6933481949792691.\u001b[0m\n",
      "feature_fraction, val_score: 0.693348:  57%|#####7    | 4/7 [00:02<00:02,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.693343:  71%|#######1  | 5/7 [00:03<00:01,  1.48it/s]\u001b[32m[I 2021-01-08 16:43:13,035]\u001b[0m Trial 4 finished with value: 0.69334341740647 and parameters: {'feature_fraction': 0.7}. Best is trial 4 with value: 0.69334341740647.\u001b[0m\n",
      "feature_fraction, val_score: 0.693343:  71%|#######1  | 5/7 [00:03<00:01,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.693343:  86%|########5 | 6/7 [00:03<00:00,  1.51it/s]\u001b[32m[I 2021-01-08 16:43:13,667]\u001b[0m Trial 5 finished with value: 0.6940389997318075 and parameters: {'feature_fraction': 0.8}. Best is trial 4 with value: 0.69334341740647.\u001b[0m\n",
      "feature_fraction, val_score: 0.693343:  86%|########5 | 6/7 [00:04<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.693343: 100%|##########| 7/7 [00:04<00:00,  1.57it/s]\u001b[32m[I 2021-01-08 16:43:14,237]\u001b[0m Trial 6 finished with value: 0.6944118203728176 and parameters: {'feature_fraction': 0.5}. Best is trial 4 with value: 0.69334341740647.\u001b[0m\n",
      "feature_fraction, val_score: 0.693343: 100%|##########| 7/7 [00:04<00:00,  1.53it/s]\n",
      "num_leaves, val_score: 0.693343:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.693343:   5%|5         | 1/20 [00:00<00:10,  1.78it/s]\u001b[32m[I 2021-01-08 16:43:14,806]\u001b[0m Trial 7 finished with value: 0.6939514873649516 and parameters: {'num_leaves': 9}. Best is trial 7 with value: 0.6939514873649516.\u001b[0m\n",
      "num_leaves, val_score: 0.693343:   5%|5         | 1/20 [00:00<00:10,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.693343:  10%|#         | 2/20 [00:01<00:12,  1.47it/s]\u001b[32m[I 2021-01-08 16:43:15,772]\u001b[0m Trial 8 finished with value: 0.6947231611836068 and parameters: {'num_leaves': 196}. Best is trial 7 with value: 0.6939514873649516.\u001b[0m\n",
      "num_leaves, val_score: 0.693343:  10%|#         | 2/20 [00:01<00:12,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.693343:  15%|#5        | 3/20 [00:02<00:12,  1.33it/s]\u001b[32m[I 2021-01-08 16:43:16,680]\u001b[0m Trial 9 finished with value: 0.6937682483733566 and parameters: {'num_leaves': 118}. Best is trial 9 with value: 0.6937682483733566.\u001b[0m\n",
      "num_leaves, val_score: 0.693343:  15%|#5        | 3/20 [00:02<00:12,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.693343:  20%|##        | 4/20 [00:03<00:12,  1.23it/s]\u001b[32m[I 2021-01-08 16:43:17,632]\u001b[0m Trial 10 finished with value: 0.6961540774245419 and parameters: {'num_leaves': 256}. Best is trial 9 with value: 0.6937682483733566.\u001b[0m\n",
      "num_leaves, val_score: 0.693343:  20%|##        | 4/20 [00:03<00:12,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.693343:  25%|##5       | 5/20 [00:03<00:10,  1.37it/s]\u001b[32m[I 2021-01-08 16:43:18,174]\u001b[0m Trial 11 finished with value: 0.6935623058888233 and parameters: {'num_leaves': 16}. Best is trial 11 with value: 0.6935623058888233.\u001b[0m\n",
      "num_leaves, val_score: 0.693343:  25%|##5       | 5/20 [00:03<00:10,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.693343:  30%|###       | 6/20 [00:04<00:10,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:43:18,894]\u001b[0m Trial 12 finished with value: 0.6934632865644014 and parameters: {'num_leaves': 97}. Best is trial 12 with value: 0.6934632865644014.\u001b[0m\n",
      "num_leaves, val_score: 0.693343:  30%|###       | 6/20 [00:04<00:10,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.693343:  35%|###5      | 7/20 [00:05<00:10,  1.25it/s]\u001b[32m[I 2021-01-08 16:43:19,857]\u001b[0m Trial 13 finished with value: 0.6960189956914918 and parameters: {'num_leaves': 253}. Best is trial 12 with value: 0.6934632865644014.\u001b[0m\n",
      "num_leaves, val_score: 0.693343:  35%|###5      | 7/20 [00:05<00:10,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692891:  40%|####      | 8/20 [00:06<00:08,  1.34it/s]\u001b[32m[I 2021-01-08 16:43:20,479]\u001b[0m Trial 14 finished with value: 0.6928914179250993 and parameters: {'num_leaves': 62}. Best is trial 14 with value: 0.6928914179250993.\u001b[0m\n",
      "num_leaves, val_score: 0.692891:  40%|####      | 8/20 [00:06<00:08,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692752:  45%|####5     | 9/20 [00:06<00:07,  1.40it/s]\u001b[32m[I 2021-01-08 16:43:21,116]\u001b[0m Trial 15 finished with value: 0.6927515028771465 and parameters: {'num_leaves': 57}. Best is trial 15 with value: 0.6927515028771465.\u001b[0m\n",
      "num_leaves, val_score: 0.692752:  45%|####5     | 9/20 [00:06<00:07,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692752:  50%|#####     | 10/20 [00:07<00:07,  1.41it/s]\u001b[32m[I 2021-01-08 16:43:21,816]\u001b[0m Trial 16 finished with value: 0.6927789265128712 and parameters: {'num_leaves': 60}. Best is trial 15 with value: 0.6927515028771465.\u001b[0m\n",
      "num_leaves, val_score: 0.692752:  50%|#####     | 10/20 [00:07<00:07,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692752:  55%|#####5    | 11/20 [00:08<00:06,  1.41it/s]\u001b[32m[I 2021-01-08 16:43:22,519]\u001b[0m Trial 17 finished with value: 0.6927789265128713 and parameters: {'num_leaves': 60}. Best is trial 15 with value: 0.6927515028771465.\u001b[0m\n",
      "num_leaves, val_score: 0.692752:  55%|#####5    | 11/20 [00:08<00:06,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692752:  60%|######    | 12/20 [00:09<00:06,  1.23it/s]\u001b[32m[I 2021-01-08 16:43:23,590]\u001b[0m Trial 18 finished with value: 0.6927731547004728 and parameters: {'num_leaves': 52}. Best is trial 15 with value: 0.6927515028771465.\u001b[0m\n",
      "num_leaves, val_score: 0.692752:  60%|######    | 12/20 [00:09<00:06,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692752:  65%|######5   | 13/20 [00:10<00:06,  1.06it/s]\u001b[32m[I 2021-01-08 16:43:24,841]\u001b[0m Trial 19 finished with value: 0.6946453262118004 and parameters: {'num_leaves': 167}. Best is trial 15 with value: 0.6927515028771465.\u001b[0m\n",
      "num_leaves, val_score: 0.692752:  65%|######5   | 13/20 [00:10<00:06,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692752:  70%|#######   | 14/20 [00:11<00:05,  1.10it/s]\u001b[32m[I 2021-01-08 16:43:25,669]\u001b[0m Trial 20 finished with value: 0.6932741848633132 and parameters: {'num_leaves': 33}. Best is trial 15 with value: 0.6927515028771465.\u001b[0m\n",
      "num_leaves, val_score: 0.692752:  70%|#######   | 14/20 [00:11<00:05,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692752:  75%|#######5  | 15/20 [00:12<00:04,  1.08it/s]\u001b[32m[I 2021-01-08 16:43:26,641]\u001b[0m Trial 21 finished with value: 0.6930616966697795 and parameters: {'num_leaves': 72}. Best is trial 15 with value: 0.6927515028771465.\u001b[0m\n",
      "num_leaves, val_score: 0.692752:  75%|#######5  | 15/20 [00:12<00:04,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692752:  80%|########  | 16/20 [00:13<00:03,  1.11it/s]\u001b[32m[I 2021-01-08 16:43:27,463]\u001b[0m Trial 22 finished with value: 0.6933287011327985 and parameters: {'num_leaves': 41}. Best is trial 15 with value: 0.6927515028771465.\u001b[0m\n",
      "num_leaves, val_score: 0.692752:  80%|########  | 16/20 [00:13<00:03,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692752:  85%|########5 | 17/20 [00:14<00:02,  1.09it/s]\u001b[32m[I 2021-01-08 16:43:28,415]\u001b[0m Trial 23 finished with value: 0.6936593363153182 and parameters: {'num_leaves': 101}. Best is trial 15 with value: 0.6927515028771465.\u001b[0m\n",
      "num_leaves, val_score: 0.692752:  85%|########5 | 17/20 [00:14<00:02,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692752:  90%|######### | 18/20 [00:14<00:01,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:43:29,274]\u001b[0m Trial 24 finished with value: 0.6929196968817128 and parameters: {'num_leaves': 73}. Best is trial 15 with value: 0.6927515028771465.\u001b[0m\n",
      "num_leaves, val_score: 0.692752:  90%|######### | 18/20 [00:15<00:01,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692752:  95%|#########5| 19/20 [00:15<00:00,  1.18it/s]\u001b[32m[I 2021-01-08 16:43:29,994]\u001b[0m Trial 25 finished with value: 0.6934416411563562 and parameters: {'num_leaves': 2}. Best is trial 15 with value: 0.6927515028771465.\u001b[0m\n",
      "num_leaves, val_score: 0.692752:  95%|#########5| 19/20 [00:15<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.692752: 100%|##########| 20/20 [00:16<00:00,  1.11it/s]\u001b[32m[I 2021-01-08 16:43:31,018]\u001b[0m Trial 26 finished with value: 0.6940468175824099 and parameters: {'num_leaves': 146}. Best is trial 15 with value: 0.6927515028771465.\u001b[0m\n",
      "num_leaves, val_score: 0.692752: 100%|##########| 20/20 [00:16<00:00,  1.19it/s]\n",
      "bagging, val_score: 0.692752:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.692752:  10%|#         | 1/10 [00:00<00:05,  1.53it/s]\u001b[32m[I 2021-01-08 16:43:31,724]\u001b[0m Trial 27 finished with value: 0.6942366949670421 and parameters: {'bagging_fraction': 0.6199153241069598, 'bagging_freq': 5}. Best is trial 27 with value: 0.6942366949670421.\u001b[0m\n",
      "bagging, val_score: 0.692752:  10%|#         | 1/10 [00:00<00:05,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.692752:  20%|##        | 2/10 [00:01<00:05,  1.50it/s]\u001b[32m[I 2021-01-08 16:43:32,384]\u001b[0m Trial 28 finished with value: 0.6944460528422397 and parameters: {'bagging_fraction': 0.9804375194759314, 'bagging_freq': 1}. Best is trial 27 with value: 0.6942366949670421.\u001b[0m\n",
      "bagging, val_score: 0.692752:  20%|##        | 2/10 [00:01<00:05,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.692752:  30%|###       | 3/10 [00:01<00:04,  1.56it/s]\u001b[32m[I 2021-01-08 16:43:32,969]\u001b[0m Trial 29 finished with value: 0.6954093851033344 and parameters: {'bagging_fraction': 0.443640447603984, 'bagging_freq': 7}. Best is trial 27 with value: 0.6942366949670421.\u001b[0m\n",
      "bagging, val_score: 0.692752:  30%|###       | 3/10 [00:01<00:04,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.692752:  40%|####      | 4/10 [00:02<00:03,  1.57it/s]\u001b[32m[I 2021-01-08 16:43:33,595]\u001b[0m Trial 30 finished with value: 0.6942731236738311 and parameters: {'bagging_fraction': 0.9858998850387364, 'bagging_freq': 1}. Best is trial 27 with value: 0.6942366949670421.\u001b[0m\n",
      "bagging, val_score: 0.692752:  40%|####      | 4/10 [00:02<00:03,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.692752:  50%|#####     | 5/10 [00:03<00:03,  1.57it/s]\u001b[32m[I 2021-01-08 16:43:34,224]\u001b[0m Trial 31 finished with value: 0.6942937552348909 and parameters: {'bagging_fraction': 0.7352570215194508, 'bagging_freq': 4}. Best is trial 27 with value: 0.6942366949670421.\u001b[0m\n",
      "bagging, val_score: 0.692752:  50%|#####     | 5/10 [00:03<00:03,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.692752:  60%|######    | 6/10 [00:03<00:02,  1.59it/s]\u001b[32m[I 2021-01-08 16:43:34,839]\u001b[0m Trial 32 finished with value: 0.6947947238631332 and parameters: {'bagging_fraction': 0.41281365846368895, 'bagging_freq': 7}. Best is trial 27 with value: 0.6942366949670421.\u001b[0m\n",
      "bagging, val_score: 0.692752:  60%|######    | 6/10 [00:03<00:02,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.692752:  70%|#######   | 7/10 [00:04<00:01,  1.59it/s]\u001b[32m[I 2021-01-08 16:43:35,469]\u001b[0m Trial 33 finished with value: 0.6941677039713461 and parameters: {'bagging_fraction': 0.821670267841157, 'bagging_freq': 2}. Best is trial 33 with value: 0.6941677039713461.\u001b[0m\n",
      "bagging, val_score: 0.692752:  70%|#######   | 7/10 [00:04<00:01,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.692752:  80%|########  | 8/10 [00:05<00:01,  1.53it/s]\u001b[32m[I 2021-01-08 16:43:36,183]\u001b[0m Trial 34 finished with value: 0.6942201897419732 and parameters: {'bagging_fraction': 0.5573245859795368, 'bagging_freq': 3}. Best is trial 33 with value: 0.6941677039713461.\u001b[0m\n",
      "bagging, val_score: 0.692752:  80%|########  | 8/10 [00:05<00:01,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.692752:  90%|######### | 9/10 [00:05<00:00,  1.45it/s]\u001b[32m[I 2021-01-08 16:43:36,958]\u001b[0m Trial 35 finished with value: 0.6942723024849523 and parameters: {'bagging_fraction': 0.8511637939281467, 'bagging_freq': 5}. Best is trial 33 with value: 0.6941677039713461.\u001b[0m\n",
      "bagging, val_score: 0.692752:  90%|######### | 9/10 [00:05<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.692752: 100%|##########| 10/10 [00:06<00:00,  1.47it/s]\u001b[32m[I 2021-01-08 16:43:37,619]\u001b[0m Trial 36 finished with value: 0.6948230771504348 and parameters: {'bagging_fraction': 0.5279854108852531, 'bagging_freq': 6}. Best is trial 33 with value: 0.6941677039713461.\u001b[0m\n",
      "bagging, val_score: 0.692752: 100%|##########| 10/10 [00:06<00:00,  1.52it/s]\n",
      "feature_fraction_stage2, val_score: 0.692752:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.692752:  17%|#6        | 1/6 [00:00<00:04,  1.06it/s]\u001b[32m[I 2021-01-08 16:43:38,578]\u001b[0m Trial 37 finished with value: 0.6927981109579207 and parameters: {'feature_fraction': 0.652}. Best is trial 37 with value: 0.6927981109579207.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.692752:  17%|#6        | 1/6 [00:00<00:04,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.692752:  33%|###3      | 2/6 [00:01<00:03,  1.11it/s]\u001b[32m[I 2021-01-08 16:43:39,381]\u001b[0m Trial 38 finished with value: 0.6927766331011609 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 38 with value: 0.6927766331011609.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.692752:  33%|###3      | 2/6 [00:01<00:03,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.692752:  50%|#####     | 3/6 [00:02<00:02,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-08 16:43:40,062]\u001b[0m Trial 39 finished with value: 0.693752728235532 and parameters: {'feature_fraction': 0.716}. Best is trial 38 with value: 0.6927766331011609.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.692752:  50%|#####     | 3/6 [00:02<00:02,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.692752:  67%|######6   | 4/6 [00:03<00:01,  1.20it/s]\u001b[32m[I 2021-01-08 16:43:40,880]\u001b[0m Trial 40 finished with value: 0.6938719754900937 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 38 with value: 0.6927766331011609.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.692752:  67%|######6   | 4/6 [00:03<00:01,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.692752:  83%|########3 | 5/6 [00:03<00:00,  1.29it/s]\u001b[32m[I 2021-01-08 16:43:41,516]\u001b[0m Trial 41 finished with value: 0.6929197526291803 and parameters: {'feature_fraction': 0.62}. Best is trial 38 with value: 0.6927766331011609.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.692752:  83%|########3 | 5/6 [00:03<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.692752: 100%|##########| 6/6 [00:04<00:00,  1.37it/s]\u001b[32m[I 2021-01-08 16:43:42,139]\u001b[0m Trial 42 finished with value: 0.6942506870618544 and parameters: {'feature_fraction': 0.748}. Best is trial 38 with value: 0.6927766331011609.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.692752: 100%|##########| 6/6 [00:04<00:00,  1.33it/s]\n",
      "regularization_factors, val_score: 0.692752:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:   5%|5         | 1/20 [00:00<00:15,  1.24it/s]\u001b[32m[I 2021-01-08 16:43:42,956]\u001b[0m Trial 43 finished with value: 0.692751540932358 and parameters: {'lambda_l1': 0.0012424398655093828, 'lambda_l2': 2.3543267793973913e-06}. Best is trial 43 with value: 0.692751540932358.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:   5%|5         | 1/20 [00:00<00:15,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  10%|#         | 2/20 [00:01<00:13,  1.31it/s]\u001b[32m[I 2021-01-08 16:43:43,635]\u001b[0m Trial 44 finished with value: 0.6927515418192011 and parameters: {'lambda_l1': 0.0012718893783508526, 'lambda_l2': 1.914529100025553e-06}. Best is trial 43 with value: 0.692751540932358.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  10%|#         | 2/20 [00:01<00:13,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  15%|#5        | 3/20 [00:02<00:12,  1.34it/s]\u001b[32m[I 2021-01-08 16:43:44,319]\u001b[0m Trial 45 finished with value: 0.6927515499225109 and parameters: {'lambda_l1': 0.0015379713447214035, 'lambda_l2': 8.723934486373424e-07}. Best is trial 43 with value: 0.692751540932358.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  15%|#5        | 3/20 [00:02<00:12,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  20%|##        | 4/20 [00:03<00:12,  1.27it/s]\u001b[32m[I 2021-01-08 16:43:45,195]\u001b[0m Trial 46 finished with value: 0.692751568356309 and parameters: {'lambda_l1': 0.002140479203922867, 'lambda_l2': 1.227309735590271e-06}. Best is trial 43 with value: 0.692751540932358.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  20%|##        | 4/20 [00:03<00:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  25%|##5       | 5/20 [00:04<00:13,  1.15it/s]\u001b[32m[I 2021-01-08 16:43:46,256]\u001b[0m Trial 47 finished with value: 0.692751546995859 and parameters: {'lambda_l1': 0.0014420912442305834, 'lambda_l2': 1.0316989101242136e-06}. Best is trial 43 with value: 0.692751540932358.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  25%|##5       | 5/20 [00:04<00:13,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  30%|###       | 6/20 [00:04<00:11,  1.18it/s]\u001b[32m[I 2021-01-08 16:43:47,049]\u001b[0m Trial 48 finished with value: 0.6927515487197945 and parameters: {'lambda_l1': 0.0014987023500830636, 'lambda_l2': 8.058200710586765e-07}. Best is trial 43 with value: 0.692751540932358.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  30%|###       | 6/20 [00:04<00:11,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  35%|###5      | 7/20 [00:05<00:10,  1.29it/s]\u001b[32m[I 2021-01-08 16:43:47,668]\u001b[0m Trial 49 finished with value: 0.6927515297591893 and parameters: {'lambda_l1': 0.0008780309616238583, 'lambda_l2': 1.314701973543093e-06}. Best is trial 49 with value: 0.6927515297591893.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  35%|###5      | 7/20 [00:05<00:10,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  40%|####      | 8/20 [00:06<00:08,  1.36it/s]\u001b[32m[I 2021-01-08 16:43:48,313]\u001b[0m Trial 50 finished with value: 0.6927515167643833 and parameters: {'lambda_l1': 0.0004499211126445351, 'lambda_l2': 4.335024535717849e-06}. Best is trial 50 with value: 0.6927515167643833.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  40%|####      | 8/20 [00:06<00:08,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  45%|####5     | 9/20 [00:06<00:07,  1.41it/s]\u001b[32m[I 2021-01-08 16:43:48,961]\u001b[0m Trial 51 finished with value: 0.6927515206221551 and parameters: {'lambda_l1': 0.0005765524988121929, 'lambda_l2': 3.899521766559304e-06}. Best is trial 50 with value: 0.6927515167643833.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  45%|####5     | 9/20 [00:06<00:07,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  50%|#####     | 10/20 [00:07<00:06,  1.44it/s]\u001b[32m[I 2021-01-08 16:43:49,612]\u001b[0m Trial 52 finished with value: 0.6927515060771706 and parameters: {'lambda_l1': 8.671273827005986e-05, 'lambda_l2': 1.783316511519115e-05}. Best is trial 52 with value: 0.6927515060771706.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  50%|#####     | 10/20 [00:07<00:06,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  55%|#####5    | 11/20 [00:08<00:06,  1.47it/s]\u001b[32m[I 2021-01-08 16:43:50,264]\u001b[0m Trial 53 finished with value: 0.6927515090810171 and parameters: {'lambda_l1': 2.0591430606591256e-07, 'lambda_l2': 0.00020118311934625856}. Best is trial 52 with value: 0.6927515060771706.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  55%|#####5    | 11/20 [00:08<00:06,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  60%|######    | 12/20 [00:08<00:05,  1.49it/s]\u001b[32m[I 2021-01-08 16:43:50,915]\u001b[0m Trial 54 finished with value: 0.6927515465125952 and parameters: {'lambda_l1': 1.6669334750156104e-07, 'lambda_l2': 0.0014163511983508888}. Best is trial 52 with value: 0.6927515060771706.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  60%|######    | 12/20 [00:08<00:05,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  65%|######5   | 13/20 [00:09<00:04,  1.48it/s]\u001b[32m[I 2021-01-08 16:43:51,606]\u001b[0m Trial 55 finished with value: 0.6927515057549196 and parameters: {'lambda_l1': 1.716197607807886e-06, 'lambda_l2': 9.171383866890118e-05}. Best is trial 55 with value: 0.6927515057549196.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  65%|######5   | 13/20 [00:09<00:04,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  70%|#######   | 14/20 [00:10<00:04,  1.45it/s]\u001b[32m[I 2021-01-08 16:43:52,321]\u001b[0m Trial 56 finished with value: 0.6927515078659183 and parameters: {'lambda_l1': 8.270841708292509e-07, 'lambda_l2': 0.00016112253152807801}. Best is trial 55 with value: 0.6927515057549196.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  70%|#######   | 14/20 [00:10<00:04,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  75%|#######5  | 15/20 [00:10<00:03,  1.48it/s]\u001b[32m[I 2021-01-08 16:43:52,971]\u001b[0m Trial 57 finished with value: 0.6927515081921517 and parameters: {'lambda_l1': 7.650074721644088e-07, 'lambda_l2': 0.00017177424063506526}. Best is trial 55 with value: 0.6927515057549196.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  75%|#######5  | 15/20 [00:10<00:03,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  80%|########  | 16/20 [00:11<00:02,  1.45it/s]\u001b[32m[I 2021-01-08 16:43:53,683]\u001b[0m Trial 58 finished with value: 0.6927515132894065 and parameters: {'lambda_l1': 6.279377336009665e-07, 'lambda_l2': 0.0003373763805078742}. Best is trial 55 with value: 0.6927515057549196.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  80%|########  | 16/20 [00:11<00:02,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  85%|########5 | 17/20 [00:12<00:02,  1.49it/s]\u001b[32m[I 2021-01-08 16:43:54,318]\u001b[0m Trial 59 finished with value: 0.6927515056419428 and parameters: {'lambda_l1': 4.3836869276064e-06, 'lambda_l2': 8.539952216361469e-05}. Best is trial 59 with value: 0.6927515056419428.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  85%|########5 | 17/20 [00:12<00:02,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  90%|######### | 18/20 [00:12<00:01,  1.50it/s]\u001b[32m[I 2021-01-08 16:43:54,976]\u001b[0m Trial 60 finished with value: 0.6927518408515053 and parameters: {'lambda_l1': 8.296682401229575e-06, 'lambda_l2': 0.02298928883799781}. Best is trial 59 with value: 0.6927515056419428.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  90%|######### | 18/20 [00:12<00:01,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752:  95%|#########5| 19/20 [00:13<00:00,  1.51it/s]\u001b[32m[I 2021-01-08 16:43:55,623]\u001b[0m Trial 61 finished with value: 0.6927515063164725 and parameters: {'lambda_l1': 3.0889192778050914e-06, 'lambda_l2': 0.00010858061188560812}. Best is trial 59 with value: 0.6927515056419428.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752:  95%|#########5| 19/20 [00:13<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.692752: 100%|##########| 20/20 [00:14<00:00,  1.53it/s]\u001b[32m[I 2021-01-08 16:43:56,263]\u001b[0m Trial 62 finished with value: 0.6927515052077853 and parameters: {'lambda_l1': 9.01698574965159e-06, 'lambda_l2': 6.670852205456531e-05}. Best is trial 62 with value: 0.6927515052077853.\u001b[0m\n",
      "regularization_factors, val_score: 0.692752: 100%|##########| 20/20 [00:14<00:00,  1.42it/s]\n",
      "min_data_in_leaf, val_score: 0.692752:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.692752:  20%|##        | 1/5 [00:00<00:02,  1.64it/s]\u001b[32m[I 2021-01-08 16:43:56,881]\u001b[0m Trial 63 finished with value: 0.6946179907874428 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.6946179907874428.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.692752:  20%|##        | 1/5 [00:00<00:02,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.692752:  40%|####      | 2/5 [00:01<00:01,  1.58it/s]\u001b[32m[I 2021-01-08 16:43:57,567]\u001b[0m Trial 64 finished with value: 0.6939772805014628 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 0.6939772805014628.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.692752:  40%|####      | 2/5 [00:01<00:01,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.692752:  60%|######    | 3/5 [00:02<00:01,  1.47it/s]\u001b[32m[I 2021-01-08 16:43:58,356]\u001b[0m Trial 65 finished with value: 0.6942569254394093 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 0.6939772805014628.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.692752:  60%|######    | 3/5 [00:02<00:01,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.692752:  80%|########  | 4/5 [00:02<00:00,  1.46it/s]\u001b[32m[I 2021-01-08 16:43:59,054]\u001b[0m Trial 66 finished with value: 0.6943251291056272 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.6939772805014628.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.692752:  80%|########  | 4/5 [00:02<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 164613\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.692752: 100%|##########| 5/5 [00:03<00:00,  1.49it/s]\u001b[32m[I 2021-01-08 16:43:59,694]\u001b[0m Trial 67 finished with value: 0.6935665029374902 and parameters: {'min_child_samples': 50}. Best is trial 67 with value: 0.6935665029374902.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.692752: 100%|##########| 5/5 [00:03<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_pen</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_people</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_perfect</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_perform</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_don</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_per_&lt;p&gt;</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_home</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               importance\n",
       "country                 0\n",
       "tfidf_pen               0\n",
       "tfidf_people            0\n",
       "tfidf_perfect           0\n",
       "tfidf_perform           0\n",
       "...                   ...\n",
       "tfidf_don               2\n",
       "word_per_<p>            2\n",
       "tfidf_home              2\n",
       "23                      2\n",
       "56                      2\n",
       "\n",
       "[1128 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "null_importances = check_null_importances(num_iteration=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tfidf_et', 'tfidf_write', 'tfidf_equipment', 'wordvec_16',\n",
      "       'wordvec_17', '9', '51', 'tfidf_price', 'tfidf_cover', 'wordvec_20',\n",
      "       'duration', 'wordvec_22', 'tfidf_culture', 'tfidf_money',\n",
      "       'tfidf_worked', 'tfidf_hope', 'tfidf_creative', 'wordvec_5',\n",
      "       'tfidf_started', 'tfidf_images', '13', 'tfidf_specific', 'tfidf_york',\n",
      "       'wordvec_10', 'wordvec_15', '1', '20', 'wordvec_2', 'wordvec_1',\n",
      "       'number_of_word', 'tfidf_huge', 'tfidf_written', '19',\n",
      "       'tfidf_professional', 'tfidf_open', 'tfidf_woman', 'tfidf_society',\n",
      "       'tfidf_fine', 'tfidf_bit', 'tfidf_sales', 'tfidf_dream',\n",
      "       'tfidf_understand', 'tfidf_local', 'tfidf_photo', 'tfidf_game',\n",
      "       'tfidf_personal', 'min_per_sentence', 'tfidf_california', 'tfidf_15',\n",
      "       'tfidf_looking', 'tfidf_passion', 'tfidf_make', 'duration_per_<p>',\n",
      "       'tfidf_love', 'tfidf_distribution', 'tfidf_thank', 'tfidf_goals',\n",
      "       'tfidf_pictures', 'tfidf_challenge', 'tfidf_reading', 'tfidf_added',\n",
      "       '63', 'tfidf_small', 'tfidf_receive', 'tfidf_background', '69',\n",
      "       'tfidf_pieces', 'tfidf_wear', 'tfidf_access', 'tfidf_art',\n",
      "       'tfidf_released', 'tfidf_learning', 'tfidf_talented', 'tfidf_voice',\n",
      "       'tfidf_visual', 'tfidf_length', 'tfidf_began', 'tfidf_simple',\n",
      "       'tfidf_home', '18', 'tfidf_expand', 'tfidf_idea', 'tfidf_don',\n",
      "       'tfidf_does', 'tfidf_try'],\n",
      "      dtype='object')\n",
      "Index(['23', '10', 'duration', 'wordvec_21', 'tfidf_hope', 'wordvec_2',\n",
      "       'wordvec_11', 'tfidf_project', 'category1', '51', 'wordvec_4',\n",
      "       'tfidf_kickstarter', 'wordvec_10', 'wordvec_18', '3', '15', '2',\n",
      "       'tfidf_wrote', '17', 'tfidf_creating', 'tfidf_inspired', 'tfidf_create',\n",
      "       'wordvec_15', 'tfidf_creative', 'tfidf_scene', 'tfidf_recently',\n",
      "       'tfidf_20', 'tfidf_material', 'tfidf_shoot', 'tfidf_forward',\n",
      "       'tfidf_form', 'tfidf_media', 'tfidf_meet', 'tfidf_party', 'tfidf_tell',\n",
      "       'tfidf_minimum', 'tfidf_festival', 'tfidf_es', 'tfidf_background',\n",
      "       'tfidf_album', 'tfidf_away', 'tfidf_special', 'tfidf_national',\n",
      "       'tfidf_october', 'tfidf_needs', 'tfidf_mark', 'tfidf_manufacturing',\n",
      "       'tfidf_funding', 'tfidf_person', '61', '62', '66', 'tfidf_help',\n",
      "       'tfidf_power', 'tfidf_let', 'tfidf_level', 'tfidf_like', 'tfidf_green',\n",
      "       'tfidf_work', 'tfidf_living', 'tfidf_campaign', 'tfidf_understand',\n",
      "       'word_per_duration', 'word_per_sentence', 'tfidf_california',\n",
      "       'duration_per_sentence', 'sentence_per_<p>', 'tfidf_good', 'wordvec_24',\n",
      "       'tfidf_place', 'duration_per_<p>'],\n",
      "      dtype='object')\n",
      "Index(['61', 'wordvec_16', '67', 'wordvec_17', 'duration', '60', 'tfidf_world',\n",
      "       'tfidf_raised', 'tfidf_quality', '17', '18', '10', 'tfidf_hope',\n",
      "       'tfidf_yes', '22', 'wordvec_23', 'tfidf_raising', 'tfidf_companies',\n",
      "       'tfidf_inspiration', 'tfidf_continue', 'tfidf_just', '3', '2',\n",
      "       'tfidf_working', 'tfidf_kickstarter', 'tfidf_helps', 'tfidf_creating',\n",
      "       'tfidf_need', 'tfidf_use', 'tfidf_makes', 'tfidf_making', 'tfidf_past',\n",
      "       'tfidf_think', 'tfidf_2012', 'tfidf_market', 'tfidf_marketing',\n",
      "       'tfidf_book', 'tfidf_materials', 'tfidf_easily', 'tfidf_festivals',\n",
      "       'tfidf_achieve', 'tfidf_actor', 'tfidf_email', 'tfidf_enjoy',\n",
      "       'tfidf_featured', 'tfidf_style', 'tfidf_entertainment', 'tfidf_stop',\n",
      "       'tfidf_amp', 'tfidf_everyday', 'tfidf_music', 'tfidf_art',\n",
      "       'tfidf_special', 'tfidf_magazine', 'tfidf_business', 'country',\n",
      "       'tfidf_challenge', 'tfidf_pledge', 'tfidf_let', 'tfidf_tour',\n",
      "       'tfidf_play', 'tfidf_plan', 'tfidf_war', 'number_of_<div>',\n",
      "       'tfidf_want', 'tfidf_room', 'tfidf_center', 'tfidf_game', 'tfidf_way',\n",
      "       'word_per_<p>', 'sentence_per_<p>', 'tfidf_traditional', 'tfidf_tracks',\n",
      "       'tfidf_come', 'tfidf_guys', 'tfidf_doing', 'tfidf_player',\n",
      "       'tfidf_visual', 'tfidf_100', 'wordvec_22', 'wordvec_18', 'tfidf_son',\n",
      "       'tfidf_kit', 'tfidf_club', 'wordvec_9', 'wordvec_4', 'tfidf_purpose',\n",
      "       '72', 'tfidf_make', '66', '73'],\n",
      "      dtype='object')\n",
      "Index(['wordvec_23', 'tfidf_age', 'tfidf_looking', 'tfidf_raised',\n",
      "       'tfidf_raise', 'wordvec_4', 'wordvec_5', 'tfidf_artist', 'tfidf_try',\n",
      "       '5', 'tfidf_sense', 'tfidf_choice', 'wordvec_12', 'tfidf_non',\n",
      "       'tfidf_site', 'tfidf_watch', 'tfidf_quality', 'tfidf_street',\n",
      "       'tfidf_story', 'tfidf_states', 'wordvec_20', 'tfidf_initial',\n",
      "       'wordvec_22', 'tfidf_human', 'wordvec_10', 'tfidf_death',\n",
      "       'tfidf_members', 'number_of_<span>', 'tfidf_having', 'tfidf_hello',\n",
      "       'tfidf_town', 'tfidf_team', 'tfidf_market', 'tfidf_recording',\n",
      "       'tfidf_step', '55', 'tfidf_worked', 'number_of_<br/>', 'tfidf_number',\n",
      "       'word_per_sentence', 'tfidf_moment', 'tfidf_source', 'tfidf_told',\n",
      "       'tfidf_manufacturing', 'tfidf_happen', 'tfidf_years', 'tfidf_making',\n",
      "       'tfidf_real', 'tfidf_youth', '51', '24', '52', 'wordvec_2', '61'],\n",
      "      dtype='object')\n",
      "Index(['tfidf_including', '20', 'tfidf_project', 'wordvec_7', 'wordvec_8',\n",
      "       'goal_min', 'tfidf_include', 'tfidf_art', 'wordvec_9', 'tfidf_summer',\n",
      "       'tfidf_offer', '16', 'tfidf_support', '9', 'tfidf_feature', '10',\n",
      "       'tfidf_start', 'tfidf_building', 'tfidf_years', 'min_per_sentence',\n",
      "       'word_per_duration', 'tfidf_goals', 'tfidf_picture', 'tfidf_buy',\n",
      "       'tfidf_good', 'tfidf_makes', 'tfidf_pick', 'tfidf_10',\n",
      "       'tfidf_performance', 'tfidf_en', 'number_of_<span>', 'tfidf_2014', '52',\n",
      "       'tfidf_space', '65', 'tfidf_energy', 'tfidf_based', '72',\n",
      "       'tfidf_helping', 'tfidf_designer', 'tfidf_metal', 'tfidf_completed',\n",
      "       '3', 'wordvec_14', 'tfidf_don', 'word_per_<p>', 'tfidf_home', '23',\n",
      "       '56'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for null_importance in null_importances:\n",
    "    null_index = null_importance[null_importance[\"importance\"] > 0].index\n",
    "    print(null_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
