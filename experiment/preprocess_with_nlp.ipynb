{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#import category_encoders as ce\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import unicodedata\n",
    "from nltk import PunktSentenceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import transformers\n",
    "import gensim.downloader\n",
    "\n",
    "import xfeat\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import gensim.downloader\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_train_test(train, test):\n",
    "    all_df = pd.merge(train, test, how=\"outer\")\n",
    "    all_df[\"data_type\"] = \"\"\n",
    "    for n in range(len(all_df)):\n",
    "        all_df[\"data_type\"][n] = \"test\" if np.isnan(all_df[\"state\"][n]) else \"train\"\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-685f4a3720c8>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_df[\"data_type\"][n] = \"test\" if np.isnan(all_df[\"state\"][n]) else \"train\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>goal</th>\n",
       "      <th>country</th>\n",
       "      <th>duration</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>html_content</th>\n",
       "      <th>state</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4001-5000</td>\n",
       "      <td>CH</td>\n",
       "      <td>29</td>\n",
       "      <td>publishing</td>\n",
       "      <td>young adult</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;span class=\"bold\"&gt;...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3001-4000</td>\n",
       "      <td>NL</td>\n",
       "      <td>34</td>\n",
       "      <td>fashion</td>\n",
       "      <td>ready-to-wear</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;h1 class=\"page-anc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19001-20000</td>\n",
       "      <td>US</td>\n",
       "      <td>30</td>\n",
       "      <td>food</td>\n",
       "      <td>spaces</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt; As our society ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2001-3000</td>\n",
       "      <td>US</td>\n",
       "      <td>41</td>\n",
       "      <td>technology</td>\n",
       "      <td>3d printing</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt;My name is Donal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2001-3000</td>\n",
       "      <td>GB</td>\n",
       "      <td>29</td>\n",
       "      <td>technology</td>\n",
       "      <td>diy electronics</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;div class=\"templat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21084</th>\n",
       "      <td>21084</td>\n",
       "      <td>9001-10000</td>\n",
       "      <td>US</td>\n",
       "      <td>30</td>\n",
       "      <td>food</td>\n",
       "      <td>drinks</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt;Its time to get ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21085</th>\n",
       "      <td>21085</td>\n",
       "      <td>1-1000</td>\n",
       "      <td>US</td>\n",
       "      <td>29</td>\n",
       "      <td>food</td>\n",
       "      <td>small batch</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt;I have been roas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21086</th>\n",
       "      <td>21086</td>\n",
       "      <td>1001-2000</td>\n",
       "      <td>US</td>\n",
       "      <td>27</td>\n",
       "      <td>crafts</td>\n",
       "      <td>pottery</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt;         I have ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21087</th>\n",
       "      <td>21087</td>\n",
       "      <td>2001-3000</td>\n",
       "      <td>US</td>\n",
       "      <td>30</td>\n",
       "      <td>design</td>\n",
       "      <td>graphic design</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;h1 class=\"page-anc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21088</th>\n",
       "      <td>21088</td>\n",
       "      <td>1001-2000</td>\n",
       "      <td>US</td>\n",
       "      <td>30</td>\n",
       "      <td>fashion</td>\n",
       "      <td>ready-to-wear</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt;I have been deve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21089 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         goal country  duration   category1        category2  \\\n",
       "0          0    4001-5000      CH        29  publishing      young adult   \n",
       "1          1    3001-4000      NL        34     fashion    ready-to-wear   \n",
       "2          2  19001-20000      US        30        food           spaces   \n",
       "3          3    2001-3000      US        41  technology      3d printing   \n",
       "4          4    2001-3000      GB        29  technology  diy electronics   \n",
       "...      ...          ...     ...       ...         ...              ...   \n",
       "21084  21084   9001-10000      US        30        food           drinks   \n",
       "21085  21085       1-1000      US        29        food      small batch   \n",
       "21086  21086    1001-2000      US        27      crafts          pottery   \n",
       "21087  21087    2001-3000      US        30      design   graphic design   \n",
       "21088  21088    1001-2000      US        30     fashion    ready-to-wear   \n",
       "\n",
       "                                            html_content  state data_type  \n",
       "0      <div class=\"contents\"><div><span class=\"bold\">...    0.0     train  \n",
       "1      <div class=\"contents\"><div><h1 class=\"page-anc...    0.0     train  \n",
       "2      <div class=\"contents\"><div><p> As our society ...    0.0     train  \n",
       "3      <div class=\"contents\"><div><p>My name is Donal...    0.0     train  \n",
       "4      <div class=\"contents\"><div><div class=\"templat...    1.0     train  \n",
       "...                                                  ...    ...       ...  \n",
       "21084  <div class=\"contents\"><div><p>Its time to get ...    NaN      test  \n",
       "21085  <div class=\"contents\"><div><p>I have been roas...    NaN      test  \n",
       "21086  <div class=\"contents\"><div><p>         I have ...    NaN      test  \n",
       "21087  <div class=\"contents\"><div><h1 class=\"page-anc...    NaN      test  \n",
       "21088  <div class=\"contents\"><div><p>I have been deve...    NaN      test  \n",
       "\n",
       "[21089 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = concat_train_test(train, test)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_spaces(html):\n",
    "    sbd = PunktSentenceTokenizer()\n",
    "    html_no_spaces = \" \".join(sbd.sentences_from_text(html, realign_boundaries=True))\n",
    "    return re.sub(r'\\s+', \" \", html_no_spaces)\n",
    "\n",
    "\n",
    "def cleanup_japanese(html):\n",
    "    return re.sub('[ぁ-ん ァ-ン 一-龥]', '', html)\n",
    "\n",
    "\n",
    "def number_of_sentences(html):\n",
    "    sbd = PunktSentenceTokenizer()\n",
    "    return len(sbd.sentences_from_text(html, realign_boundaries=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_each_paragraphs(html_text):\n",
    "    paragraphs = []\n",
    "    para_list = html_text.split(\"<p>\")\n",
    "    if not \"<p>\" in html_text[0:4]:\n",
    "        para_list = para_list[1:]\n",
    "    for para in para_list:\n",
    "        if \"</p>\" in para:\n",
    "            para_new = para.split(\"</p>\")[0]\n",
    "        else:\n",
    "            para_new = \"\"\n",
    "            \n",
    "        #それでも残っているhtmlタグを取り除く(要らないかも)\n",
    "        para_new = get_text(para_new)\n",
    "        #para_new = remove_nobreak_space(para_new)\n",
    "        \n",
    "        paragraphs.append(para_new)\n",
    "    try:\n",
    "        paragraphs.remove(\"\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        paragraphs.remove(\" \")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return paragraphs\n",
    "\n",
    "def number_of_chars(html):\n",
    "    return len(\" \".join(html.split()))\n",
    "\n",
    "def number_of_words(html):\n",
    "    return len(html.split())\n",
    "\n",
    "def number_of_excmark(html):\n",
    "    return html.count(\"!\")\n",
    "\n",
    "def number_of_questmark(html):\n",
    "    return html.count(\"?\")\n",
    "\n",
    "def number_of_punctuation(html):\n",
    "    return sum(html.count(w) for w in \".,;:\")\n",
    "\n",
    "def number_of_symbols(html):\n",
    "    return sum(html.count(w) for w in \"*$%&\")\n",
    "\n",
    "def number_of_unique_words(html):\n",
    "    return len(set(w for w in html.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_video_exist(n_video):\n",
    "    is_video_exist = 1 if n_video != 0 else 0\n",
    "    return is_video_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_html_tag(html):\n",
    "    html_tags = [\"a\", \"div\", \"!\", \"span\", \"img\", \"button\", \"video\", \"figure\",\n",
    "                 \"figcaption\", \"h1\",\"h1 \", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"polygon\",\n",
    "                 \"iframe\", \"style\", \"svg\", \"use\", \"time\", \"source\", \"li\",\n",
    "                 \"ul\", \"track\", \"embed\", \"input\", \"param\",\n",
    "                ]\n",
    "    html = html.replace(u'\\xa0', u' ')\n",
    "    html = html.replace(u'\\xc2', u' ')\n",
    "    spaces = re.compile(r'\\s+')\n",
    "    html = spaces.sub(\" \", html)\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    html = url.sub(\"<URL>\", html)\n",
    "    \n",
    "    for tag in html_tags:\n",
    "        compiler = re.compile(r\"<{}.*?>\".format(tag))\n",
    "        html = compiler.sub(f\"<{tag}>\", html)\n",
    "        \n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_html_tag(html_text):\n",
    "    tag_list = re.findall(r\"<.*?>\", html_text)\n",
    "    return tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tag_set(df):\n",
    "    tags = set()\n",
    "    for html_text in df.html_content:\n",
    "        compiled_html_text = compile_html_tag(html_text)\n",
    "        tags |= set(extract_html_tag(compiled_html_text))\n",
    "    return tags\n",
    "\n",
    "def count_n_tag(html_tag):\n",
    "    html, tag = html_tag\n",
    "    return html.count(tag)\n",
    "\n",
    "def add_number_of_tag(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    tag_set = make_tag_set(df)\n",
    "    for tag in tag_set:\n",
    "        df[f\"number_of_{tag}\"] = list(map(count_n_tag, zip(df[\"html_compiled\"], [tag]*len(df))))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TAGS = make_tag_set(all_df)\n",
    "def get_text(html):\n",
    "    html_tags = ALL_TAGS\n",
    "    for tag in html_tags:\n",
    "        html = re.sub(tag, \"\", html)\n",
    "    html = cleanup_spaces(html)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_is_nonzero(col):\n",
    "    return 0 if col == 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    #text = cleanup_japanese(text)\n",
    "    #text = cleanup_spaces(text)\n",
    "    normalized_text = normalize_unicode(text)\n",
    "    normalized_text = normalize_number(normalized_text)\n",
    "    normalized_text = lower_text(normalized_text)\n",
    "    return normalized_text\n",
    "\n",
    "\n",
    "def lower_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def normalize_unicode(text, form='NFKC'):\n",
    "    normalized_text = unicodedata.normalize(form, text)\n",
    "    return normalized_text\n",
    "\n",
    "\n",
    "def normalize_number(text):\n",
    "    # 連続した数字を除去\n",
    "    replaced_text = re.sub(r'\\d+', '', text)\n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_nlp_preprofuncs(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    preprofuncs = [\n",
    "        (compile_html_tag, \"html_compiled\", \"html_content\"),\n",
    "        (get_text, \"html_raw\", \"html_compiled\"),\n",
    "        (number_of_chars, \"number_of_chars\", \"html_raw\"),\n",
    "        (number_of_words, \"number_of_words\", \"html_raw\"),\n",
    "        (number_of_sentences, \"number_of_sentences\", \"html_raw\"),\n",
    "        (number_of_excmark, \"number_of_excmark\", \"html_raw\"),\n",
    "        (number_of_questmark, \"number_of_questmark\", \"html_raw\"),\n",
    "        (number_of_punctuation, \"number_of_punctuation\", \"html_raw\"),\n",
    "        (number_of_symbols, \"number_of_symbols\", \"html_raw\"),\n",
    "        (number_of_unique_words, \"number_of_unique_words\", \"html_raw\"),\n",
    "    ]\n",
    "    for func, col_name, target in tqdm(preprofuncs):\n",
    "        df[col_name] = list(map(func, df[target]))\n",
    "    df = add_number_of_tag(df)\n",
    "    \n",
    "    df = df.drop([\"html_content\", \"html_compiled\", \"html_raw\"], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:19<00:00,  9.74s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>goal</th>\n",
       "      <th>country</th>\n",
       "      <th>duration</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>html_content</th>\n",
       "      <th>state</th>\n",
       "      <th>data_type</th>\n",
       "      <th>html_compiled</th>\n",
       "      <th>html_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4001-5000</td>\n",
       "      <td>CH</td>\n",
       "      <td>29</td>\n",
       "      <td>publishing</td>\n",
       "      <td>young adult</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;span class=\"bold\"&gt;...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;span&gt;Mark Saggia&lt;/span&gt; is an Itali...</td>\n",
       "      <td>Mark Saggia is an Italian writer who emigrated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3001-4000</td>\n",
       "      <td>NL</td>\n",
       "      <td>34</td>\n",
       "      <td>fashion</td>\n",
       "      <td>ready-to-wear</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;h1 class=\"page-anc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;h1&gt;Hello, I am Augustinas. I am a g...</td>\n",
       "      <td>Hello, I am Augustinas. I am a graphic designe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19001-20000</td>\n",
       "      <td>US</td>\n",
       "      <td>30</td>\n",
       "      <td>food</td>\n",
       "      <td>spaces</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt; As our society ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;p&gt; As our society begins to wake up...</td>\n",
       "      <td>As our society begins to wake up from the han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2001-3000</td>\n",
       "      <td>US</td>\n",
       "      <td>41</td>\n",
       "      <td>technology</td>\n",
       "      <td>3d printing</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;p&gt;My name is Donal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;p&gt;My name is Donald Osborne and I a...</td>\n",
       "      <td>My name is Donald Osborne and I am an entrepre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2001-3000</td>\n",
       "      <td>GB</td>\n",
       "      <td>29</td>\n",
       "      <td>technology</td>\n",
       "      <td>diy electronics</td>\n",
       "      <td>&lt;div class=\"contents\"&gt;&lt;div&gt;&lt;div class=\"templat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;div&gt;&lt;div&gt;&lt;div&gt; &lt;figure&gt; &lt;img&gt; &lt;/figure&gt; &lt;/div...</td>\n",
       "      <td>We all love to play, don't we! No matter the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         goal country  duration   category1        category2  \\\n",
       "0   0    4001-5000      CH        29  publishing      young adult   \n",
       "1   1    3001-4000      NL        34     fashion    ready-to-wear   \n",
       "2   2  19001-20000      US        30        food           spaces   \n",
       "3   3    2001-3000      US        41  technology      3d printing   \n",
       "4   4    2001-3000      GB        29  technology  diy electronics   \n",
       "\n",
       "                                        html_content  state data_type  \\\n",
       "0  <div class=\"contents\"><div><span class=\"bold\">...    0.0     train   \n",
       "1  <div class=\"contents\"><div><h1 class=\"page-anc...    0.0     train   \n",
       "2  <div class=\"contents\"><div><p> As our society ...    0.0     train   \n",
       "3  <div class=\"contents\"><div><p>My name is Donal...    0.0     train   \n",
       "4  <div class=\"contents\"><div><div class=\"templat...    1.0     train   \n",
       "\n",
       "                                       html_compiled  \\\n",
       "0  <div><div><span>Mark Saggia</span> is an Itali...   \n",
       "1  <div><div><h1>Hello, I am Augustinas. I am a g...   \n",
       "2  <div><div><p> As our society begins to wake up...   \n",
       "3  <div><div><p>My name is Donald Osborne and I a...   \n",
       "4  <div><div><div> <figure> <img> </figure> </div...   \n",
       "\n",
       "                                            html_raw  \n",
       "0  Mark Saggia is an Italian writer who emigrated...  \n",
       "1  Hello, I am Augustinas. I am a graphic designe...  \n",
       "2   As our society begins to wake up from the han...  \n",
       "3  My name is Donald Osborne and I am an entrepre...  \n",
       "4   We all love to play, don't we! No matter the ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_nlp_preprofuncs_for_bert(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    preprofuncs = [\n",
    "        (compile_html_tag, \"html_compiled\", \"html_content\"),\n",
    "        (get_text, \"html_raw\", \"html_compiled\"),\n",
    "        (normalize, \"normalized_html_raw\", \"html_raw\")\n",
    "    ]\n",
    "    for func, col_name, target in tqdm(preprofuncs):\n",
    "        df[col_name] = list(map(func, df[target]))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:26<00:00,  2.66s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>goal</th>\n",
       "      <th>country</th>\n",
       "      <th>duration</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>state</th>\n",
       "      <th>data_type</th>\n",
       "      <th>number_of_chars</th>\n",
       "      <th>number_of_words</th>\n",
       "      <th>...</th>\n",
       "      <th>number_of_&lt;/figure&gt;</th>\n",
       "      <th>number_of_&lt;polygon&gt;</th>\n",
       "      <th>number_of_&lt;button&gt;</th>\n",
       "      <th>number_of_&lt;ul&gt;</th>\n",
       "      <th>number_of_&lt;track&gt;</th>\n",
       "      <th>number_of_&lt;!&gt;</th>\n",
       "      <th>number_of_&lt;/span&gt;</th>\n",
       "      <th>number_of_&lt;/i&gt;</th>\n",
       "      <th>number_of_&lt;/iframe&gt;</th>\n",
       "      <th>number_of_&lt;svg&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4001-5000</td>\n",
       "      <td>CH</td>\n",
       "      <td>29</td>\n",
       "      <td>publishing</td>\n",
       "      <td>young adult</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>5289</td>\n",
       "      <td>961</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3001-4000</td>\n",
       "      <td>NL</td>\n",
       "      <td>34</td>\n",
       "      <td>fashion</td>\n",
       "      <td>ready-to-wear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1144</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19001-20000</td>\n",
       "      <td>US</td>\n",
       "      <td>30</td>\n",
       "      <td>food</td>\n",
       "      <td>spaces</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>3316</td>\n",
       "      <td>549</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2001-3000</td>\n",
       "      <td>US</td>\n",
       "      <td>41</td>\n",
       "      <td>technology</td>\n",
       "      <td>3d printing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1670</td>\n",
       "      <td>293</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2001-3000</td>\n",
       "      <td>GB</td>\n",
       "      <td>29</td>\n",
       "      <td>technology</td>\n",
       "      <td>diy electronics</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>7560</td>\n",
       "      <td>1211</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         goal country  duration   category1        category2  state  \\\n",
       "0   0    4001-5000      CH        29  publishing      young adult    0.0   \n",
       "1   1    3001-4000      NL        34     fashion    ready-to-wear    0.0   \n",
       "2   2  19001-20000      US        30        food           spaces    0.0   \n",
       "3   3    2001-3000      US        41  technology      3d printing    0.0   \n",
       "4   4    2001-3000      GB        29  technology  diy electronics    1.0   \n",
       "\n",
       "  data_type  number_of_chars  number_of_words  ...  number_of_</figure>  \\\n",
       "0     train             5289              961  ...                    6   \n",
       "1     train             1144              202  ...                   15   \n",
       "2     train             3316              549  ...                    5   \n",
       "3     train             1670              293  ...                    0   \n",
       "4     train             7560             1211  ...                   67   \n",
       "\n",
       "   number_of_<polygon>  number_of_<button>  number_of_<ul>  number_of_<track>  \\\n",
       "0                    0                   0               0                  0   \n",
       "1                    0                   0               0                  0   \n",
       "2                    5                   4               0                  0   \n",
       "3                    0                   0               0                  0   \n",
       "4                   45                  36               1                  0   \n",
       "\n",
       "   number_of_<!>  number_of_</span>  number_of_</i>  number_of_</iframe>  \\\n",
       "0              0                 18               0                    0   \n",
       "1              0                  0               0                    0   \n",
       "2              6                  5               0                    0   \n",
       "3              0                  0               0                    0   \n",
       "4             54                 66               0                    0   \n",
       "\n",
       "   number_of_<svg>  \n",
       "0                0  \n",
       "1                0  \n",
       "2                3  \n",
       "3                0  \n",
       "4               27  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_preprocessed_df = apply_nlp_preprofuncs(all_df)\n",
    "text_type_df = apply_nlp_preprofuncs_for_bert(all_df)\n",
    "text_type_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_preprocessed_df.to_csv('data/nlp_prepared_df.csv', index=False)\n",
    "text_type_df.to_csv('data/nlp_prepared_bert.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tfidf_svd(df, target_col, stop_words=\"english\", max_gram=2, num_features_tfidf=2000, num_features_svd=128):\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                                 ngram_range=(1,max_gram),\n",
    "                                max_features=num_features_tfidf,\n",
    "                                )\n",
    "    transformer = TruncatedSVD(n_components=num_features_svd)\n",
    "    \n",
    "    X = vectorizer.fit_transform(df[target_col])\n",
    "    matrix = transformer.fit_transform(X)\n",
    "    \n",
    "    columns = [f\"tfidf_svd_{target_col}_{dim}\" for dim in range(num_features_svd)]\n",
    "    feature_df = pd.DataFrame(matrix, columns=columns)\n",
    "    ids = [n for n in range(len(df))]\n",
    "    feature_df[\"id\"] = ids\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_most_freq_word(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    \n",
    "    num_features = 1\n",
    "    vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                                 ngram_range=(1,1),\n",
    "                                max_features=num_features,)\n",
    "    mfw_dict = {}\n",
    "    for n in range(len(df)):\n",
    "        try:\n",
    "            vectorizer.fit_transform([df.normalized_html_raw.iloc[n]])\n",
    "            feature = vectorizer.get_feature_names()[0]\n",
    "        except:\n",
    "            # no text\n",
    "            feature = \"\"\n",
    "        mfw_dict[f\"{n}\"] = feature\n",
    "    mfw_df = pd.DataFrame({\"id\": mfw_dict.keys(), \"mfw\": mfw_dict.values()})\n",
    "    \n",
    "    \n",
    "    num_features = 2\n",
    "    vectorizer = CountVectorizer(stop_words=\"english\",\n",
    "                                 ngram_range=(1,1),\n",
    "                                max_features=num_features,)\n",
    "    sfw_dict = {}\n",
    "    for n in range(len(df)):\n",
    "        try:\n",
    "            vectorizer.fit_transform([df.normalized_html_raw.iloc[n]])\n",
    "            feature = list(vectorizer.get_feature_names())\n",
    "            feature.remove(mfw_df[\"mfw\"].iloc[n])\n",
    "            feature = feature[0]\n",
    "        except:\n",
    "            # no text\n",
    "            feature = \"\"\n",
    "        sfw_dict[f\"{n}\"] = feature     \n",
    "    mfw_df[\"sfw\"] =  sfw_dict.values()\n",
    "    \n",
    "    return mfw_df\n",
    "\n",
    "glove_short_vectors = gensim.downloader.load('glove-twitter-25')  # you can use any type of word2vec\n",
    "def word_to_vector2(words):\n",
    "    try:\n",
    "        vector = glove_short_vectors[words[0]]\n",
    "    except:\n",
    "        try:\n",
    "            vector = glove_short_vectors[words[1]]\n",
    "        except:\n",
    "            vector = np.zeros(25)\n",
    "    return vector\n",
    "\n",
    "\n",
    "def add_wordvec2(df_origin, columns):\n",
    "    df = df_origin.copy()\n",
    "    col1, col2 = columns\n",
    "    df[[f\"mfw_{n}\" for n in range(25)]] = list(map(word_to_vector2, zip(df[col1], df[col2])))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_most_informative_word(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    \n",
    "    num_features = 5000\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                                 ngram_range=(1,1),\n",
    "                                max_features=num_features,)\n",
    "    X = vectorizer.fit_transform(df.normalized_html_raw)\n",
    "    matrix = vectorizer.transform(df.normalized_html_raw)\n",
    "    feature_name = vectorizer.get_feature_names()\n",
    "    \n",
    "    miws = []\n",
    "    ids = df[\"id\"]\n",
    "    for n in tqdm(range(len(df))):\n",
    "        miw_column = np.argmax(matrix[n])\n",
    "        miw = feature_name[miw_column]\n",
    "        miws.append(miw)\n",
    "    miw_df = pd.DataFrame({\"id\": ids, \"miw\": miws})\n",
    "    return miw_df\n",
    "\n",
    "\n",
    "def word_to_vector(words):\n",
    "    try:\n",
    "        vector = glove_short_vectors[words]\n",
    "    except:\n",
    "        print(words)\n",
    "        vector = np.zeros(25)\n",
    "    return vector\n",
    "\n",
    "\n",
    "def add_wordvec(df_origin):\n",
    "    df = df_origin.copy()\n",
    "    df[[f\"miw_{n}\" for n in range(25)]] = list(map(word_to_vector, df[\"miw\"]))\n",
    "    df = df.drop(\"miw\", axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfw_df = extract_most_freq_word(text_type_df)\n",
    "mfw_df = add_wordvec(mfw_df)\n",
    "mfw_df.to_csv('data/mfw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miw_df = extract_most_informative_word(text_type_df)\n",
    "miw_df = add_wordvec(miw_df)\n",
    "miw_df.to_csv('data/miw.csv', index=False)\n",
    "miw_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
