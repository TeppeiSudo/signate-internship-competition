{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna.integration.lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data = pd.read_csv('data/all_added_encoded_vectorized.csv')\n",
    "#all_new = pd.read_csv('data/all_region_added_encoded_shortvectorized.csv')\n",
    "all_new = pd.read_csv('data/all_df_nlp_preprocessed.csv')\n",
    "sub = pd.read_csv('data/sample_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'goal', 'country', 'duration', 'category1', 'category2',\n",
       "       'html_content', 'state', 'data_type', 'region', 'goal_min', 'goal_max',\n",
       "       'range/min', 'max/min', '0', '1', '2', '3', '4', '5', '6', '7', '8',\n",
       "       '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20',\n",
       "       '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32',\n",
       "       '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44',\n",
       "       '45', '46', '47', '48', '49', 'html_raw', 'number_of_figure',\n",
       "       'number_of_video', 'number_of_paragraph', 'length_of_text', 'video',\n",
       "       'selected_paragraphs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optuna_lgbm(test, train, target_cols, feature_cols, categorical_cols):\n",
    "    \"\"\"\n",
    "    import optuna.integration.lightgbm as lgb\n",
    "    \"\"\"\n",
    "    X_train = train[feature_cols]\n",
    "    y_train = train[target_cols]\n",
    "    X_test = test[feature_cols]\n",
    "    \n",
    "    y_preds = []\n",
    "    models = []\n",
    "    oof_train = np.zeros((len(X_train),))\n",
    "    \n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    for fold_id, (train_index, valid_index) in enumerate(cv.split(X_train)):\n",
    "        X_tr = X_train.loc[train_index, :]\n",
    "        X_val = X_train.loc[valid_index, :]\n",
    "        y_tr = y_train.loc[train_index]\n",
    "        y_val = y_train.loc[valid_index]\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_tr,\n",
    "                                y_tr,\n",
    "                                categorical_feature=categorical_cols)\n",
    "\n",
    "        lgb_eval = lgb.Dataset(X_val,\n",
    "                               y_val,\n",
    "                               reference=lgb_train,\n",
    "                               categorical_feature=categorical_cols)\n",
    "        \n",
    "        model = lgb.train(params,\n",
    "                          lgb_train,\n",
    "                          valid_sets=[lgb_train, lgb_eval],\n",
    "                          verbose_eval=False,\n",
    "                          num_boost_round=100,\n",
    "                          early_stopping_rounds=5,\n",
    "                          )\n",
    "        \n",
    "        oof_train[valid_index] = model.predict(X_val,\n",
    "                                               num_iteration=model.best_iteration)\n",
    "        y_pred = model.predict(X_test,\n",
    "                               num_iteration=model.best_iteration)\n",
    "\n",
    "        y_preds.append(y_pred)\n",
    "        models.append(model)\n",
    "        \n",
    "        # display importance\n",
    "        importance = pd.DataFrame(model.feature_importance(), index=feature_cols, columns=['importance'])\n",
    "        display(importance)\n",
    "\n",
    "    return oof_train, sum(y_preds) / len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['country', 'category1', 'duration', 'goal_min', 'number_of_figure', 'number_of_paragraph', 'length_of_text', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24']\n"
     ]
    }
   ],
   "source": [
    "target_cols = [\"state\"]\n",
    "feature_cols = [\"country\", \"category1\", \"duration\", \"goal_min\", 'number_of_figure', 'number_of_paragraph', 'length_of_text']\n",
    "categorical_cols = [\"country\", \"category1\"]\n",
    "vector = list(map(str, range(25)))\n",
    "feature_cols.extend(vector)\n",
    "print(feature_cols)\n",
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTO DO:\\n\\nregion 以外にcountry関連の特徴量が欲しい．\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TO DO:\n",
    "\n",
    "region 以外にcountry関連の特徴量が欲しい．\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-26 22:01:06,752]\u001b[0m A new study created in memory with name: no-name-c84bc491-7424-4696-9c34-de90939e6981\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/Applications/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.435439:  14%|#4        | 1/7 [00:00<00:02,  2.91it/s]\u001b[32m[I 2020-12-26 22:01:07,101]\u001b[0m Trial 0 finished with value: 0.4354391056010323 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.4354391056010323.\u001b[0m\n",
      "feature_fraction, val_score: 0.435439:  14%|#4        | 1/7 [00:00<00:02,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.435439:  29%|##8       | 2/7 [00:00<00:01,  2.86it/s]\u001b[32m[I 2020-12-26 22:01:07,465]\u001b[0m Trial 1 finished with value: 0.4391051702913577 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.4354391056010323.\u001b[0m\n",
      "feature_fraction, val_score: 0.435439:  29%|##8       | 2/7 [00:00<00:01,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.433056:  43%|####2     | 3/7 [00:01<00:01,  2.73it/s]\u001b[32m[I 2020-12-26 22:01:07,883]\u001b[0m Trial 2 finished with value: 0.4330563492257173 and parameters: {'feature_fraction': 1.0}. Best is trial 2 with value: 0.4330563492257173.\u001b[0m\n",
      "feature_fraction, val_score: 0.433056:  43%|####2     | 3/7 [00:01<00:01,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.433056:  57%|#####7    | 4/7 [00:01<00:01,  2.55it/s]\u001b[32m[I 2020-12-26 22:01:08,326]\u001b[0m Trial 3 finished with value: 0.4396233398030315 and parameters: {'feature_fraction': 0.8}. Best is trial 2 with value: 0.4330563492257173.\u001b[0m\n",
      "feature_fraction, val_score: 0.433056:  57%|#####7    | 4/7 [00:01<00:01,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.433056:  71%|#######1  | 5/7 [00:02<00:00,  2.46it/s]\u001b[32m[I 2020-12-26 22:01:08,763]\u001b[0m Trial 4 finished with value: 0.43842587393642907 and parameters: {'feature_fraction': 0.6}. Best is trial 2 with value: 0.4330563492257173.\u001b[0m\n",
      "feature_fraction, val_score: 0.433056:  71%|#######1  | 5/7 [00:02<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.433056:  86%|########5 | 6/7 [00:02<00:00,  2.40it/s]\u001b[32m[I 2020-12-26 22:01:09,204]\u001b[0m Trial 5 finished with value: 0.43518370953261126 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 0.4330563492257173.\u001b[0m\n",
      "feature_fraction, val_score: 0.433056:  86%|########5 | 6/7 [00:02<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.433056: 100%|##########| 7/7 [00:02<00:00,  2.28it/s]\u001b[32m[I 2020-12-26 22:01:09,696]\u001b[0m Trial 6 finished with value: 0.4377973513777154 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 0.4330563492257173.\u001b[0m\n",
      "feature_fraction, val_score: 0.433056: 100%|##########| 7/7 [00:02<00:00,  2.38it/s]\n",
      "num_leaves, val_score: 0.433056:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:   5%|5         | 1/20 [00:00<00:09,  2.04it/s]\u001b[32m[I 2020-12-26 22:01:10,197]\u001b[0m Trial 7 finished with value: 0.44075437918896687 and parameters: {'num_leaves': 66}. Best is trial 7 with value: 0.44075437918896687.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:   5%|5         | 1/20 [00:00<00:09,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  10%|#         | 2/20 [00:00<00:08,  2.03it/s]\u001b[32m[I 2020-12-26 22:01:10,695]\u001b[0m Trial 8 finished with value: 0.4371330279195433 and parameters: {'num_leaves': 51}. Best is trial 8 with value: 0.4371330279195433.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  10%|#         | 2/20 [00:00<00:08,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  15%|#5        | 3/20 [00:01<00:08,  2.05it/s]\u001b[32m[I 2020-12-26 22:01:11,176]\u001b[0m Trial 9 finished with value: 0.4365729706009582 and parameters: {'num_leaves': 35}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  15%|#5        | 3/20 [00:01<00:08,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  20%|##        | 4/20 [00:02<00:09,  1.69it/s]\u001b[32m[I 2020-12-26 22:01:12,010]\u001b[0m Trial 10 finished with value: 0.454237687921261 and parameters: {'num_leaves': 239}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  20%|##        | 4/20 [00:02<00:09,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  25%|##5       | 5/20 [00:03<00:09,  1.56it/s]\u001b[32m[I 2020-12-26 22:01:12,765]\u001b[0m Trial 11 finished with value: 0.45564249300191084 and parameters: {'num_leaves': 253}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  25%|##5       | 5/20 [00:03<00:09,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  30%|###       | 6/20 [00:03<00:08,  1.59it/s]\u001b[32m[I 2020-12-26 22:01:13,370]\u001b[0m Trial 12 finished with value: 0.4488038564298223 and parameters: {'num_leaves': 158}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  30%|###       | 6/20 [00:03<00:08,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  35%|###5      | 7/20 [00:04<00:07,  1.71it/s]\u001b[32m[I 2020-12-26 22:01:13,856]\u001b[0m Trial 13 finished with value: 0.4453832135717679 and parameters: {'num_leaves': 154}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  35%|###5      | 7/20 [00:04<00:07,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  40%|####      | 8/20 [00:04<00:06,  1.79it/s]\u001b[32m[I 2020-12-26 22:01:14,344]\u001b[0m Trial 14 finished with value: 0.4512375646777037 and parameters: {'num_leaves': 202}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  40%|####      | 8/20 [00:04<00:06,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  45%|####5     | 9/20 [00:05<00:07,  1.54it/s]\u001b[32m[I 2020-12-26 22:01:15,205]\u001b[0m Trial 15 finished with value: 0.44487278712911227 and parameters: {'num_leaves': 94}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  45%|####5     | 9/20 [00:05<00:07,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  50%|#####     | 10/20 [00:06<00:06,  1.48it/s]\u001b[32m[I 2020-12-26 22:01:15,951]\u001b[0m Trial 16 finished with value: 0.44735325389579433 and parameters: {'num_leaves': 116}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  50%|#####     | 10/20 [00:06<00:06,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  55%|#####5    | 11/20 [00:06<00:05,  1.63it/s]\u001b[32m[I 2020-12-26 22:01:16,411]\u001b[0m Trial 17 finished with value: 0.44313745729505066 and parameters: {'num_leaves': 8}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  55%|#####5    | 11/20 [00:06<00:05,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  60%|######    | 12/20 [00:07<00:05,  1.50it/s]\u001b[32m[I 2020-12-26 22:01:17,200]\u001b[0m Trial 18 finished with value: 0.45068814728523543 and parameters: {'num_leaves': 199}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  65%|######5   | 13/20 [00:07<00:03,  1.89it/s]\u001b[32m[I 2020-12-26 22:01:17,411]\u001b[0m Trial 19 finished with value: 0.4563022869804932 and parameters: {'num_leaves': 5}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  65%|######5   | 13/20 [00:07<00:03,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  70%|#######   | 14/20 [00:08<00:03,  1.71it/s]\u001b[32m[I 2020-12-26 22:01:18,126]\u001b[0m Trial 20 finished with value: 0.45620273374800707 and parameters: {'num_leaves': 209}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  70%|#######   | 14/20 [00:08<00:03,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  75%|#######5  | 15/20 [00:09<00:02,  1.71it/s]\u001b[32m[I 2020-12-26 22:01:18,707]\u001b[0m Trial 21 finished with value: 0.4420387421255665 and parameters: {'num_leaves': 91}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  75%|#######5  | 15/20 [00:09<00:02,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  80%|########  | 16/20 [00:09<00:02,  1.84it/s]\u001b[32m[I 2020-12-26 22:01:19,160]\u001b[0m Trial 22 finished with value: 0.4505386318560833 and parameters: {'num_leaves': 153}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  80%|########  | 16/20 [00:09<00:02,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  85%|########5 | 17/20 [00:09<00:01,  1.87it/s]\u001b[32m[I 2020-12-26 22:01:19,671]\u001b[0m Trial 23 finished with value: 0.45326856278568023 and parameters: {'num_leaves': 231}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  85%|########5 | 17/20 [00:09<00:01,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  90%|######### | 18/20 [00:10<00:01,  1.88it/s]\u001b[32m[I 2020-12-26 22:01:20,200]\u001b[0m Trial 24 finished with value: 0.4514383120978065 and parameters: {'num_leaves': 185}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  90%|######### | 18/20 [00:10<00:01,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056:  95%|#########5| 19/20 [00:11<00:00,  1.83it/s]\u001b[32m[I 2020-12-26 22:01:20,776]\u001b[0m Trial 25 finished with value: 0.4490682285362747 and parameters: {'num_leaves': 124}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056:  95%|#########5| 19/20 [00:11<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.433056: 100%|##########| 20/20 [00:11<00:00,  2.04it/s]\u001b[32m[I 2020-12-26 22:01:21,136]\u001b[0m Trial 26 finished with value: 0.4407586286116962 and parameters: {'num_leaves': 37}. Best is trial 9 with value: 0.4365729706009582.\u001b[0m\n",
      "num_leaves, val_score: 0.433056: 100%|##########| 20/20 [00:11<00:00,  1.75it/s]\n",
      "bagging, val_score: 0.433056:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.433056:  10%|#         | 1/10 [00:00<00:03,  2.73it/s]\u001b[32m[I 2020-12-26 22:01:21,514]\u001b[0m Trial 27 finished with value: 0.4367864592621794 and parameters: {'bagging_fraction': 0.8485476048194194, 'bagging_freq': 3}. Best is trial 27 with value: 0.4367864592621794.\u001b[0m\n",
      "bagging, val_score: 0.433056:  10%|#         | 1/10 [00:00<00:03,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.433056:  20%|##        | 2/10 [00:00<00:02,  2.85it/s]\u001b[32m[I 2020-12-26 22:01:21,828]\u001b[0m Trial 28 finished with value: 0.44523269858275805 and parameters: {'bagging_fraction': 0.40696249063110657, 'bagging_freq': 7}. Best is trial 27 with value: 0.4367864592621794.\u001b[0m\n",
      "bagging, val_score: 0.433056:  30%|###       | 3/10 [00:00<00:02,  3.06it/s]\u001b[32m[I 2020-12-26 22:01:22,099]\u001b[0m Trial 29 finished with value: 0.4413587538942037 and parameters: {'bagging_fraction': 0.4690275497125156, 'bagging_freq': 1}. Best is trial 27 with value: 0.4367864592621794.\u001b[0m\n",
      "bagging, val_score: 0.433056:  30%|###       | 3/10 [00:00<00:02,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n",
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.433056:  40%|####      | 4/10 [00:01<00:02,  2.94it/s]\u001b[32m[I 2020-12-26 22:01:22,469]\u001b[0m Trial 30 finished with value: 0.4338274335108649 and parameters: {'bagging_fraction': 0.9811470323164375, 'bagging_freq': 7}. Best is trial 30 with value: 0.4338274335108649.\u001b[0m\n",
      "bagging, val_score: 0.433056:  40%|####      | 4/10 [00:01<00:02,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.433056:  50%|#####     | 5/10 [00:01<00:01,  2.85it/s]\u001b[32m[I 2020-12-26 22:01:22,846]\u001b[0m Trial 31 finished with value: 0.4345358779555393 and parameters: {'bagging_fraction': 0.976982373601562, 'bagging_freq': 7}. Best is trial 30 with value: 0.4338274335108649.\u001b[0m\n",
      "bagging, val_score: 0.433056:  50%|#####     | 5/10 [00:01<00:01,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.433056:  60%|######    | 6/10 [00:02<00:01,  2.84it/s]\u001b[32m[I 2020-12-26 22:01:23,200]\u001b[0m Trial 32 finished with value: 0.43454720302104377 and parameters: {'bagging_fraction': 0.9826471058267375, 'bagging_freq': 7}. Best is trial 30 with value: 0.4338274335108649.\u001b[0m\n",
      "bagging, val_score: 0.433056:  60%|######    | 6/10 [00:02<00:01,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.433056:  70%|#######   | 7/10 [00:02<00:01,  2.71it/s]\u001b[32m[I 2020-12-26 22:01:23,608]\u001b[0m Trial 33 finished with value: 0.4378078501365641 and parameters: {'bagging_fraction': 0.9899125282883893, 'bagging_freq': 7}. Best is trial 30 with value: 0.4338274335108649.\u001b[0m\n",
      "bagging, val_score: 0.433056:  70%|#######   | 7/10 [00:02<00:01,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.433056:  80%|########  | 8/10 [00:02<00:00,  2.72it/s]\u001b[32m[I 2020-12-26 22:01:23,978]\u001b[0m Trial 34 finished with value: 0.43805042868194544 and parameters: {'bagging_fraction': 0.9971695124223052, 'bagging_freq': 7}. Best is trial 30 with value: 0.4338274335108649.\u001b[0m\n",
      "bagging, val_score: 0.433056:  80%|########  | 8/10 [00:02<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.433056:  90%|######### | 9/10 [00:03<00:00,  2.74it/s]\u001b[32m[I 2020-12-26 22:01:24,331]\u001b[0m Trial 35 finished with value: 0.43555921911970963 and parameters: {'bagging_fraction': 0.904333328607099, 'bagging_freq': 5}. Best is trial 30 with value: 0.4338274335108649.\u001b[0m\n",
      "bagging, val_score: 0.433056:  90%|######### | 9/10 [00:03<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.433056: 100%|##########| 10/10 [00:03<00:00,  2.75it/s]\u001b[32m[I 2020-12-26 22:01:24,691]\u001b[0m Trial 36 finished with value: 0.43609663123681086 and parameters: {'bagging_fraction': 0.7905385017472254, 'bagging_freq': 6}. Best is trial 30 with value: 0.4338274335108649.\u001b[0m\n",
      "bagging, val_score: 0.433056: 100%|##########| 10/10 [00:03<00:00,  2.82it/s]\n",
      "feature_fraction_stage2, val_score: 0.433056:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.433056:  33%|###3      | 1/3 [00:00<00:00,  2.64it/s]\u001b[32m[I 2020-12-26 22:01:25,080]\u001b[0m Trial 37 finished with value: 0.43395639955868687 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 37 with value: 0.43395639955868687.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.433056:  33%|###3      | 1/3 [00:00<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.433056:  67%|######6   | 2/3 [00:00<00:00,  2.68it/s]\u001b[32m[I 2020-12-26 22:01:25,438]\u001b[0m Trial 38 finished with value: 0.43518370953261126 and parameters: {'feature_fraction': 0.92}. Best is trial 37 with value: 0.43395639955868687.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.433056:  67%|######6   | 2/3 [00:00<00:00,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.433056: 100%|##########| 3/3 [00:01<00:00,  2.80it/s]\u001b[32m[I 2020-12-26 22:01:25,757]\u001b[0m Trial 39 finished with value: 0.4345119585257134 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 37 with value: 0.43395639955868687.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.433056: 100%|##########| 3/3 [00:01<00:00,  2.83it/s]\n",
      "regularization_factors, val_score: 0.433056:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:   5%|5         | 1/20 [00:00<00:07,  2.59it/s]\u001b[32m[I 2020-12-26 22:01:26,155]\u001b[0m Trial 40 finished with value: 0.43609729101914846 and parameters: {'lambda_l1': 0.0030834432013600883, 'lambda_l2': 2.622618246323293e-06}. Best is trial 40 with value: 0.43609729101914846.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:   5%|5         | 1/20 [00:00<00:07,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  10%|#         | 2/20 [00:00<00:07,  2.53it/s]\u001b[32m[I 2020-12-26 22:01:26,570]\u001b[0m Trial 41 finished with value: 0.4351199414313405 and parameters: {'lambda_l1': 2.7633587565495258e-08, 'lambda_l2': 6.334958192088934}. Best is trial 41 with value: 0.4351199414313405.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  10%|#         | 2/20 [00:00<00:07,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  15%|#5        | 3/20 [00:01<00:06,  2.52it/s]\u001b[32m[I 2020-12-26 22:01:26,970]\u001b[0m Trial 42 finished with value: 0.439424122336303 and parameters: {'lambda_l1': 9.77085626036679, 'lambda_l2': 1.144018715853333}. Best is trial 41 with value: 0.4351199414313405.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  15%|#5        | 3/20 [00:01<00:06,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  20%|##        | 4/20 [00:01<00:06,  2.48it/s]\u001b[32m[I 2020-12-26 22:01:27,389]\u001b[0m Trial 43 finished with value: 0.43305634922152725 and parameters: {'lambda_l1': 2.0118533574094275e-08, 'lambda_l2': 1.8430181830941848e-08}. Best is trial 43 with value: 0.43305634922152725.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  20%|##        | 4/20 [00:01<00:06,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  25%|##5       | 5/20 [00:02<00:06,  2.47it/s]\u001b[32m[I 2020-12-26 22:01:27,797]\u001b[0m Trial 44 finished with value: 0.43305634921337244 and parameters: {'lambda_l1': 1.9735759022426926e-08, 'lambda_l2': 3.188818254572417e-08}. Best is trial 44 with value: 0.43305634921337244.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  25%|##5       | 5/20 [00:02<00:06,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  30%|###       | 6/20 [00:02<00:05,  2.41it/s]\u001b[32m[I 2020-12-26 22:01:28,235]\u001b[0m Trial 45 finished with value: 0.4330563492263475 and parameters: {'lambda_l1': 1.1561994889752782e-08, 'lambda_l2': 1.2168703610892001e-08}. Best is trial 44 with value: 0.43305634921337244.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  30%|###       | 6/20 [00:02<00:05,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  35%|###5      | 7/20 [00:02<00:05,  2.41it/s]\u001b[32m[I 2020-12-26 22:01:28,649]\u001b[0m Trial 46 finished with value: 0.4330563492273872 and parameters: {'lambda_l1': 1.0683658092471323e-08, 'lambda_l2': 1.1625733755634157e-08}. Best is trial 44 with value: 0.43305634921337244.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  35%|###5      | 7/20 [00:02<00:05,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  40%|####      | 8/20 [00:03<00:05,  2.26it/s]\u001b[32m[I 2020-12-26 22:01:29,155]\u001b[0m Trial 47 finished with value: 0.4330563492234736 and parameters: {'lambda_l1': 1.2891684227111254e-08, 'lambda_l2': 1.2606315066729739e-08}. Best is trial 44 with value: 0.43305634921337244.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  40%|####      | 8/20 [00:03<00:05,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  45%|####5     | 9/20 [00:03<00:04,  2.28it/s]\u001b[32m[I 2020-12-26 22:01:29,584]\u001b[0m Trial 48 finished with value: 0.4330563492245645 and parameters: {'lambda_l1': 1.1063122045684603e-08, 'lambda_l2': 1.0307900102620892e-08}. Best is trial 44 with value: 0.43305634921337244.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  45%|####5     | 9/20 [00:03<00:04,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  50%|#####     | 10/20 [00:04<00:04,  2.33it/s]\u001b[32m[I 2020-12-26 22:01:29,992]\u001b[0m Trial 49 finished with value: 0.4330563492676118 and parameters: {'lambda_l1': 4.24856093658533e-07, 'lambda_l2': 1.0618905644244255e-08}. Best is trial 44 with value: 0.43305634921337244.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  50%|#####     | 10/20 [00:04<00:04,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  55%|#####5    | 11/20 [00:04<00:03,  2.34it/s]\u001b[32m[I 2020-12-26 22:01:30,414]\u001b[0m Trial 50 finished with value: 0.43305634931840725 and parameters: {'lambda_l1': 9.887773899114267e-07, 'lambda_l2': 2.661133444873847e-07}. Best is trial 44 with value: 0.43305634921337244.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  55%|#####5    | 11/20 [00:04<00:03,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  60%|######    | 12/20 [00:05<00:03,  2.37it/s]\u001b[32m[I 2020-12-26 22:01:30,824]\u001b[0m Trial 51 finished with value: 0.43305634922268993 and parameters: {'lambda_l1': 1.4470455473188751e-08, 'lambda_l2': 1.0823459282350015e-08}. Best is trial 44 with value: 0.43305634921337244.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  60%|######    | 12/20 [00:05<00:03,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  65%|######5   | 13/20 [00:05<00:02,  2.37it/s]\u001b[32m[I 2020-12-26 22:01:31,245]\u001b[0m Trial 52 finished with value: 0.43305634922263114 and parameters: {'lambda_l1': 1.9925293373033587e-08, 'lambda_l2': 1.2267031278624343e-08}. Best is trial 44 with value: 0.43305634921337244.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  65%|######5   | 13/20 [00:05<00:02,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  70%|#######   | 14/20 [00:05<00:02,  2.39it/s]\u001b[32m[I 2020-12-26 22:01:31,655]\u001b[0m Trial 53 finished with value: 0.4330563492258443 and parameters: {'lambda_l1': 1.13156354062975e-08, 'lambda_l2': 1.0154831355572561e-08}. Best is trial 44 with value: 0.43305634921337244.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  70%|#######   | 14/20 [00:05<00:02,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  75%|#######5  | 15/20 [00:06<00:02,  2.38it/s]\u001b[32m[I 2020-12-26 22:01:32,077]\u001b[0m Trial 54 finished with value: 0.4330563492114365 and parameters: {'lambda_l1': 1.1372441823983767e-08, 'lambda_l2': 3.849626874212113e-08}. Best is trial 54 with value: 0.4330563492114365.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  75%|#######5  | 15/20 [00:06<00:02,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  80%|########  | 16/20 [00:06<00:01,  2.38it/s]\u001b[32m[I 2020-12-26 22:01:32,497]\u001b[0m Trial 55 finished with value: 0.43305634920602903 and parameters: {'lambda_l1': 2.2237240170120844e-07, 'lambda_l2': 3.5532090970658244e-07}. Best is trial 55 with value: 0.43305634920602903.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  80%|########  | 16/20 [00:06<00:01,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  85%|########5 | 17/20 [00:07<00:01,  2.37it/s]\u001b[32m[I 2020-12-26 22:01:32,926]\u001b[0m Trial 56 finished with value: 0.43305634924076125 and parameters: {'lambda_l1': 3.973934614213338e-07, 'lambda_l2': 5.474811203571911e-07}. Best is trial 55 with value: 0.43305634920602903.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  85%|########5 | 17/20 [00:07<00:01,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  90%|######### | 18/20 [00:07<00:00,  2.37it/s]\u001b[32m[I 2020-12-26 22:01:33,345]\u001b[0m Trial 57 finished with value: 0.433056349214183 and parameters: {'lambda_l1': 1.5697417278031195e-07, 'lambda_l2': 1.829917626578494e-07}. Best is trial 55 with value: 0.43305634920602903.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  90%|######### | 18/20 [00:07<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056:  95%|#########5| 19/20 [00:07<00:00,  2.37it/s]\u001b[32m[I 2020-12-26 22:01:33,766]\u001b[0m Trial 58 finished with value: 0.4330563492188323 and parameters: {'lambda_l1': 2.5310750900727446e-07, 'lambda_l2': 3.098273212074913e-07}. Best is trial 55 with value: 0.43305634920602903.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056:  95%|#########5| 19/20 [00:08<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.433056: 100%|##########| 20/20 [00:08<00:00,  2.36it/s]\u001b[32m[I 2020-12-26 22:01:34,198]\u001b[0m Trial 59 finished with value: 0.4330563496039415 and parameters: {'lambda_l1': 3.4676361053356657e-06, 'lambda_l2': 3.5677041651179955e-07}. Best is trial 55 with value: 0.43305634920602903.\u001b[0m\n",
      "regularization_factors, val_score: 0.433056: 100%|##########| 20/20 [00:08<00:00,  2.37it/s]\n",
      "min_data_in_leaf, val_score: 0.433056:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.433056:  20%|##        | 1/5 [00:00<00:01,  2.78it/s]\u001b[32m[I 2020-12-26 22:01:34,569]\u001b[0m Trial 60 finished with value: 0.4383265601871549 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.4383265601871549.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.433056:  20%|##        | 1/5 [00:00<00:01,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.433056:  40%|####      | 2/5 [00:00<00:01,  2.58it/s]\u001b[32m[I 2020-12-26 22:01:35,022]\u001b[0m Trial 61 finished with value: 0.4355031579691896 and parameters: {'min_child_samples': 5}. Best is trial 61 with value: 0.4355031579691896.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.433056:  40%|####      | 2/5 [00:00<00:01,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.433056:  60%|######    | 3/5 [00:01<00:00,  2.55it/s]\u001b[32m[I 2020-12-26 22:01:35,423]\u001b[0m Trial 62 finished with value: 0.4349525529717919 and parameters: {'min_child_samples': 10}. Best is trial 62 with value: 0.4349525529717919.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.433056:  60%|######    | 3/5 [00:01<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.433056:  80%|########  | 4/5 [00:01<00:00,  2.56it/s]\u001b[32m[I 2020-12-26 22:01:35,812]\u001b[0m Trial 63 finished with value: 0.43353230438809365 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.43353230438809365.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.433056:  80%|########  | 4/5 [00:01<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4244, number of negative: 4192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503082 -> initscore=0.012328\n",
      "[LightGBM] [Info] Start training from score 0.012328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.433056: 100%|##########| 5/5 [00:02<00:00,  2.41it/s]\u001b[32m[I 2020-12-26 22:01:36,282]\u001b[0m Trial 64 finished with value: 0.4365122978103574 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.43353230438809365.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.433056: 100%|##########| 5/5 [00:02<00:00,  2.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category1</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goal_min</th>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_figure</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_paragraph</th>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length_of_text</th>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importance\n",
       "country                      58\n",
       "category1                    89\n",
       "duration                    194\n",
       "goal_min                    253\n",
       "number_of_figure            191\n",
       "number_of_paragraph         159\n",
       "length_of_text              313\n",
       "0                            67\n",
       "1                            83\n",
       "2                            69\n",
       "3                            72\n",
       "4                            27\n",
       "5                            81\n",
       "6                            47\n",
       "7                            55\n",
       "8                            44\n",
       "9                            53\n",
       "10                           54\n",
       "11                           80\n",
       "12                           52\n",
       "13                           74\n",
       "14                           57\n",
       "15                           45\n",
       "16                           42\n",
       "17                           63\n",
       "18                           65\n",
       "19                           53\n",
       "20                           43\n",
       "21                           44\n",
       "22                           60\n",
       "23                           56\n",
       "24                           87"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-26 22:01:36,413]\u001b[0m A new study created in memory with name: no-name-8db33938-7f17-472b-98f0-8d6af0720ec3\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/Applications/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.465004:  14%|#4        | 1/7 [00:00<00:02,  2.72it/s]\u001b[32m[I 2020-12-26 22:01:36,804]\u001b[0m Trial 0 finished with value: 0.4650043856318458 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.4650043856318458.\u001b[0m\n",
      "feature_fraction, val_score: 0.465004:  14%|#4        | 1/7 [00:00<00:02,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.464360:  29%|##8       | 2/7 [00:00<00:01,  2.96it/s]\u001b[32m[I 2020-12-26 22:01:37,075]\u001b[0m Trial 1 finished with value: 0.4643599061173926 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.4643599061173926.\u001b[0m\n",
      "feature_fraction, val_score: 0.464360:  43%|####2     | 3/7 [00:00<00:01,  3.14it/s]\u001b[32m[I 2020-12-26 22:01:37,347]\u001b[0m Trial 2 finished with value: 0.4646372641059476 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.4643599061173926.\u001b[0m\n",
      "feature_fraction, val_score: 0.464360:  43%|####2     | 3/7 [00:00<00:01,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.464360:  57%|#####7    | 4/7 [00:01<00:00,  3.39it/s]\u001b[32m[I 2020-12-26 22:01:37,589]\u001b[0m Trial 3 finished with value: 0.4656680475596193 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.4643599061173926.\u001b[0m\n",
      "feature_fraction, val_score: 0.464360:  57%|#####7    | 4/7 [00:01<00:00,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.461627:  71%|#######1  | 5/7 [00:01<00:00,  3.32it/s]\u001b[32m[I 2020-12-26 22:01:37,901]\u001b[0m Trial 4 finished with value: 0.46162713061945876 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 0.46162713061945876.\u001b[0m\n",
      "feature_fraction, val_score: 0.461627:  71%|#######1  | 5/7 [00:01<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.461627:  86%|########5 | 6/7 [00:01<00:00,  3.20it/s]\u001b[32m[I 2020-12-26 22:01:38,241]\u001b[0m Trial 5 finished with value: 0.46330684902106917 and parameters: {'feature_fraction': 0.8}. Best is trial 4 with value: 0.46162713061945876.\u001b[0m\n",
      "feature_fraction, val_score: 0.461627:  86%|########5 | 6/7 [00:01<00:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.461627: 100%|##########| 7/7 [00:02<00:00,  3.14it/s]\u001b[32m[I 2020-12-26 22:01:38,573]\u001b[0m Trial 6 finished with value: 0.46426512682255816 and parameters: {'feature_fraction': 0.7}. Best is trial 4 with value: 0.46162713061945876.\u001b[0m\n",
      "feature_fraction, val_score: 0.461627: 100%|##########| 7/7 [00:02<00:00,  3.27it/s]\n",
      "num_leaves, val_score: 0.461627:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.461627:   5%|5         | 1/20 [00:00<00:06,  2.72it/s]\u001b[32m[I 2020-12-26 22:01:38,950]\u001b[0m Trial 7 finished with value: 0.47499771467083673 and parameters: {'num_leaves': 162}. Best is trial 7 with value: 0.47499771467083673.\u001b[0m\n",
      "num_leaves, val_score: 0.461627:   5%|5         | 1/20 [00:00<00:06,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.461627:  10%|#         | 2/20 [00:00<00:06,  2.81it/s]\u001b[32m[I 2020-12-26 22:01:39,280]\u001b[0m Trial 8 finished with value: 0.4701051879238895 and parameters: {'num_leaves': 77}. Best is trial 8 with value: 0.4701051879238895.\u001b[0m\n",
      "num_leaves, val_score: 0.461627:  10%|#         | 2/20 [00:00<00:06,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.461627:  15%|#5        | 3/20 [00:01<00:06,  2.82it/s]\u001b[32m[I 2020-12-26 22:01:39,629]\u001b[0m Trial 9 finished with value: 0.4716177758172439 and parameters: {'num_leaves': 79}. Best is trial 8 with value: 0.4701051879238895.\u001b[0m\n",
      "num_leaves, val_score: 0.461627:  15%|#5        | 3/20 [00:01<00:06,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.461627:  20%|##        | 4/20 [00:01<00:06,  2.60it/s]\u001b[32m[I 2020-12-26 22:01:40,084]\u001b[0m Trial 10 finished with value: 0.479406407559271 and parameters: {'num_leaves': 254}. Best is trial 8 with value: 0.4701051879238895.\u001b[0m\n",
      "num_leaves, val_score: 0.461627:  20%|##        | 4/20 [00:01<00:06,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.459039:  25%|##5       | 5/20 [00:01<00:05,  2.90it/s]\u001b[32m[I 2020-12-26 22:01:40,334]\u001b[0m Trial 11 finished with value: 0.4590389211837704 and parameters: {'num_leaves': 11}. Best is trial 11 with value: 0.4590389211837704.\u001b[0m\n",
      "num_leaves, val_score: 0.458303:  30%|###       | 6/20 [00:02<00:04,  3.15it/s]\u001b[32m[I 2020-12-26 22:01:40,588]\u001b[0m Trial 12 finished with value: 0.45830276979422885 and parameters: {'num_leaves': 24}. Best is trial 12 with value: 0.45830276979422885.\u001b[0m\n",
      "num_leaves, val_score: 0.458303:  30%|###       | 6/20 [00:02<00:04,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.458303:  35%|###5      | 7/20 [00:02<00:03,  3.56it/s]\u001b[32m[I 2020-12-26 22:01:40,787]\u001b[0m Trial 13 finished with value: 0.47464200691657144 and parameters: {'num_leaves': 5}. Best is trial 12 with value: 0.45830276979422885.\u001b[0m\n",
      "num_leaves, val_score: 0.458303:  35%|###5      | 7/20 [00:02<00:03,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.458303:  40%|####      | 8/20 [00:02<00:03,  3.82it/s]\u001b[32m[I 2020-12-26 22:01:41,003]\u001b[0m Trial 14 finished with value: 0.4696449694730795 and parameters: {'num_leaves': 6}. Best is trial 12 with value: 0.45830276979422885.\u001b[0m\n",
      "num_leaves, val_score: 0.458303:  40%|####      | 8/20 [00:02<00:03,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.458303:  45%|####5     | 9/20 [00:02<00:02,  4.07it/s]\u001b[32m[I 2020-12-26 22:01:41,210]\u001b[0m Trial 15 finished with value: 0.4830523807134565 and parameters: {'num_leaves': 4}. Best is trial 12 with value: 0.45830276979422885.\u001b[0m\n",
      "num_leaves, val_score: 0.458303:  45%|####5     | 9/20 [00:02<00:02,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.458303:  50%|#####     | 10/20 [00:02<00:02,  3.63it/s]\u001b[32m[I 2020-12-26 22:01:41,554]\u001b[0m Trial 16 finished with value: 0.466827546145534 and parameters: {'num_leaves': 64}. Best is trial 12 with value: 0.45830276979422885.\u001b[0m\n",
      "num_leaves, val_score: 0.458303:  50%|#####     | 10/20 [00:02<00:02,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.458303:  55%|#####5    | 11/20 [00:03<00:02,  3.32it/s]\u001b[32m[I 2020-12-26 22:01:41,915]\u001b[0m Trial 17 finished with value: 0.47358324993689205 and parameters: {'num_leaves': 154}. Best is trial 12 with value: 0.45830276979422885.\u001b[0m\n",
      "num_leaves, val_score: 0.458303:  60%|######    | 12/20 [00:03<00:02,  3.44it/s]\u001b[32m[I 2020-12-26 22:01:42,182]\u001b[0m Trial 18 finished with value: 0.46302961127294173 and parameters: {'num_leaves': 39}. Best is trial 12 with value: 0.45830276979422885.\u001b[0m\n",
      "num_leaves, val_score: 0.458303:  60%|######    | 12/20 [00:03<00:02,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.458303:  65%|######5   | 13/20 [00:04<00:02,  2.88it/s]\u001b[32m[I 2020-12-26 22:01:42,663]\u001b[0m Trial 19 finished with value: 0.47946648196541986 and parameters: {'num_leaves': 227}. Best is trial 12 with value: 0.45830276979422885.\u001b[0m\n",
      "num_leaves, val_score: 0.458303:  65%|######5   | 13/20 [00:04<00:02,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.458303:  70%|#######   | 14/20 [00:04<00:02,  2.75it/s]\u001b[32m[I 2020-12-26 22:01:43,064]\u001b[0m Trial 20 finished with value: 0.47490284905888075 and parameters: {'num_leaves': 119}. Best is trial 12 with value: 0.45830276979422885.\u001b[0m\n",
      "num_leaves, val_score: 0.458303:  70%|#######   | 14/20 [00:04<00:02,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.458303:  75%|#######5  | 15/20 [00:04<00:01,  2.87it/s]\u001b[32m[I 2020-12-26 22:01:43,378]\u001b[0m Trial 21 finished with value: 0.46038185888500416 and parameters: {'num_leaves': 35}. Best is trial 12 with value: 0.45830276979422885.\u001b[0m\n",
      "num_leaves, val_score: 0.458303:  75%|#######5  | 15/20 [00:04<00:01,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457719:  80%|########  | 16/20 [00:05<00:01,  3.03it/s]\u001b[32m[I 2020-12-26 22:01:43,664]\u001b[0m Trial 22 finished with value: 0.45771889702268875 and parameters: {'num_leaves': 26}. Best is trial 22 with value: 0.45771889702268875.\u001b[0m\n",
      "num_leaves, val_score: 0.457719:  80%|########  | 16/20 [00:05<00:01,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457719:  85%|########5 | 17/20 [00:05<00:00,  3.10it/s]\u001b[32m[I 2020-12-26 22:01:43,971]\u001b[0m Trial 23 finished with value: 0.46180963070263537 and parameters: {'num_leaves': 36}. Best is trial 22 with value: 0.45771889702268875.\u001b[0m\n",
      "num_leaves, val_score: 0.457719:  90%|######### | 18/20 [00:05<00:00,  3.26it/s]\u001b[32m[I 2020-12-26 22:01:44,243]\u001b[0m Trial 24 finished with value: 0.4992214717686948 and parameters: {'num_leaves': 3}. Best is trial 22 with value: 0.45771889702268875.\u001b[0m\n",
      "num_leaves, val_score: 0.457719:  90%|######### | 18/20 [00:05<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457719:  95%|#########5| 19/20 [00:06<00:00,  2.61it/s]\u001b[32m[I 2020-12-26 22:01:44,802]\u001b[0m Trial 25 finished with value: 0.4657094901453141 and parameters: {'num_leaves': 47}. Best is trial 22 with value: 0.45771889702268875.\u001b[0m\n",
      "num_leaves, val_score: 0.457719:  95%|#########5| 19/20 [00:06<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.457719: 100%|##########| 20/20 [00:07<00:00,  1.82it/s]\u001b[32m[I 2020-12-26 22:01:45,774]\u001b[0m Trial 26 finished with value: 0.47490284905888075 and parameters: {'num_leaves': 119}. Best is trial 22 with value: 0.45771889702268875.\u001b[0m\n",
      "num_leaves, val_score: 0.457719: 100%|##########| 20/20 [00:07<00:00,  2.78it/s]\n",
      "bagging, val_score: 0.457719:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457719:  10%|#         | 1/10 [00:00<00:05,  1.76it/s]\u001b[32m[I 2020-12-26 22:01:46,383]\u001b[0m Trial 27 finished with value: 0.4600314217084218 and parameters: {'bagging_fraction': 0.7669009882782104, 'bagging_freq': 2}. Best is trial 27 with value: 0.4600314217084218.\u001b[0m\n",
      "bagging, val_score: 0.457719:  10%|#         | 1/10 [00:00<00:05,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457719:  20%|##        | 2/10 [00:01<00:04,  1.87it/s]\u001b[32m[I 2020-12-26 22:01:46,842]\u001b[0m Trial 28 finished with value: 0.47624347149728635 and parameters: {'bagging_fraction': 0.40185560899242667, 'bagging_freq': 7}. Best is trial 27 with value: 0.4600314217084218.\u001b[0m\n",
      "bagging, val_score: 0.457719:  20%|##        | 2/10 [00:01<00:04,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457719:  30%|###       | 3/10 [00:01<00:03,  1.96it/s]\u001b[32m[I 2020-12-26 22:01:47,292]\u001b[0m Trial 29 finished with value: 0.47683847430287146 and parameters: {'bagging_fraction': 0.4274939358532492, 'bagging_freq': 7}. Best is trial 27 with value: 0.4600314217084218.\u001b[0m\n",
      "bagging, val_score: 0.457719:  30%|###       | 3/10 [00:01<00:03,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457393:  40%|####      | 4/10 [00:02<00:03,  1.86it/s]\u001b[32m[I 2020-12-26 22:01:47,895]\u001b[0m Trial 30 finished with value: 0.45739300151771667 and parameters: {'bagging_fraction': 0.9939230801569312, 'bagging_freq': 1}. Best is trial 30 with value: 0.45739300151771667.\u001b[0m\n",
      "bagging, val_score: 0.457393:  40%|####      | 4/10 [00:02<00:03,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457393:  50%|#####     | 5/10 [00:02<00:02,  2.04it/s]\u001b[32m[I 2020-12-26 22:01:48,275]\u001b[0m Trial 31 finished with value: 0.4589506315658284 and parameters: {'bagging_fraction': 0.9743283466674102, 'bagging_freq': 1}. Best is trial 30 with value: 0.45739300151771667.\u001b[0m\n",
      "bagging, val_score: 0.457393:  50%|#####     | 5/10 [00:02<00:02,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457393:  60%|######    | 6/10 [00:02<00:01,  2.34it/s]\u001b[32m[I 2020-12-26 22:01:48,552]\u001b[0m Trial 32 finished with value: 0.4602231878590459 and parameters: {'bagging_fraction': 0.9763849214200636, 'bagging_freq': 1}. Best is trial 30 with value: 0.45739300151771667.\u001b[0m\n",
      "bagging, val_score: 0.457393:  60%|######    | 6/10 [00:02<00:01,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457393:  70%|#######   | 7/10 [00:03<00:01,  2.51it/s]\u001b[32m[I 2020-12-26 22:01:48,882]\u001b[0m Trial 33 finished with value: 0.4589640463514232 and parameters: {'bagging_fraction': 0.9910028382352865, 'bagging_freq': 3}. Best is trial 30 with value: 0.45739300151771667.\u001b[0m\n",
      "bagging, val_score: 0.457393:  70%|#######   | 7/10 [00:03<00:01,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457393:  80%|########  | 8/10 [00:03<00:00,  2.78it/s]\u001b[32m[I 2020-12-26 22:01:49,155]\u001b[0m Trial 34 finished with value: 0.4599585282531859 and parameters: {'bagging_fraction': 0.8360754455541468, 'bagging_freq': 1}. Best is trial 30 with value: 0.45739300151771667.\u001b[0m\n",
      "bagging, val_score: 0.457393:  80%|########  | 8/10 [00:03<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.457393:  90%|######### | 9/10 [00:03<00:00,  2.85it/s]\u001b[32m[I 2020-12-26 22:01:49,485]\u001b[0m Trial 35 finished with value: 0.4574014202777161 and parameters: {'bagging_fraction': 0.9982388222915205, 'bagging_freq': 5}. Best is trial 30 with value: 0.45739300151771667.\u001b[0m\n",
      "bagging, val_score: 0.457393: 100%|##########| 10/10 [00:03<00:00,  3.10it/s]\u001b[32m[I 2020-12-26 22:01:49,741]\u001b[0m Trial 36 finished with value: 0.46709750922177734 and parameters: {'bagging_fraction': 0.5748599192990892, 'bagging_freq': 5}. Best is trial 30 with value: 0.45739300151771667.\u001b[0m\n",
      "bagging, val_score: 0.457393: 100%|##########| 10/10 [00:03<00:00,  2.54it/s]\n",
      "feature_fraction_stage2, val_score: 0.457393:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.457393:  33%|###3      | 1/3 [00:00<00:00,  4.15it/s]\u001b[32m[I 2020-12-26 22:01:49,992]\u001b[0m Trial 37 finished with value: 0.46527685789919804 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.46527685789919804.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.457393:  33%|###3      | 1/3 [00:00<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n",
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.457393:  67%|######6   | 2/3 [00:00<00:00,  3.80it/s]\u001b[32m[I 2020-12-26 22:01:50,306]\u001b[0m Trial 38 finished with value: 0.45739300151771667 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 38 with value: 0.45739300151771667.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.457393:  67%|######6   | 2/3 [00:00<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.457393: 100%|##########| 3/3 [00:00<00:00,  3.55it/s]\u001b[32m[I 2020-12-26 22:01:50,633]\u001b[0m Trial 39 finished with value: 0.4624014768843208 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 38 with value: 0.45739300151771667.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.457393: 100%|##########| 3/3 [00:00<00:00,  3.37it/s]\n",
      "regularization_factors, val_score: 0.457393:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457393:   5%|5         | 1/20 [00:00<00:05,  3.29it/s]\u001b[32m[I 2020-12-26 22:01:50,947]\u001b[0m Trial 40 finished with value: 0.45793121028880684 and parameters: {'lambda_l1': 0.018476204261303412, 'lambda_l2': 2.9290409079515857e-06}. Best is trial 40 with value: 0.45793121028880684.\u001b[0m\n",
      "regularization_factors, val_score: 0.457393:   5%|5         | 1/20 [00:00<00:05,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457393:  10%|#         | 2/20 [00:00<00:05,  3.26it/s]\u001b[32m[I 2020-12-26 22:01:51,264]\u001b[0m Trial 41 finished with value: 0.46047499480692233 and parameters: {'lambda_l1': 0.04918827501401617, 'lambda_l2': 1.6475403741721538e-06}. Best is trial 40 with value: 0.45793121028880684.\u001b[0m\n",
      "regularization_factors, val_score: 0.457393:  10%|#         | 2/20 [00:00<00:05,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457393:  15%|#5        | 3/20 [00:00<00:05,  3.24it/s]\u001b[32m[I 2020-12-26 22:01:51,573]\u001b[0m Trial 42 finished with value: 0.46007687696889615 and parameters: {'lambda_l1': 1.8737273524237654e-06, 'lambda_l2': 0.023466562234686326}. Best is trial 40 with value: 0.45793121028880684.\u001b[0m\n",
      "regularization_factors, val_score: 0.457393:  15%|#5        | 3/20 [00:00<00:05,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457393:  20%|##        | 4/20 [00:01<00:04,  3.22it/s]\u001b[32m[I 2020-12-26 22:01:51,890]\u001b[0m Trial 43 finished with value: 0.4604743618626936 and parameters: {'lambda_l1': 2.746864724865657, 'lambda_l2': 1.759264251010728e-08}. Best is trial 40 with value: 0.45793121028880684.\u001b[0m\n",
      "regularization_factors, val_score: 0.457393:  20%|##        | 4/20 [00:01<00:04,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457393:  25%|##5       | 5/20 [00:01<00:04,  3.31it/s]\u001b[32m[I 2020-12-26 22:01:52,172]\u001b[0m Trial 44 finished with value: 0.45739296007016406 and parameters: {'lambda_l1': 0.0007224823687284483, 'lambda_l2': 3.315761375263055e-05}. Best is trial 44 with value: 0.45739296007016406.\u001b[0m\n",
      "regularization_factors, val_score: 0.457393:  25%|##5       | 5/20 [00:01<00:04,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457393:  30%|###       | 6/20 [00:01<00:04,  3.15it/s]\u001b[32m[I 2020-12-26 22:01:52,524]\u001b[0m Trial 45 finished with value: 0.46245809231438956 and parameters: {'lambda_l1': 6.352506715096712e-06, 'lambda_l2': 2.3055049305520976}. Best is trial 44 with value: 0.45739296007016406.\u001b[0m\n",
      "regularization_factors, val_score: 0.457393:  30%|###       | 6/20 [00:01<00:04,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457393:  35%|###5      | 7/20 [00:02<00:04,  3.10it/s]\u001b[32m[I 2020-12-26 22:01:52,858]\u001b[0m Trial 46 finished with value: 0.4573930452943918 and parameters: {'lambda_l1': 0.00029726076478878795, 'lambda_l2': 0.0008405798715123869}. Best is trial 44 with value: 0.45739296007016406.\u001b[0m\n",
      "regularization_factors, val_score: 0.457393:  35%|###5      | 7/20 [00:02<00:04,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457393:  40%|####      | 8/20 [00:02<00:03,  3.23it/s]\u001b[32m[I 2020-12-26 22:01:53,139]\u001b[0m Trial 47 finished with value: 0.45739299048303955 and parameters: {'lambda_l1': 0.000728308323393901, 'lambda_l2': 0.0004510247842097569}. Best is trial 44 with value: 0.45739296007016406.\u001b[0m\n",
      "regularization_factors, val_score: 0.457393:  40%|####      | 8/20 [00:02<00:03,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457393:  45%|####5     | 9/20 [00:02<00:03,  3.27it/s]\u001b[32m[I 2020-12-26 22:01:53,437]\u001b[0m Trial 48 finished with value: 0.45739299404840333 and parameters: {'lambda_l1': 0.0006128725930570847, 'lambda_l2': 0.00040536305875498146}. Best is trial 44 with value: 0.45739296007016406.\u001b[0m\n",
      "regularization_factors, val_score: 0.457393:  45%|####5     | 9/20 [00:02<00:03,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457393:  50%|#####     | 10/20 [00:03<00:03,  3.22it/s]\u001b[32m[I 2020-12-26 22:01:53,759]\u001b[0m Trial 49 finished with value: 0.4573929718338364 and parameters: {'lambda_l1': 0.0006303360883758201, 'lambda_l2': 0.00011675018293932198}. Best is trial 44 with value: 0.45739296007016406.\u001b[0m\n",
      "regularization_factors, val_score: 0.457393:  50%|#####     | 10/20 [00:03<00:03,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457393:  55%|#####5    | 11/20 [00:03<00:02,  3.28it/s]\u001b[32m[I 2020-12-26 22:01:54,049]\u001b[0m Trial 50 finished with value: 0.45739297291131664 and parameters: {'lambda_l1': 0.0006496400617357773, 'lambda_l2': 0.00014754318415927532}. Best is trial 44 with value: 0.45739296007016406.\u001b[0m\n",
      "regularization_factors, val_score: 0.457393:  55%|#####5    | 11/20 [00:03<00:02,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457393:  60%|######    | 12/20 [00:03<00:02,  3.27it/s]\u001b[32m[I 2020-12-26 22:01:54,363]\u001b[0m Trial 51 finished with value: 0.4573929882852249 and parameters: {'lambda_l1': 0.00037483086707593464, 'lambda_l2': 0.0001297142359825842}. Best is trial 44 with value: 0.45739296007016406.\u001b[0m\n",
      "regularization_factors, val_score: 0.457393:  60%|######    | 12/20 [00:03<00:02,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457393:  65%|######5   | 13/20 [00:04<00:02,  3.25it/s]\u001b[32m[I 2020-12-26 22:01:54,670]\u001b[0m Trial 52 finished with value: 0.45739295997920054 and parameters: {'lambda_l1': 0.000788959667478624, 'lambda_l2': 8.621293232362783e-05}. Best is trial 52 with value: 0.45739295997920054.\u001b[0m\n",
      "regularization_factors, val_score: 0.457393:  65%|######5   | 13/20 [00:04<00:02,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457393:  70%|#######   | 14/20 [00:04<00:01,  3.25it/s]\u001b[32m[I 2020-12-26 22:01:54,977]\u001b[0m Trial 53 finished with value: 0.4573929727170898 and parameters: {'lambda_l1': 0.0005150679681998052, 'lambda_l2': 3.390023570838119e-05}. Best is trial 52 with value: 0.45739295997920054.\u001b[0m\n",
      "regularization_factors, val_score: 0.457393:  70%|#######   | 14/20 [00:04<00:01,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457393:  75%|#######5  | 15/20 [00:04<00:01,  3.23it/s]\u001b[32m[I 2020-12-26 22:01:55,302]\u001b[0m Trial 54 finished with value: 0.4573929812016459 and parameters: {'lambda_l1': 0.000353284847781535, 'lambda_l2': 1.5807158976376876e-05}. Best is trial 52 with value: 0.45739295997920054.\u001b[0m\n",
      "regularization_factors, val_score: 0.457393:  75%|#######5  | 15/20 [00:04<00:01,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.457393:  80%|########  | 16/20 [00:04<00:01,  3.15it/s]\u001b[32m[I 2020-12-26 22:01:55,626]\u001b[0m Trial 55 finished with value: 0.4573929485755469 and parameters: {'lambda_l1': 0.000885497738925824, 'lambda_l2': 1.1212797893201144e-05}. Best is trial 55 with value: 0.4573929485755469.\u001b[0m\n",
      "regularization_factors, val_score: 0.457393:  80%|########  | 16/20 [00:04<00:01,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.455861:  85%|########5 | 17/20 [00:05<00:00,  3.21it/s]\u001b[32m[I 2020-12-26 22:01:55,924]\u001b[0m Trial 56 finished with value: 0.4558607501297309 and parameters: {'lambda_l1': 0.006453407799169357, 'lambda_l2': 2.5162794741411746e-05}. Best is trial 56 with value: 0.4558607501297309.\u001b[0m\n",
      "regularization_factors, val_score: 0.455861:  85%|########5 | 17/20 [00:05<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.455547:  90%|######### | 18/20 [00:05<00:00,  3.05it/s]\u001b[32m[I 2020-12-26 22:01:56,288]\u001b[0m Trial 57 finished with value: 0.45554709975305807 and parameters: {'lambda_l1': 0.023190297643106837, 'lambda_l2': 1.0527024190097006e-05}. Best is trial 57 with value: 0.45554709975305807.\u001b[0m\n",
      "regularization_factors, val_score: 0.455547:  90%|######### | 18/20 [00:05<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.455547:  95%|#########5| 19/20 [00:05<00:00,  2.99it/s]\u001b[32m[I 2020-12-26 22:01:56,641]\u001b[0m Trial 58 finished with value: 0.4608589430069801 and parameters: {'lambda_l1': 0.02936304678677622, 'lambda_l2': 4.6804363020722035e-06}. Best is trial 57 with value: 0.45554709975305807.\u001b[0m\n",
      "regularization_factors, val_score: 0.455547:  95%|#########5| 19/20 [00:06<00:00,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.455547: 100%|##########| 20/20 [00:06<00:00,  3.02it/s]\u001b[32m[I 2020-12-26 22:01:56,963]\u001b[0m Trial 59 finished with value: 0.4562320089945991 and parameters: {'lambda_l1': 0.008287957949828933, 'lambda_l2': 3.6217613566808293e-07}. Best is trial 57 with value: 0.45554709975305807.\u001b[0m\n",
      "regularization_factors, val_score: 0.455547: 100%|##########| 20/20 [00:06<00:00,  3.16it/s]\n",
      "min_data_in_leaf, val_score: 0.455547:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.455547:  20%|##        | 1/5 [00:00<00:01,  3.37it/s]\u001b[32m[I 2020-12-26 22:01:57,274]\u001b[0m Trial 60 finished with value: 0.46100108743663415 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.46100108743663415.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.455547:  20%|##        | 1/5 [00:00<00:01,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.455547:  40%|####      | 2/5 [00:00<00:00,  3.25it/s]\u001b[32m[I 2020-12-26 22:01:57,607]\u001b[0m Trial 61 finished with value: 0.459129234522067 and parameters: {'min_child_samples': 5}. Best is trial 61 with value: 0.459129234522067.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.455547:  40%|####      | 2/5 [00:00<00:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.455547:  60%|######    | 3/5 [00:00<00:00,  3.32it/s]\u001b[32m[I 2020-12-26 22:01:57,900]\u001b[0m Trial 62 finished with value: 0.4605353205382642 and parameters: {'min_child_samples': 25}. Best is trial 61 with value: 0.459129234522067.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.455547:  60%|######    | 3/5 [00:00<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.455547:  80%|########  | 4/5 [00:01<00:00,  3.05it/s]\u001b[32m[I 2020-12-26 22:01:58,283]\u001b[0m Trial 63 finished with value: 0.4581469109084298 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.4581469109084298.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.455547:  80%|########  | 4/5 [00:01<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4236, number of negative: 4200\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4038\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502134 -> initscore=0.008535\n",
      "[LightGBM] [Info] Start training from score 0.008535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.455547: 100%|##########| 5/5 [00:01<00:00,  3.11it/s]\u001b[32m[I 2020-12-26 22:01:58,590]\u001b[0m Trial 64 finished with value: 0.4592555488433074 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.4581469109084298.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.455547: 100%|##########| 5/5 [00:01<00:00,  3.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category1</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goal_min</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_figure</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_paragraph</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length_of_text</th>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importance\n",
       "country                      50\n",
       "category1                    76\n",
       "duration                    107\n",
       "goal_min                    142\n",
       "number_of_figure            118\n",
       "number_of_paragraph          77\n",
       "length_of_text              131\n",
       "0                            73\n",
       "1                            67\n",
       "2                            76\n",
       "3                            65\n",
       "4                            43\n",
       "5                            62\n",
       "6                            26\n",
       "7                            47\n",
       "8                            31\n",
       "9                            19\n",
       "10                           49\n",
       "11                           54\n",
       "12                           34\n",
       "13                           46\n",
       "14                           45\n",
       "15                           43\n",
       "16                           42\n",
       "17                           48\n",
       "18                           53\n",
       "19                           57\n",
       "20                           48\n",
       "21                           49\n",
       "22                           66\n",
       "23                           57\n",
       "24                           49"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-26 22:01:58,700]\u001b[0m A new study created in memory with name: no-name-081966a8-41c7-492a-8120-d094527bab15\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/Applications/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.442094:  14%|#4        | 1/7 [00:00<00:02,  2.84it/s]\u001b[32m[I 2020-12-26 22:01:59,059]\u001b[0m Trial 0 finished with value: 0.44209422799223375 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.44209422799223375.\u001b[0m\n",
      "feature_fraction, val_score: 0.442094:  14%|#4        | 1/7 [00:00<00:02,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.442094:  29%|##8       | 2/7 [00:00<00:01,  2.91it/s]\u001b[32m[I 2020-12-26 22:01:59,383]\u001b[0m Trial 1 finished with value: 0.4450248340896686 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.44209422799223375.\u001b[0m\n",
      "feature_fraction, val_score: 0.442094:  29%|##8       | 2/7 [00:00<00:01,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.442094:  43%|####2     | 3/7 [00:00<00:01,  3.04it/s]\u001b[32m[I 2020-12-26 22:01:59,684]\u001b[0m Trial 2 finished with value: 0.4468614749683676 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.44209422799223375.\u001b[0m\n",
      "feature_fraction, val_score: 0.442094:  57%|#####7    | 4/7 [00:01<00:00,  3.27it/s]\u001b[32m[I 2020-12-26 22:01:59,931]\u001b[0m Trial 3 finished with value: 0.4485157324028264 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.44209422799223375.\u001b[0m\n",
      "feature_fraction, val_score: 0.442094:  57%|#####7    | 4/7 [00:01<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.442094:  71%|#######1  | 5/7 [00:01<00:00,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-26 22:02:00,199]\u001b[0m Trial 4 finished with value: 0.44431313651480275 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.44209422799223375.\u001b[0m\n",
      "feature_fraction, val_score: 0.442094:  86%|########5 | 6/7 [00:01<00:00,  3.65it/s]\u001b[32m[I 2020-12-26 22:02:00,426]\u001b[0m Trial 5 finished with value: 0.4488236988175425 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.44209422799223375.\u001b[0m\n",
      "feature_fraction, val_score: 0.442094:  86%|########5 | 6/7 [00:01<00:00,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.442094: 100%|##########| 7/7 [00:02<00:00,  3.49it/s]\u001b[32m[I 2020-12-26 22:02:00,741]\u001b[0m Trial 6 finished with value: 0.4446451962615986 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.44209422799223375.\u001b[0m\n",
      "feature_fraction, val_score: 0.442094: 100%|##########| 7/7 [00:02<00:00,  3.43it/s]\n",
      "num_leaves, val_score: 0.442094:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.442094:   5%|5         | 1/20 [00:00<00:08,  2.31it/s]\u001b[32m[I 2020-12-26 22:02:01,184]\u001b[0m Trial 7 finished with value: 0.4596067049420019 and parameters: {'num_leaves': 139}. Best is trial 7 with value: 0.4596067049420019.\u001b[0m\n",
      "num_leaves, val_score: 0.442094:   5%|5         | 1/20 [00:00<00:08,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.442094:  10%|#         | 2/20 [00:00<00:07,  2.28it/s]\u001b[32m[I 2020-12-26 22:02:01,635]\u001b[0m Trial 8 finished with value: 0.46308440586060573 and parameters: {'num_leaves': 187}. Best is trial 7 with value: 0.4596067049420019.\u001b[0m\n",
      "num_leaves, val_score: 0.442094:  10%|#         | 2/20 [00:00<00:07,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.442094:  15%|#5        | 3/20 [00:01<00:07,  2.18it/s]\u001b[32m[I 2020-12-26 22:02:02,141]\u001b[0m Trial 9 finished with value: 0.46437531463657256 and parameters: {'num_leaves': 243}. Best is trial 7 with value: 0.4596067049420019.\u001b[0m\n",
      "num_leaves, val_score: 0.441644:  20%|##        | 4/20 [00:01<00:06,  2.45it/s]\u001b[32m[I 2020-12-26 22:02:02,429]\u001b[0m Trial 10 finished with value: 0.44164421861839465 and parameters: {'num_leaves': 10}. Best is trial 10 with value: 0.44164421861839465.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.441644:  20%|##        | 4/20 [00:01<00:06,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.440783:  25%|##5       | 5/20 [00:01<00:05,  2.66it/s]\u001b[32m[I 2020-12-26 22:02:02,733]\u001b[0m Trial 11 finished with value: 0.44078328600312994 and parameters: {'num_leaves': 20}. Best is trial 11 with value: 0.44078328600312994.\u001b[0m\n",
      "num_leaves, val_score: 0.440783:  30%|###       | 6/20 [00:02<00:04,  2.90it/s]\u001b[32m[I 2020-12-26 22:02:03,003]\u001b[0m Trial 12 finished with value: 0.44478879827230206 and parameters: {'num_leaves': 12}. Best is trial 11 with value: 0.44078328600312994.\u001b[0m\n",
      "num_leaves, val_score: 0.440783:  30%|###       | 6/20 [00:02<00:04,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.440783:  35%|###5      | 7/20 [00:02<00:03,  3.26it/s]\u001b[32m[I 2020-12-26 22:02:03,221]\u001b[0m Trial 13 finished with value: 0.4530343738097687 and parameters: {'num_leaves': 6}. Best is trial 11 with value: 0.44078328600312994.\u001b[0m\n",
      "num_leaves, val_score: 0.440783:  35%|###5      | 7/20 [00:02<00:03,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.440783:  40%|####      | 8/20 [00:02<00:03,  3.10it/s]\u001b[32m[I 2020-12-26 22:02:03,584]\u001b[0m Trial 14 finished with value: 0.4492406381058509 and parameters: {'num_leaves': 56}. Best is trial 11 with value: 0.44078328600312994.\u001b[0m\n",
      "num_leaves, val_score: 0.440783:  40%|####      | 8/20 [00:02<00:03,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.440783:  45%|####5     | 9/20 [00:03<00:03,  2.87it/s]\u001b[32m[I 2020-12-26 22:02:03,991]\u001b[0m Trial 15 finished with value: 0.45118346029458495 and parameters: {'num_leaves': 69}. Best is trial 11 with value: 0.44078328600312994.\u001b[0m\n",
      "num_leaves, val_score: 0.440783:  45%|####5     | 9/20 [00:03<00:03,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.440783:  50%|#####     | 10/20 [00:03<00:03,  2.70it/s]\u001b[32m[I 2020-12-26 22:02:04,416]\u001b[0m Trial 16 finished with value: 0.44306251250505024 and parameters: {'num_leaves': 58}. Best is trial 11 with value: 0.44078328600312994.\u001b[0m\n",
      "num_leaves, val_score: 0.440783:  55%|#####5    | 11/20 [00:03<00:03,  2.95it/s]\u001b[32m[I 2020-12-26 22:02:04,679]\u001b[0m Trial 17 finished with value: 0.44642236966964194 and parameters: {'num_leaves': 13}. Best is trial 11 with value: 0.44078328600312994.\u001b[0m\n",
      "num_leaves, val_score: 0.440783:  55%|#####5    | 11/20 [00:03<00:03,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.440783:  60%|######    | 12/20 [00:04<00:02,  2.70it/s]\u001b[32m[I 2020-12-26 22:02:05,123]\u001b[0m Trial 18 finished with value: 0.4532469038879171 and parameters: {'num_leaves': 97}. Best is trial 11 with value: 0.44078328600312994.\u001b[0m\n",
      "num_leaves, val_score: 0.440783:  65%|######5   | 13/20 [00:04<00:02,  3.05it/s]\u001b[32m[I 2020-12-26 22:02:05,349]\u001b[0m Trial 19 finished with value: 0.45987565784049306 and parameters: {'num_leaves': 5}. Best is trial 11 with value: 0.44078328600312994.\u001b[0m\n",
      "num_leaves, val_score: 0.440783:  65%|######5   | 13/20 [00:04<00:02,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.440783:  70%|#######   | 14/20 [00:05<00:02,  2.79it/s]\u001b[32m[I 2020-12-26 22:02:05,781]\u001b[0m Trial 20 finished with value: 0.45755694908551414 and parameters: {'num_leaves': 134}. Best is trial 11 with value: 0.44078328600312994.\u001b[0m\n",
      "num_leaves, val_score: 0.440783:  70%|#######   | 14/20 [00:05<00:02,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.440783:  75%|#######5  | 15/20 [00:05<00:01,  2.71it/s]\u001b[32m[I 2020-12-26 22:02:06,175]\u001b[0m Trial 21 finished with value: 0.4466453976186747 and parameters: {'num_leaves': 41}. Best is trial 11 with value: 0.44078328600312994.\u001b[0m\n",
      "num_leaves, val_score: 0.440783:  75%|#######5  | 15/20 [00:05<00:01,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.440783:  80%|########  | 16/20 [00:05<00:01,  2.70it/s]\u001b[32m[I 2020-12-26 22:02:06,550]\u001b[0m Trial 22 finished with value: 0.45690979448797736 and parameters: {'num_leaves': 96}. Best is trial 11 with value: 0.44078328600312994.\u001b[0m\n",
      "num_leaves, val_score: 0.440783:  80%|########  | 16/20 [00:05<00:01,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.440783:  85%|########5 | 17/20 [00:06<00:01,  2.46it/s]\u001b[32m[I 2020-12-26 22:02:07,038]\u001b[0m Trial 23 finished with value: 0.4635775097016533 and parameters: {'num_leaves': 183}. Best is trial 11 with value: 0.44078328600312994.\u001b[0m\n",
      "num_leaves, val_score: 0.440783:  85%|########5 | 17/20 [00:06<00:01,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.440783:  90%|######### | 18/20 [00:06<00:00,  2.58it/s]\u001b[32m[I 2020-12-26 22:02:07,381]\u001b[0m Trial 24 finished with value: 0.4442101551510782 and parameters: {'num_leaves': 32}. Best is trial 11 with value: 0.44078328600312994.\u001b[0m\n",
      "num_leaves, val_score: 0.440783:  90%|######### | 18/20 [00:06<00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.440783:  95%|#########5| 19/20 [00:07<00:00,  2.48it/s]\u001b[32m[I 2020-12-26 22:02:07,822]\u001b[0m Trial 25 finished with value: 0.4532469038879171 and parameters: {'num_leaves': 97}. Best is trial 11 with value: 0.44078328600312994.\u001b[0m\n",
      "num_leaves, val_score: 0.440783:  95%|#########5| 19/20 [00:07<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.440783: 100%|##########| 20/20 [00:07<00:00,  2.32it/s]\u001b[32m[I 2020-12-26 22:02:08,317]\u001b[0m Trial 26 finished with value: 0.464210162140779 and parameters: {'num_leaves': 247}. Best is trial 11 with value: 0.44078328600312994.\u001b[0m\n",
      "num_leaves, val_score: 0.440783: 100%|##########| 20/20 [00:07<00:00,  2.64it/s]\n",
      "bagging, val_score: 0.440783:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.440783:  10%|#         | 1/10 [00:00<00:03,  2.86it/s]\u001b[32m[I 2020-12-26 22:02:08,678]\u001b[0m Trial 27 finished with value: 0.4419386773901636 and parameters: {'bagging_fraction': 0.7682665223340456, 'bagging_freq': 7}. Best is trial 27 with value: 0.4419386773901636.\u001b[0m\n",
      "bagging, val_score: 0.440783:  10%|#         | 1/10 [00:00<00:03,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.440783:  20%|##        | 2/10 [00:00<00:02,  2.90it/s]\u001b[32m[I 2020-12-26 22:02:09,011]\u001b[0m Trial 28 finished with value: 0.4438750252045741 and parameters: {'bagging_fraction': 0.7762755134231677, 'bagging_freq': 7}. Best is trial 27 with value: 0.4419386773901636.\u001b[0m\n",
      "bagging, val_score: 0.440783:  20%|##        | 2/10 [00:00<00:02,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.440783:  30%|###       | 3/10 [00:00<00:02,  3.01it/s]\u001b[32m[I 2020-12-26 22:02:09,319]\u001b[0m Trial 29 finished with value: 0.4429554750395506 and parameters: {'bagging_fraction': 0.48599266059444773, 'bagging_freq': 6}. Best is trial 27 with value: 0.4419386773901636.\u001b[0m\n",
      "bagging, val_score: 0.440783:  30%|###       | 3/10 [00:00<00:02,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.439169:  40%|####      | 4/10 [00:01<00:02,  2.96it/s]\u001b[32m[I 2020-12-26 22:02:09,663]\u001b[0m Trial 30 finished with value: 0.43916889494696104 and parameters: {'bagging_fraction': 0.9738092494513454, 'bagging_freq': 1}. Best is trial 30 with value: 0.43916889494696104.\u001b[0m\n",
      "bagging, val_score: 0.439169:  40%|####      | 4/10 [00:01<00:02,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.439053:  50%|#####     | 5/10 [00:01<00:01,  3.05it/s]\u001b[32m[I 2020-12-26 22:02:09,968]\u001b[0m Trial 31 finished with value: 0.43905320579277557 and parameters: {'bagging_fraction': 0.9643266478155181, 'bagging_freq': 1}. Best is trial 31 with value: 0.43905320579277557.\u001b[0m\n",
      "bagging, val_score: 0.439053:  60%|######    | 6/10 [00:01<00:01,  3.21it/s]\u001b[32m[I 2020-12-26 22:02:10,242]\u001b[0m Trial 32 finished with value: 0.4428947557758697 and parameters: {'bagging_fraction': 0.9541608302323883, 'bagging_freq': 1}. Best is trial 31 with value: 0.43905320579277557.\u001b[0m\n",
      "bagging, val_score: 0.439053:  60%|######    | 6/10 [00:01<00:01,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n",
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.439053:  70%|#######   | 7/10 [00:02<00:00,  3.11it/s]\u001b[32m[I 2020-12-26 22:02:10,588]\u001b[0m Trial 33 finished with value: 0.4391728465623093 and parameters: {'bagging_fraction': 0.9954232131071816, 'bagging_freq': 1}. Best is trial 31 with value: 0.43905320579277557.\u001b[0m\n",
      "bagging, val_score: 0.439053:  70%|#######   | 7/10 [00:02<00:00,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.439053:  80%|########  | 8/10 [00:02<00:00,  3.06it/s]\u001b[32m[I 2020-12-26 22:02:10,926]\u001b[0m Trial 34 finished with value: 0.4427650581797629 and parameters: {'bagging_fraction': 0.983019884934703, 'bagging_freq': 1}. Best is trial 31 with value: 0.43905320579277557.\u001b[0m\n",
      "bagging, val_score: 0.439053:  80%|########  | 8/10 [00:02<00:00,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.439053:  90%|######### | 9/10 [00:02<00:00,  3.07it/s]\u001b[32m[I 2020-12-26 22:02:11,248]\u001b[0m Trial 35 finished with value: 0.44458333609185385 and parameters: {'bagging_fraction': 0.9763323469158459, 'bagging_freq': 2}. Best is trial 31 with value: 0.43905320579277557.\u001b[0m\n",
      "bagging, val_score: 0.439053: 100%|##########| 10/10 [00:03<00:00,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-26 22:02:11,534]\u001b[0m Trial 36 finished with value: 0.44599798749453656 and parameters: {'bagging_fraction': 0.9013551150837144, 'bagging_freq': 3}. Best is trial 31 with value: 0.43905320579277557.\u001b[0m\n",
      "bagging, val_score: 0.439053: 100%|##########| 10/10 [00:03<00:00,  3.11it/s]\n",
      "feature_fraction_stage2, val_score: 0.439053:  17%|#6        | 1/6 [00:00<00:01,  3.78it/s]\u001b[32m[I 2020-12-26 22:02:11,809]\u001b[0m Trial 37 finished with value: 0.44137334896263325 and parameters: {'feature_fraction': 0.7200000000000001}. Best is trial 37 with value: 0.44137334896263325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.439053:  17%|#6        | 1/6 [00:00<00:01,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.439053:  33%|###3      | 2/6 [00:00<00:01,  3.69it/s]\u001b[32m[I 2020-12-26 22:02:12,097]\u001b[0m Trial 38 finished with value: 0.44198066454869717 and parameters: {'feature_fraction': 0.784}. Best is trial 37 with value: 0.44137334896263325.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.439053:  33%|###3      | 2/6 [00:00<00:01,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.439053:  50%|#####     | 3/6 [00:00<00:00,  3.61it/s]\u001b[32m[I 2020-12-26 22:02:12,386]\u001b[0m Trial 39 finished with value: 0.4406661539466924 and parameters: {'feature_fraction': 0.88}. Best is trial 39 with value: 0.4406661539466924.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.439053:  67%|######6   | 4/6 [00:01<00:00,  3.66it/s]\u001b[32m[I 2020-12-26 22:02:12,651]\u001b[0m Trial 40 finished with value: 0.4434179406009173 and parameters: {'feature_fraction': 0.7520000000000001}. Best is trial 39 with value: 0.4406661539466924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.439053:  67%|######6   | 4/6 [00:01<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.439053:  83%|########3 | 5/6 [00:01<00:00,  3.42it/s]\u001b[32m[I 2020-12-26 22:02:12,989]\u001b[0m Trial 41 finished with value: 0.43905320579277557 and parameters: {'feature_fraction': 0.8160000000000001}. Best is trial 41 with value: 0.43905320579277557.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.439053:  83%|########3 | 5/6 [00:01<00:00,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.439053: 100%|##########| 6/6 [00:01<00:00,  3.42it/s]\u001b[32m[I 2020-12-26 22:02:13,287]\u001b[0m Trial 42 finished with value: 0.4400147310289753 and parameters: {'feature_fraction': 0.8480000000000001}. Best is trial 41 with value: 0.43905320579277557.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.439053: 100%|##########| 6/6 [00:01<00:00,  3.42it/s]\n",
      "regularization_factors, val_score: 0.439053:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:   5%|5         | 1/20 [00:00<00:06,  2.74it/s]\u001b[32m[I 2020-12-26 22:02:13,669]\u001b[0m Trial 43 finished with value: 0.44360186585904715 and parameters: {'lambda_l1': 0.0056125070387577835, 'lambda_l2': 0.9006074764322481}. Best is trial 43 with value: 0.44360186585904715.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:   5%|5         | 1/20 [00:00<00:06,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  10%|#         | 2/20 [00:00<00:06,  2.80it/s]\u001b[32m[I 2020-12-26 22:02:14,007]\u001b[0m Trial 44 finished with value: 0.43905320580257895 and parameters: {'lambda_l1': 1.0031555210700113e-08, 'lambda_l2': 2.7215063038647413e-08}. Best is trial 44 with value: 0.43905320580257895.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  10%|#         | 2/20 [00:00<00:06,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  15%|#5        | 3/20 [00:01<00:06,  2.78it/s]\u001b[32m[I 2020-12-26 22:02:14,375]\u001b[0m Trial 45 finished with value: 0.4390532057993325 and parameters: {'lambda_l1': 1.4307444136643502e-08, 'lambda_l2': 1.3088422731214767e-08}. Best is trial 45 with value: 0.4390532057993325.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  15%|#5        | 3/20 [00:01<00:06,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  20%|##        | 4/20 [00:01<00:05,  2.77it/s]\u001b[32m[I 2020-12-26 22:02:14,738]\u001b[0m Trial 46 finished with value: 0.4390532058002923 and parameters: {'lambda_l1': 1.1417067499862591e-08, 'lambda_l2': 1.5112222562350595e-08}. Best is trial 45 with value: 0.4390532057993325.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  20%|##        | 4/20 [00:01<00:05,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  25%|##5       | 5/20 [00:01<00:05,  2.79it/s]\u001b[32m[I 2020-12-26 22:02:15,091]\u001b[0m Trial 47 finished with value: 0.4390532057958546 and parameters: {'lambda_l1': 1.02252688354018e-08, 'lambda_l2': 1.1758288937406482e-08}. Best is trial 47 with value: 0.4390532057958546.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  25%|##5       | 5/20 [00:01<00:05,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  30%|###       | 6/20 [00:02<00:05,  2.70it/s]\u001b[32m[I 2020-12-26 22:02:15,486]\u001b[0m Trial 48 finished with value: 0.4390532058006225 and parameters: {'lambda_l1': 2.3778008209646093e-08, 'lambda_l2': 1.2285299744148097e-08}. Best is trial 47 with value: 0.4390532057958546.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  30%|###       | 6/20 [00:02<00:05,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  35%|###5      | 7/20 [00:02<00:04,  2.74it/s]\u001b[32m[I 2020-12-26 22:02:15,838]\u001b[0m Trial 49 finished with value: 0.4390532057982647 and parameters: {'lambda_l1': 1.5521198266998557e-08, 'lambda_l2': 1.0442414507914806e-08}. Best is trial 47 with value: 0.4390532057958546.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  35%|###5      | 7/20 [00:02<00:04,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  40%|####      | 8/20 [00:02<00:04,  2.77it/s]\u001b[32m[I 2020-12-26 22:02:16,192]\u001b[0m Trial 50 finished with value: 0.4390532085402384 and parameters: {'lambda_l1': 3.4020861242797357e-06, 'lambda_l2': 4.955754506698024e-06}. Best is trial 47 with value: 0.4390532057958546.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  40%|####      | 8/20 [00:02<00:04,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  45%|####5     | 9/20 [00:03<00:03,  2.77it/s]\u001b[32m[I 2020-12-26 22:02:16,552]\u001b[0m Trial 51 finished with value: 0.43905320580045865 and parameters: {'lambda_l1': 1.2312605469585873e-08, 'lambda_l2': 1.76196831076741e-08}. Best is trial 47 with value: 0.4390532057958546.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  45%|####5     | 9/20 [00:03<00:03,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  50%|#####     | 10/20 [00:03<00:03,  2.79it/s]\u001b[32m[I 2020-12-26 22:02:16,903]\u001b[0m Trial 52 finished with value: 0.43905320580114227 and parameters: {'lambda_l1': 1.0071461389600908e-08, 'lambda_l2': 1.681300715767219e-08}. Best is trial 47 with value: 0.4390532057958546.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  50%|#####     | 10/20 [00:03<00:03,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  55%|#####5    | 11/20 [00:03<00:03,  2.80it/s]\u001b[32m[I 2020-12-26 22:02:17,258]\u001b[0m Trial 53 finished with value: 0.4390532063133318 and parameters: {'lambda_l1': 8.713199386073624e-07, 'lambda_l2': 8.170820524155733e-07}. Best is trial 47 with value: 0.4390532057958546.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  55%|#####5    | 11/20 [00:03<00:03,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  60%|######    | 12/20 [00:04<00:02,  2.79it/s]\u001b[32m[I 2020-12-26 22:02:17,619]\u001b[0m Trial 54 finished with value: 0.4390532058981581 and parameters: {'lambda_l1': 4.942983526932959e-07, 'lambda_l2': 1.0318457636786279e-08}. Best is trial 47 with value: 0.4390532057958546.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  60%|######    | 12/20 [00:04<00:02,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  65%|######5   | 13/20 [00:04<00:02,  2.68it/s]\u001b[32m[I 2020-12-26 22:02:18,030]\u001b[0m Trial 55 finished with value: 0.44225767047877235 and parameters: {'lambda_l1': 3.34037344984693, 'lambda_l2': 1.1100131599605738e-06}. Best is trial 47 with value: 0.4390532057958546.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  65%|######5   | 13/20 [00:04<00:02,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  70%|#######   | 14/20 [00:05<00:02,  2.72it/s]\u001b[32m[I 2020-12-26 22:02:18,386]\u001b[0m Trial 56 finished with value: 0.4430942902667281 and parameters: {'lambda_l1': 9.656971423071688e-08, 'lambda_l2': 0.01297305943310951}. Best is trial 47 with value: 0.4390532057958546.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  70%|#######   | 14/20 [00:05<00:02,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  75%|#######5  | 15/20 [00:05<00:01,  2.77it/s]\u001b[32m[I 2020-12-26 22:02:18,728]\u001b[0m Trial 57 finished with value: 0.4390532163087646 and parameters: {'lambda_l1': 4.406026628752168e-05, 'lambda_l2': 2.488531810189592e-07}. Best is trial 47 with value: 0.4390532057958546.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  75%|#######5  | 15/20 [00:05<00:01,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  80%|########  | 16/20 [00:05<00:01,  2.83it/s]\u001b[32m[I 2020-12-26 22:02:19,063]\u001b[0m Trial 58 finished with value: 0.4390532058463321 and parameters: {'lambda_l1': 1.0716747142461477e-08, 'lambda_l2': 1.1035291237296514e-07}. Best is trial 47 with value: 0.4390532057958546.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  80%|########  | 16/20 [00:05<00:01,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  85%|########5 | 17/20 [00:06<00:01,  2.89it/s]\u001b[32m[I 2020-12-26 22:02:19,391]\u001b[0m Trial 59 finished with value: 0.43905321338240255 and parameters: {'lambda_l1': 1.648343475267999e-07, 'lambda_l2': 1.9487459292168054e-05}. Best is trial 47 with value: 0.4390532057958546.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  85%|########5 | 17/20 [00:06<00:01,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  90%|######### | 18/20 [00:06<00:00,  2.88it/s]\u001b[32m[I 2020-12-26 22:02:19,741]\u001b[0m Trial 60 finished with value: 0.4390532058485635 and parameters: {'lambda_l1': 1.4075169939452255e-08, 'lambda_l2': 1.1322591474967324e-07}. Best is trial 47 with value: 0.4390532057958546.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  90%|######### | 18/20 [00:06<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053:  95%|#########5| 19/20 [00:06<00:00,  2.88it/s]\u001b[32m[I 2020-12-26 22:02:20,089]\u001b[0m Trial 61 finished with value: 0.4390532057965289 and parameters: {'lambda_l1': 1.2993813302197156e-08, 'lambda_l2': 1.0821520876389286e-08}. Best is trial 47 with value: 0.4390532057958546.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053:  95%|#########5| 19/20 [00:06<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.439053: 100%|##########| 20/20 [00:07<00:00,  2.88it/s]\u001b[32m[I 2020-12-26 22:02:20,438]\u001b[0m Trial 62 finished with value: 0.43905320581588825 and parameters: {'lambda_l1': 8.85615461321708e-08, 'lambda_l2': 1.067082739947947e-08}. Best is trial 47 with value: 0.4390532057958546.\u001b[0m\n",
      "regularization_factors, val_score: 0.439053: 100%|##########| 20/20 [00:07<00:00,  2.80it/s]\n",
      "min_data_in_leaf, val_score: 0.439053:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.439053:  20%|##        | 1/5 [00:00<00:01,  3.26it/s]\u001b[32m[I 2020-12-26 22:02:20,755]\u001b[0m Trial 63 finished with value: 0.44058042211616777 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.44058042211616777.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.439053:  20%|##        | 1/5 [00:00<00:01,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.439053:  40%|####      | 2/5 [00:00<00:00,  3.05it/s]\u001b[32m[I 2020-12-26 22:02:21,134]\u001b[0m Trial 64 finished with value: 0.44080467740085916 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.44058042211616777.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.439053:  40%|####      | 2/5 [00:00<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.439053:  60%|######    | 3/5 [00:01<00:00,  2.97it/s]\u001b[32m[I 2020-12-26 22:02:21,489]\u001b[0m Trial 65 finished with value: 0.4412279270079824 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.44058042211616777.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.439053:  80%|########  | 4/5 [00:01<00:00,  3.10it/s]\u001b[32m[I 2020-12-26 22:02:21,778]\u001b[0m Trial 66 finished with value: 0.4411088004443505 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.44058042211616777.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.439053:  80%|########  | 4/5 [00:01<00:00,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4250, number of negative: 4186\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3986\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503793 -> initscore=0.015173\n",
      "[LightGBM] [Info] Start training from score 0.015173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.439053: 100%|##########| 5/5 [00:01<00:00,  3.08it/s]\u001b[32m[I 2020-12-26 22:02:22,107]\u001b[0m Trial 67 finished with value: 0.4427709475831549 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.44058042211616777.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.439053: 100%|##########| 5/5 [00:01<00:00,  3.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category1</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goal_min</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_figure</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_paragraph</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length_of_text</th>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importance\n",
       "country                      47\n",
       "category1                    75\n",
       "duration                     97\n",
       "goal_min                    127\n",
       "number_of_figure            125\n",
       "number_of_paragraph          70\n",
       "length_of_text              124\n",
       "0                            47\n",
       "1                            48\n",
       "2                            50\n",
       "3                            32\n",
       "4                            23\n",
       "5                            61\n",
       "6                            24\n",
       "7                            31\n",
       "8                            28\n",
       "9                            24\n",
       "10                           26\n",
       "11                           49\n",
       "12                           21\n",
       "13                           25\n",
       "14                           22\n",
       "15                           20\n",
       "16                           20\n",
       "17                           42\n",
       "18                           41\n",
       "19                           37\n",
       "20                           19\n",
       "21                           29\n",
       "22                           42\n",
       "23                           31\n",
       "24                           44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-26 22:02:22,195]\u001b[0m A new study created in memory with name: no-name-89b888d5-ce57-4198-bc17-6362394a26ab\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/Applications/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.442405:  14%|#4        | 1/7 [00:00<00:02,  2.85it/s]\u001b[32m[I 2020-12-26 22:02:22,555]\u001b[0m Trial 0 finished with value: 0.44240524373182233 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.44240524373182233.\u001b[0m\n",
      "feature_fraction, val_score: 0.442405:  14%|#4        | 1/7 [00:00<00:02,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.442405:  29%|##8       | 2/7 [00:00<00:01,  2.91it/s]\u001b[32m[I 2020-12-26 22:02:22,885]\u001b[0m Trial 1 finished with value: 0.44429689573775777 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.44240524373182233.\u001b[0m\n",
      "feature_fraction, val_score: 0.442405:  29%|##8       | 2/7 [00:00<00:01,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.440269:  43%|####2     | 3/7 [00:00<00:01,  3.05it/s]\u001b[32m[I 2020-12-26 22:02:23,174]\u001b[0m Trial 2 finished with value: 0.4402686657465779 and parameters: {'feature_fraction': 0.4}. Best is trial 2 with value: 0.4402686657465779.\u001b[0m\n",
      "feature_fraction, val_score: 0.440269:  43%|####2     | 3/7 [00:00<00:01,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.440269:  57%|#####7    | 4/7 [00:01<00:00,  3.19it/s]\u001b[32m[I 2020-12-26 22:02:23,455]\u001b[0m Trial 3 finished with value: 0.44104277940729236 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 0.4402686657465779.\u001b[0m\n",
      "feature_fraction, val_score: 0.440269:  57%|#####7    | 4/7 [00:01<00:00,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.440269:  71%|#######1  | 5/7 [00:01<00:00,  2.97it/s]\u001b[32m[I 2020-12-26 22:02:23,845]\u001b[0m Trial 4 finished with value: 0.4408032816574951 and parameters: {'feature_fraction': 0.8}. Best is trial 2 with value: 0.4402686657465779.\u001b[0m\n",
      "feature_fraction, val_score: 0.440269:  71%|#######1  | 5/7 [00:01<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.440269:  86%|########5 | 6/7 [00:01<00:00,  2.92it/s]\u001b[32m[I 2020-12-26 22:02:24,202]\u001b[0m Trial 5 finished with value: 0.44235817341852013 and parameters: {'feature_fraction': 0.6}. Best is trial 2 with value: 0.4402686657465779.\u001b[0m\n",
      "feature_fraction, val_score: 0.440269:  86%|########5 | 6/7 [00:02<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.439540: 100%|##########| 7/7 [00:02<00:00,  2.91it/s]\u001b[32m[I 2020-12-26 22:02:24,545]\u001b[0m Trial 6 finished with value: 0.43953972814499276 and parameters: {'feature_fraction': 0.5}. Best is trial 6 with value: 0.43953972814499276.\u001b[0m\n",
      "feature_fraction, val_score: 0.439540: 100%|##########| 7/7 [00:02<00:00,  2.98it/s]\n",
      "num_leaves, val_score: 0.439540:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:   5%|5         | 1/20 [00:00<00:08,  2.25it/s]\u001b[32m[I 2020-12-26 22:02:25,002]\u001b[0m Trial 7 finished with value: 0.45420749716667835 and parameters: {'num_leaves': 171}. Best is trial 7 with value: 0.45420749716667835.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:   5%|5         | 1/20 [00:00<00:08,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  10%|#         | 2/20 [00:00<00:07,  2.29it/s]\u001b[32m[I 2020-12-26 22:02:25,421]\u001b[0m Trial 8 finished with value: 0.44705359319185517 and parameters: {'num_leaves': 85}. Best is trial 8 with value: 0.44705359319185517.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  10%|#         | 2/20 [00:00<00:07,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  15%|#5        | 3/20 [00:01<00:07,  2.36it/s]\u001b[32m[I 2020-12-26 22:02:25,815]\u001b[0m Trial 9 finished with value: 0.44325934396496297 and parameters: {'num_leaves': 87}. Best is trial 9 with value: 0.44325934396496297.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  15%|#5        | 3/20 [00:01<00:07,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  20%|##        | 4/20 [00:01<00:07,  2.09it/s]\u001b[32m[I 2020-12-26 22:02:26,423]\u001b[0m Trial 10 finished with value: 0.4560597530136024 and parameters: {'num_leaves': 235}. Best is trial 9 with value: 0.44325934396496297.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  25%|##5       | 5/20 [00:02<00:05,  2.54it/s]\u001b[32m[I 2020-12-26 22:02:26,619]\u001b[0m Trial 11 finished with value: 0.45122847792399584 and parameters: {'num_leaves': 6}. Best is trial 9 with value: 0.44325934396496297.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  25%|##5       | 5/20 [00:02<00:05,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  30%|###       | 6/20 [00:02<00:04,  2.98it/s]\u001b[32m[I 2020-12-26 22:02:26,819]\u001b[0m Trial 12 finished with value: 0.5322346580717546 and parameters: {'num_leaves': 2}. Best is trial 9 with value: 0.44325934396496297.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  30%|###       | 6/20 [00:02<00:04,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  35%|###5      | 7/20 [00:02<00:05,  2.45it/s]\u001b[32m[I 2020-12-26 22:02:27,392]\u001b[0m Trial 13 finished with value: 0.45793189743610074 and parameters: {'num_leaves': 256}. Best is trial 9 with value: 0.44325934396496297.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  35%|###5      | 7/20 [00:02<00:05,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  40%|####      | 8/20 [00:03<00:05,  2.32it/s]\u001b[32m[I 2020-12-26 22:02:27,881]\u001b[0m Trial 14 finished with value: 0.45533965729401876 and parameters: {'num_leaves': 180}. Best is trial 9 with value: 0.44325934396496297.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  40%|####      | 8/20 [00:03<00:05,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  45%|####5     | 9/20 [00:03<00:04,  2.41it/s]\u001b[32m[I 2020-12-26 22:02:28,257]\u001b[0m Trial 15 finished with value: 0.44510231368559616 and parameters: {'num_leaves': 60}. Best is trial 9 with value: 0.44325934396496297.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  45%|####5     | 9/20 [00:03<00:04,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  50%|#####     | 10/20 [00:04<00:04,  2.37it/s]\u001b[32m[I 2020-12-26 22:02:28,697]\u001b[0m Trial 16 finished with value: 0.44956853596735863 and parameters: {'num_leaves': 198}. Best is trial 9 with value: 0.44325934396496297.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  50%|#####     | 10/20 [00:04<00:04,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  55%|#####5    | 11/20 [00:04<00:03,  2.33it/s]\u001b[32m[I 2020-12-26 22:02:29,145]\u001b[0m Trial 17 finished with value: 0.44859200228825336 and parameters: {'num_leaves': 131}. Best is trial 9 with value: 0.44325934396496297.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  55%|#####5    | 11/20 [00:04<00:03,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  60%|######    | 12/20 [00:04<00:03,  2.54it/s]\u001b[32m[I 2020-12-26 22:02:29,455]\u001b[0m Trial 18 finished with value: 0.44161663048350647 and parameters: {'num_leaves': 33}. Best is trial 18 with value: 0.44161663048350647.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  60%|######    | 12/20 [00:04<00:03,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  65%|######5   | 13/20 [00:05<00:02,  2.45it/s]\u001b[32m[I 2020-12-26 22:02:29,897]\u001b[0m Trial 19 finished with value: 0.44859200228825336 and parameters: {'num_leaves': 131}. Best is trial 18 with value: 0.44161663048350647.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  65%|######5   | 13/20 [00:05<00:02,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  70%|#######   | 14/20 [00:05<00:02,  2.32it/s]\u001b[32m[I 2020-12-26 22:02:30,381]\u001b[0m Trial 20 finished with value: 0.4590810760351035 and parameters: {'num_leaves': 227}. Best is trial 18 with value: 0.44161663048350647.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  70%|#######   | 14/20 [00:05<00:02,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  75%|#######5  | 15/20 [00:06<00:02,  2.36it/s]\u001b[32m[I 2020-12-26 22:02:30,786]\u001b[0m Trial 21 finished with value: 0.4472485844395996 and parameters: {'num_leaves': 100}. Best is trial 18 with value: 0.44161663048350647.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  75%|#######5  | 15/20 [00:06<00:02,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  80%|########  | 16/20 [00:06<00:01,  2.37it/s]\u001b[32m[I 2020-12-26 22:02:31,205]\u001b[0m Trial 22 finished with value: 0.4533154692118227 and parameters: {'num_leaves': 155}. Best is trial 18 with value: 0.44161663048350647.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  80%|########  | 16/20 [00:06<00:01,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  85%|########5 | 17/20 [00:06<00:01,  2.58it/s]\u001b[32m[I 2020-12-26 22:02:31,511]\u001b[0m Trial 23 finished with value: 0.4415040101465067 and parameters: {'num_leaves': 35}. Best is trial 23 with value: 0.4415040101465067.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  85%|########5 | 17/20 [00:06<00:01,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  90%|######### | 18/20 [00:07<00:00,  2.48it/s]\u001b[32m[I 2020-12-26 22:02:31,949]\u001b[0m Trial 24 finished with value: 0.45718368684218547 and parameters: {'num_leaves': 207}. Best is trial 23 with value: 0.4415040101465067.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  90%|######### | 18/20 [00:07<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540:  95%|#########5| 19/20 [00:07<00:00,  2.46it/s]\u001b[32m[I 2020-12-26 22:02:32,365]\u001b[0m Trial 25 finished with value: 0.4473560288474622 and parameters: {'num_leaves': 109}. Best is trial 23 with value: 0.4415040101465067.\u001b[0m\n",
      "num_leaves, val_score: 0.439540:  95%|#########5| 19/20 [00:07<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.439540: 100%|##########| 20/20 [00:08<00:00,  2.58it/s]\u001b[32m[I 2020-12-26 22:02:32,711]\u001b[0m Trial 26 finished with value: 0.44627228720502643 and parameters: {'num_leaves': 63}. Best is trial 23 with value: 0.4415040101465067.\u001b[0m\n",
      "num_leaves, val_score: 0.439540: 100%|##########| 20/20 [00:08<00:00,  2.45it/s]\n",
      "bagging, val_score: 0.439540:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.439540:  10%|#         | 1/10 [00:00<00:03,  2.92it/s]\u001b[32m[I 2020-12-26 22:02:33,064]\u001b[0m Trial 27 finished with value: 0.44408618099487024 and parameters: {'bagging_fraction': 0.6398867805608527, 'bagging_freq': 1}. Best is trial 27 with value: 0.44408618099487024.\u001b[0m\n",
      "bagging, val_score: 0.439540:  10%|#         | 1/10 [00:00<00:03,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.439098:  20%|##        | 2/10 [00:00<00:02,  2.86it/s]\u001b[32m[I 2020-12-26 22:02:33,429]\u001b[0m Trial 28 finished with value: 0.43909780537112886 and parameters: {'bagging_fraction': 0.9355495640388806, 'bagging_freq': 7}. Best is trial 28 with value: 0.43909780537112886.\u001b[0m\n",
      "bagging, val_score: 0.439098:  20%|##        | 2/10 [00:00<00:02,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.439098:  30%|###       | 3/10 [00:01<00:02,  2.74it/s]\u001b[32m[I 2020-12-26 22:02:33,831]\u001b[0m Trial 29 finished with value: 0.4409161905983196 and parameters: {'bagging_fraction': 0.9782707687381226, 'bagging_freq': 7}. Best is trial 28 with value: 0.43909780537112886.\u001b[0m\n",
      "bagging, val_score: 0.439098:  30%|###       | 3/10 [00:01<00:02,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.438667:  40%|####      | 4/10 [00:01<00:02,  2.31it/s]\u001b[32m[I 2020-12-26 22:02:34,425]\u001b[0m Trial 30 finished with value: 0.4386671086721484 and parameters: {'bagging_fraction': 0.9780681654614318, 'bagging_freq': 7}. Best is trial 30 with value: 0.4386671086721484.\u001b[0m\n",
      "bagging, val_score: 0.438667:  50%|#####     | 5/10 [00:01<00:01,  2.58it/s]\u001b[32m[I 2020-12-26 22:02:34,706]\u001b[0m Trial 31 finished with value: 0.44357431548480114 and parameters: {'bagging_fraction': 0.9688008136694204, 'bagging_freq': 7}. Best is trial 30 with value: 0.4386671086721484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.438667:  60%|######    | 6/10 [00:02<00:01,  2.86it/s]\u001b[32m[I 2020-12-26 22:02:34,966]\u001b[0m Trial 32 finished with value: 0.4438713393212579 and parameters: {'bagging_fraction': 0.9050541592276359, 'bagging_freq': 5}. Best is trial 30 with value: 0.4386671086721484.\u001b[0m\n",
      "bagging, val_score: 0.438667:  60%|######    | 6/10 [00:02<00:01,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.438667:  70%|#######   | 7/10 [00:02<00:00,  3.10it/s]\u001b[32m[I 2020-12-26 22:02:35,226]\u001b[0m Trial 33 finished with value: 0.4498346130695475 and parameters: {'bagging_fraction': 0.41119288581355806, 'bagging_freq': 7}. Best is trial 30 with value: 0.4386671086721484.\u001b[0m\n",
      "bagging, val_score: 0.438667:  70%|#######   | 7/10 [00:02<00:00,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n",
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.438667:  80%|########  | 8/10 [00:02<00:00,  3.13it/s]\u001b[32m[I 2020-12-26 22:02:35,537]\u001b[0m Trial 34 finished with value: 0.4405513463384033 and parameters: {'bagging_fraction': 0.784013051534092, 'bagging_freq': 5}. Best is trial 30 with value: 0.4386671086721484.\u001b[0m\n",
      "bagging, val_score: 0.438667:  80%|########  | 8/10 [00:02<00:00,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.438667:  90%|######### | 9/10 [00:03<00:00,  3.21it/s]\u001b[32m[I 2020-12-26 22:02:35,831]\u001b[0m Trial 35 finished with value: 0.443183274167784 and parameters: {'bagging_fraction': 0.8409224356901529, 'bagging_freq': 2}. Best is trial 30 with value: 0.4386671086721484.\u001b[0m\n",
      "bagging, val_score: 0.438667: 100%|##########| 10/10 [00:03<00:00,  3.28it/s]\u001b[32m[I 2020-12-26 22:02:36,119]\u001b[0m Trial 36 finished with value: 0.4427331554454465 and parameters: {'bagging_fraction': 0.6470633592366535, 'bagging_freq': 6}. Best is trial 30 with value: 0.4386671086721484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.438667: 100%|##########| 10/10 [00:03<00:00,  2.94it/s]\n",
      "feature_fraction_stage2, val_score: 0.438667:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.437143:  17%|#6        | 1/6 [00:00<00:01,  2.68it/s]\u001b[32m[I 2020-12-26 22:02:36,504]\u001b[0m Trial 37 finished with value: 0.4371426655816105 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 37 with value: 0.4371426655816105.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.437143:  17%|#6        | 1/6 [00:00<00:01,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.437143:  33%|###3      | 2/6 [00:00<00:01,  2.75it/s]\u001b[32m[I 2020-12-26 22:02:36,848]\u001b[0m Trial 38 finished with value: 0.44088522985420775 and parameters: {'feature_fraction': 0.42}. Best is trial 37 with value: 0.4371426655816105.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.437143:  33%|###3      | 2/6 [00:00<00:01,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.437143:  50%|#####     | 3/6 [00:01<00:01,  2.73it/s]\u001b[32m[I 2020-12-26 22:02:37,218]\u001b[0m Trial 39 finished with value: 0.43854329172264034 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 37 with value: 0.4371426655816105.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.437143:  50%|#####     | 3/6 [00:01<00:01,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.437143:  67%|######6   | 4/6 [00:01<00:00,  2.73it/s]\u001b[32m[I 2020-12-26 22:02:37,586]\u001b[0m Trial 40 finished with value: 0.44190833811750346 and parameters: {'feature_fraction': 0.58}. Best is trial 37 with value: 0.4371426655816105.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.437143:  67%|######6   | 4/6 [00:01<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.437143:  83%|########3 | 5/6 [00:01<00:00,  2.76it/s]\u001b[32m[I 2020-12-26 22:02:37,940]\u001b[0m Trial 41 finished with value: 0.4380667954915193 and parameters: {'feature_fraction': 0.484}. Best is trial 37 with value: 0.4371426655816105.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.437143:  83%|########3 | 5/6 [00:01<00:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.437143: 100%|##########| 6/6 [00:02<00:00,  2.79it/s]\u001b[32m[I 2020-12-26 22:02:38,288]\u001b[0m Trial 42 finished with value: 0.44376351461176283 and parameters: {'feature_fraction': 0.516}. Best is trial 37 with value: 0.4371426655816105.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.437143: 100%|##########| 6/6 [00:02<00:00,  2.77it/s]\n",
      "regularization_factors, val_score: 0.437143:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:   5%|5         | 1/20 [00:00<00:06,  3.01it/s]\u001b[32m[I 2020-12-26 22:02:38,633]\u001b[0m Trial 43 finished with value: 0.4405533060293845 and parameters: {'lambda_l1': 1.370386519053112, 'lambda_l2': 0.005337276817065211}. Best is trial 43 with value: 0.4405533060293845.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:   5%|5         | 1/20 [00:00<00:06,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  10%|#         | 2/20 [00:00<00:06,  2.96it/s]\u001b[32m[I 2020-12-26 22:02:38,980]\u001b[0m Trial 44 finished with value: 0.43714266556950904 and parameters: {'lambda_l1': 4.287772010572417e-08, 'lambda_l2': 9.417450263970718e-08}. Best is trial 44 with value: 0.43714266556950904.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  10%|#         | 2/20 [00:00<00:06,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  15%|#5        | 3/20 [00:01<00:05,  2.86it/s]\u001b[32m[I 2020-12-26 22:02:39,357]\u001b[0m Trial 45 finished with value: 0.4371426655689925 and parameters: {'lambda_l1': 1.3389736825954065e-07, 'lambda_l2': 4.396135750060206e-08}. Best is trial 45 with value: 0.4371426655689925.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  15%|#5        | 3/20 [00:01<00:05,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  20%|##        | 4/20 [00:01<00:05,  2.80it/s]\u001b[32m[I 2020-12-26 22:02:39,734]\u001b[0m Trial 46 finished with value: 0.43714266558152953 and parameters: {'lambda_l1': 1.5018335250092963e-08, 'lambda_l2': 1.3094236581323372e-08}. Best is trial 45 with value: 0.4371426655689925.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  20%|##        | 4/20 [00:01<00:05,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  25%|##5       | 5/20 [00:01<00:05,  2.71it/s]\u001b[32m[I 2020-12-26 22:02:40,133]\u001b[0m Trial 47 finished with value: 0.43714266558405773 and parameters: {'lambda_l1': 1.759729742411857e-08, 'lambda_l2': 1.3160260203726558e-08}. Best is trial 45 with value: 0.4371426655689925.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  25%|##5       | 5/20 [00:01<00:05,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  30%|###       | 6/20 [00:02<00:05,  2.66it/s]\u001b[32m[I 2020-12-26 22:02:40,520]\u001b[0m Trial 48 finished with value: 0.4371426655775104 and parameters: {'lambda_l1': 1.069391897602564e-08, 'lambda_l2': 1.175642038918092e-08}. Best is trial 45 with value: 0.4371426655689925.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  30%|###       | 6/20 [00:02<00:05,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  35%|###5      | 7/20 [00:02<00:04,  2.68it/s]\u001b[32m[I 2020-12-26 22:02:40,892]\u001b[0m Trial 49 finished with value: 0.4371426655785505 and parameters: {'lambda_l1': 1.4278022847492331e-08, 'lambda_l2': 1.0379342115644933e-08}. Best is trial 45 with value: 0.4371426655689925.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  35%|###5      | 7/20 [00:02<00:04,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  40%|####      | 8/20 [00:02<00:04,  2.64it/s]\u001b[32m[I 2020-12-26 22:02:41,281]\u001b[0m Trial 50 finished with value: 0.43714266557604464 and parameters: {'lambda_l1': 1.5072215541681084e-08, 'lambda_l2': 1.0595868927178184e-08}. Best is trial 45 with value: 0.4371426655689925.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  40%|####      | 8/20 [00:02<00:04,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  45%|####5     | 9/20 [00:03<00:04,  2.66it/s]\u001b[32m[I 2020-12-26 22:02:41,652]\u001b[0m Trial 51 finished with value: 0.43714266557779163 and parameters: {'lambda_l1': 1.4330523324424817e-08, 'lambda_l2': 1.0610516920686687e-08}. Best is trial 45 with value: 0.4371426655689925.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  45%|####5     | 9/20 [00:03<00:04,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  50%|#####     | 10/20 [00:03<00:03,  2.61it/s]\u001b[32m[I 2020-12-26 22:02:42,051]\u001b[0m Trial 52 finished with value: 0.4371426655833464 and parameters: {'lambda_l1': 1.6405382316092572e-08, 'lambda_l2': 1.3410883816002713e-08}. Best is trial 45 with value: 0.4371426655689925.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  50%|#####     | 10/20 [00:03<00:03,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  55%|#####5    | 11/20 [00:04<00:03,  2.54it/s]\u001b[32m[I 2020-12-26 22:02:42,470]\u001b[0m Trial 53 finished with value: 0.4371426655830282 and parameters: {'lambda_l1': 1.8114825668114728e-08, 'lambda_l2': 1.4591495358794978e-08}. Best is trial 45 with value: 0.4371426655689925.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  55%|#####5    | 11/20 [00:04<00:03,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  60%|######    | 12/20 [00:04<00:03,  2.56it/s]\u001b[32m[I 2020-12-26 22:02:42,853]\u001b[0m Trial 54 finished with value: 0.4371426655839392 and parameters: {'lambda_l1': 1.9079938125934092e-08, 'lambda_l2': 1.6725892523772603e-08}. Best is trial 45 with value: 0.4371426655689925.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  60%|######    | 12/20 [00:04<00:03,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  65%|######5   | 13/20 [00:04<00:02,  2.60it/s]\u001b[32m[I 2020-12-26 22:02:43,223]\u001b[0m Trial 55 finished with value: 0.4371426655441919 and parameters: {'lambda_l1': 2.3690228908491662e-07, 'lambda_l2': 3.432439938847594e-07}. Best is trial 55 with value: 0.4371426655441919.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  65%|######5   | 13/20 [00:04<00:02,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  70%|#######   | 14/20 [00:05<00:02,  2.63it/s]\u001b[32m[I 2020-12-26 22:02:43,591]\u001b[0m Trial 56 finished with value: 0.4371426648493949 and parameters: {'lambda_l1': 4.0202840995391385e-06, 'lambda_l2': 4.265541251979605e-06}. Best is trial 56 with value: 0.4371426648493949.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  70%|#######   | 14/20 [00:05<00:02,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  75%|#######5  | 15/20 [00:05<00:01,  2.65it/s]\u001b[32m[I 2020-12-26 22:02:43,961]\u001b[0m Trial 57 finished with value: 0.4371426647701051 and parameters: {'lambda_l1': 7.462980398699661e-06, 'lambda_l2': 4.7202564318192075e-06}. Best is trial 57 with value: 0.4371426647701051.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  75%|#######5  | 15/20 [00:05<00:01,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  80%|########  | 16/20 [00:06<00:01,  2.66it/s]\u001b[32m[I 2020-12-26 22:02:44,336]\u001b[0m Trial 58 finished with value: 0.4371426634231836 and parameters: {'lambda_l1': 5.245445327085895e-06, 'lambda_l2': 1.3023834095423076e-05}. Best is trial 58 with value: 0.4371426634231836.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  80%|########  | 16/20 [00:06<00:01,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  85%|########5 | 17/20 [00:06<00:01,  2.67it/s]\u001b[32m[I 2020-12-26 22:02:44,708]\u001b[0m Trial 59 finished with value: 0.4371426649817112 and parameters: {'lambda_l1': 6.1333504445513446e-06, 'lambda_l2': 3.757703448717278e-06}. Best is trial 58 with value: 0.4371426634231836.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  85%|########5 | 17/20 [00:06<00:01,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  90%|######### | 18/20 [00:06<00:00,  2.64it/s]\u001b[32m[I 2020-12-26 22:02:45,098]\u001b[0m Trial 60 finished with value: 0.4371426647975575 and parameters: {'lambda_l1': 5.354690452231901e-06, 'lambda_l2': 4.8092157891457e-06}. Best is trial 58 with value: 0.4371426634231836.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  90%|######### | 18/20 [00:06<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143:  95%|#########5| 19/20 [00:07<00:00,  2.60it/s]\u001b[32m[I 2020-12-26 22:02:45,494]\u001b[0m Trial 61 finished with value: 0.43714266435520543 and parameters: {'lambda_l1': 4.908821613452411e-06, 'lambda_l2': 7.3758293795090665e-06}. Best is trial 58 with value: 0.4371426634231836.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143:  95%|#########5| 19/20 [00:07<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.437143: 100%|##########| 20/20 [00:07<00:00,  2.62it/s]\u001b[32m[I 2020-12-26 22:02:45,870]\u001b[0m Trial 62 finished with value: 0.43714266466913665 and parameters: {'lambda_l1': 7.800288313621399e-06, 'lambda_l2': 5.331621066948633e-06}. Best is trial 58 with value: 0.4371426634231836.\u001b[0m\n",
      "regularization_factors, val_score: 0.437143: 100%|##########| 20/20 [00:07<00:00,  2.64it/s]\n",
      "min_data_in_leaf, val_score: 0.437143:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.437143:  20%|##        | 1/5 [00:00<00:01,  2.62it/s]\u001b[32m[I 2020-12-26 22:02:46,259]\u001b[0m Trial 63 finished with value: 0.4397280934089533 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.4397280934089533.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.437143:  20%|##        | 1/5 [00:00<00:01,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.435240:  40%|####      | 2/5 [00:00<00:01,  2.61it/s]\u001b[32m[I 2020-12-26 22:02:46,647]\u001b[0m Trial 64 finished with value: 0.43524037944471 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 0.43524037944471.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.435240:  40%|####      | 2/5 [00:00<00:01,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.435240:  60%|######    | 3/5 [00:01<00:00,  2.63it/s]\u001b[32m[I 2020-12-26 22:02:47,019]\u001b[0m Trial 65 finished with value: 0.4376721815161802 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.43524037944471.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.435240:  60%|######    | 3/5 [00:01<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.435240:  80%|########  | 4/5 [00:01<00:00,  2.55it/s]\u001b[32m[I 2020-12-26 22:02:47,443]\u001b[0m Trial 66 finished with value: 0.4393588062980161 and parameters: {'min_child_samples': 50}. Best is trial 64 with value: 0.43524037944471.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.435240:  80%|########  | 4/5 [00:01<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4268, number of negative: 4168\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505927 -> initscore=0.023709\n",
      "[LightGBM] [Info] Start training from score 0.023709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.435240: 100%|##########| 5/5 [00:01<00:00,  2.58it/s]\u001b[32m[I 2020-12-26 22:02:47,819]\u001b[0m Trial 67 finished with value: 0.44134471516685114 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 0.43524037944471.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.435240: 100%|##########| 5/5 [00:01<00:00,  2.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category1</th>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goal_min</th>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_figure</th>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_paragraph</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length_of_text</th>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importance\n",
       "country                      81\n",
       "category1                   111\n",
       "duration                     98\n",
       "goal_min                    171\n",
       "number_of_figure            134\n",
       "number_of_paragraph          92\n",
       "length_of_text              181\n",
       "0                            82\n",
       "1                            65\n",
       "2                            79\n",
       "3                            91\n",
       "4                            63\n",
       "5                            85\n",
       "6                            49\n",
       "7                            68\n",
       "8                            45\n",
       "9                            53\n",
       "10                           62\n",
       "11                           50\n",
       "12                           48\n",
       "13                           57\n",
       "14                           49\n",
       "15                           71\n",
       "16                           50\n",
       "17                           72\n",
       "18                           75\n",
       "19                           62\n",
       "20                           68\n",
       "21                           55\n",
       "22                           55\n",
       "23                           59\n",
       "24                           49"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-26 22:02:47,945]\u001b[0m A new study created in memory with name: no-name-9c9b0f5a-695e-4deb-8873-2a515e4d4e76\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/Applications/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Applications/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.420551:  14%|#4        | 1/7 [00:00<00:02,  2.47it/s]\u001b[32m[I 2020-12-26 22:02:48,358]\u001b[0m Trial 0 finished with value: 0.420550992204515 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.420550992204515.\u001b[0m\n",
      "feature_fraction, val_score: 0.420551:  14%|#4        | 1/7 [00:00<00:02,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.420551:  29%|##8       | 2/7 [00:00<00:01,  2.52it/s]\u001b[32m[I 2020-12-26 22:02:48,737]\u001b[0m Trial 1 finished with value: 0.42056103468186873 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.420550992204515.\u001b[0m\n",
      "feature_fraction, val_score: 0.420551:  29%|##8       | 2/7 [00:00<00:01,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.420551:  43%|####2     | 3/7 [00:01<00:01,  2.59it/s]\u001b[32m[I 2020-12-26 22:02:49,099]\u001b[0m Trial 2 finished with value: 0.4216598520745696 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.420550992204515.\u001b[0m\n",
      "feature_fraction, val_score: 0.420551:  43%|####2     | 3/7 [00:01<00:01,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.420551:  57%|#####7    | 4/7 [00:01<00:01,  2.52it/s]\u001b[32m[I 2020-12-26 22:02:49,521]\u001b[0m Trial 3 finished with value: 0.421980885730525 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.420550992204515.\u001b[0m\n",
      "feature_fraction, val_score: 0.420551:  57%|#####7    | 4/7 [00:01<00:01,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.419406:  71%|#######1  | 5/7 [00:01<00:00,  2.53it/s]\u001b[32m[I 2020-12-26 22:02:49,911]\u001b[0m Trial 4 finished with value: 0.4194057361941744 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 4 with value: 0.4194057361941744.\u001b[0m\n",
      "feature_fraction, val_score: 0.419406:  71%|#######1  | 5/7 [00:01<00:00,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.416536:  86%|########5 | 6/7 [00:02<00:00,  2.58it/s]\u001b[32m[I 2020-12-26 22:02:50,280]\u001b[0m Trial 5 finished with value: 0.4165356308834747 and parameters: {'feature_fraction': 0.4}. Best is trial 5 with value: 0.4165356308834747.\u001b[0m\n",
      "feature_fraction, val_score: 0.416536:  86%|########5 | 6/7 [00:02<00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.416536: 100%|##########| 7/7 [00:02<00:00,  2.59it/s]\u001b[32m[I 2020-12-26 22:02:50,664]\u001b[0m Trial 6 finished with value: 0.41924504429945886 and parameters: {'feature_fraction': 0.5}. Best is trial 5 with value: 0.4165356308834747.\u001b[0m\n",
      "feature_fraction, val_score: 0.416536: 100%|##########| 7/7 [00:02<00:00,  2.58it/s]\n",
      "num_leaves, val_score: 0.416536:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.416536:   5%|5         | 1/20 [00:00<00:09,  1.97it/s]\u001b[32m[I 2020-12-26 22:02:51,185]\u001b[0m Trial 7 finished with value: 0.4389346047917414 and parameters: {'num_leaves': 161}. Best is trial 7 with value: 0.4389346047917414.\u001b[0m\n",
      "num_leaves, val_score: 0.416536:   5%|5         | 1/20 [00:00<00:09,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.416536:  10%|#         | 2/20 [00:01<00:09,  1.94it/s]\u001b[32m[I 2020-12-26 22:02:51,718]\u001b[0m Trial 8 finished with value: 0.436587156253425 and parameters: {'num_leaves': 223}. Best is trial 8 with value: 0.436587156253425.\u001b[0m\n",
      "num_leaves, val_score: 0.416536:  10%|#         | 2/20 [00:01<00:09,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.416536:  15%|#5        | 3/20 [00:01<00:09,  1.87it/s]\u001b[32m[I 2020-12-26 22:02:52,299]\u001b[0m Trial 9 finished with value: 0.4328760657881819 and parameters: {'num_leaves': 196}. Best is trial 9 with value: 0.4328760657881819.\u001b[0m\n",
      "num_leaves, val_score: 0.416536:  15%|#5        | 3/20 [00:01<00:09,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.416294:  20%|##        | 4/20 [00:02<00:08,  2.00it/s]\u001b[32m[I 2020-12-26 22:02:52,716]\u001b[0m Trial 10 finished with value: 0.4162941724274117 and parameters: {'num_leaves': 35}. Best is trial 10 with value: 0.4162941724274117.\u001b[0m\n",
      "num_leaves, val_score: 0.416294:  25%|##5       | 5/20 [00:02<00:06,  2.29it/s]\u001b[32m[I 2020-12-26 22:02:53,006]\u001b[0m Trial 11 finished with value: 0.4204804082622572 and parameters: {'num_leaves': 17}. Best is trial 10 with value: 0.4162941724274117.\u001b[0m\n",
      "num_leaves, val_score: 0.416294:  25%|##5       | 5/20 [00:02<00:06,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.414742:  30%|###       | 6/20 [00:02<00:05,  2.43it/s]\u001b[32m[I 2020-12-26 22:02:53,356]\u001b[0m Trial 12 finished with value: 0.41474175536378594 and parameters: {'num_leaves': 34}. Best is trial 12 with value: 0.41474175536378594.\u001b[0m\n",
      "num_leaves, val_score: 0.414742:  35%|###5      | 7/20 [00:02<00:04,  2.73it/s]\u001b[32m[I 2020-12-26 22:02:53,620]\u001b[0m Trial 13 finished with value: 0.4220905711921935 and parameters: {'num_leaves': 33}. Best is trial 12 with value: 0.41474175536378594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.414742:  35%|###5      | 7/20 [00:02<00:04,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.414742:  40%|####      | 8/20 [00:03<00:04,  2.53it/s]\u001b[32m[I 2020-12-26 22:02:54,081]\u001b[0m Trial 14 finished with value: 0.4235612659254484 and parameters: {'num_leaves': 86}. Best is trial 12 with value: 0.41474175536378594.\u001b[0m\n",
      "num_leaves, val_score: 0.414742:  40%|####      | 8/20 [00:03<00:04,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.414742:  45%|####5     | 9/20 [00:03<00:04,  2.45it/s]\u001b[32m[I 2020-12-26 22:02:54,520]\u001b[0m Trial 15 finished with value: 0.4216511454314069 and parameters: {'num_leaves': 69}. Best is trial 12 with value: 0.41474175536378594.\u001b[0m\n",
      "num_leaves, val_score: 0.414742:  50%|#####     | 10/20 [00:04<00:03,  2.83it/s]\u001b[32m[I 2020-12-26 22:02:54,743]\u001b[0m Trial 16 finished with value: 0.43317675689499147 and parameters: {'num_leaves': 7}. Best is trial 12 with value: 0.41474175536378594.\u001b[0m\n",
      "num_leaves, val_score: 0.414742:  50%|#####     | 10/20 [00:04<00:03,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.414742:  55%|#####5    | 11/20 [00:04<00:03,  2.61it/s]\u001b[32m[I 2020-12-26 22:02:55,201]\u001b[0m Trial 17 finished with value: 0.42322249483792884 and parameters: {'num_leaves': 93}. Best is trial 12 with value: 0.41474175536378594.\u001b[0m\n",
      "num_leaves, val_score: 0.414742:  55%|#####5    | 11/20 [00:04<00:03,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.414742:  60%|######    | 12/20 [00:04<00:03,  2.50it/s]\u001b[32m[I 2020-12-26 22:02:55,639]\u001b[0m Trial 18 finished with value: 0.41797152262544307 and parameters: {'num_leaves': 53}. Best is trial 12 with value: 0.41474175536378594.\u001b[0m\n",
      "num_leaves, val_score: 0.414742:  60%|######    | 12/20 [00:04<00:03,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.414742:  65%|######5   | 13/20 [00:05<00:02,  2.42it/s]\u001b[32m[I 2020-12-26 22:02:56,083]\u001b[0m Trial 19 finished with value: 0.4282539065580449 and parameters: {'num_leaves': 114}. Best is trial 12 with value: 0.41474175536378594.\u001b[0m\n",
      "num_leaves, val_score: 0.414742:  65%|######5   | 13/20 [00:05<00:02,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.414742:  70%|#######   | 14/20 [00:05<00:02,  2.26it/s]\u001b[32m[I 2020-12-26 22:02:56,591]\u001b[0m Trial 20 finished with value: 0.4305714150926164 and parameters: {'num_leaves': 141}. Best is trial 12 with value: 0.41474175536378594.\u001b[0m\n",
      "num_leaves, val_score: 0.414742:  70%|#######   | 14/20 [00:05<00:02,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.414742:  75%|#######5  | 15/20 [00:06<00:02,  2.32it/s]\u001b[32m[I 2020-12-26 22:02:56,997]\u001b[0m Trial 21 finished with value: 0.41783154909532877 and parameters: {'num_leaves': 43}. Best is trial 12 with value: 0.41474175536378594.\u001b[0m\n",
      "num_leaves, val_score: 0.414742:  80%|########  | 16/20 [00:06<00:01,  2.69it/s]\u001b[32m[I 2020-12-26 22:02:57,233]\u001b[0m Trial 22 finished with value: 0.4331767568949914 and parameters: {'num_leaves': 7}. Best is trial 12 with value: 0.41474175536378594.\u001b[0m\n",
      "num_leaves, val_score: 0.414742:  80%|########  | 16/20 [00:06<00:01,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.414742:  85%|########5 | 17/20 [00:06<00:00,  3.11it/s]\u001b[32m[I 2020-12-26 22:02:57,433]\u001b[0m Trial 23 finished with value: 0.4596934640182371 and parameters: {'num_leaves': 4}. Best is trial 12 with value: 0.41474175536378594.\u001b[0m\n",
      "num_leaves, val_score: 0.414742:  85%|########5 | 17/20 [00:06<00:00,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.414742:  90%|######### | 18/20 [00:07<00:00,  2.78it/s]\u001b[32m[I 2020-12-26 22:02:57,884]\u001b[0m Trial 24 finished with value: 0.4220890485749034 and parameters: {'num_leaves': 67}. Best is trial 12 with value: 0.41474175536378594.\u001b[0m\n",
      "num_leaves, val_score: 0.414742:  90%|######### | 18/20 [00:07<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.414742:  95%|#########5| 19/20 [00:07<00:00,  2.50it/s]\u001b[32m[I 2020-12-26 22:02:58,376]\u001b[0m Trial 25 finished with value: 0.42977684461807986 and parameters: {'num_leaves': 121}. Best is trial 12 with value: 0.41474175536378594.\u001b[0m\n",
      "num_leaves, val_score: 0.414742:  95%|#########5| 19/20 [00:07<00:00,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.414574: 100%|##########| 20/20 [00:08<00:00,  2.52it/s]\u001b[32m[I 2020-12-26 22:02:58,766]\u001b[0m Trial 26 finished with value: 0.41457398375229165 and parameters: {'num_leaves': 36}. Best is trial 26 with value: 0.41457398375229165.\u001b[0m\n",
      "num_leaves, val_score: 0.414574: 100%|##########| 20/20 [00:08<00:00,  2.47it/s]\n",
      "bagging, val_score: 0.414574:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.414574:  10%|#         | 1/10 [00:00<00:02,  3.31it/s]\u001b[32m[I 2020-12-26 22:02:59,080]\u001b[0m Trial 27 finished with value: 0.4253243269957678 and parameters: {'bagging_fraction': 0.5585265489647864, 'bagging_freq': 2}. Best is trial 27 with value: 0.4253243269957678.\u001b[0m\n",
      "bagging, val_score: 0.414574:  10%|#         | 1/10 [00:00<00:02,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.414574:  20%|##        | 2/10 [00:00<00:02,  2.91it/s]\u001b[32m[I 2020-12-26 22:02:59,523]\u001b[0m Trial 28 finished with value: 0.41726349075557795 and parameters: {'bagging_fraction': 0.959451477011368, 'bagging_freq': 7}. Best is trial 28 with value: 0.41726349075557795.\u001b[0m\n",
      "bagging, val_score: 0.414574:  20%|##        | 2/10 [00:00<00:02,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.414574:  30%|###       | 3/10 [00:01<00:02,  2.78it/s]\u001b[32m[I 2020-12-26 22:02:59,916]\u001b[0m Trial 29 finished with value: 0.4174412533015751 and parameters: {'bagging_fraction': 0.9975226905661583, 'bagging_freq': 7}. Best is trial 28 with value: 0.41726349075557795.\u001b[0m\n",
      "bagging, val_score: 0.414574:  30%|###       | 3/10 [00:01<00:02,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.414574:  40%|####      | 4/10 [00:01<00:02,  2.69it/s]\u001b[32m[I 2020-12-26 22:03:00,316]\u001b[0m Trial 30 finished with value: 0.41989936284097057 and parameters: {'bagging_fraction': 0.4248349697910448, 'bagging_freq': 1}. Best is trial 28 with value: 0.41726349075557795.\u001b[0m\n",
      "bagging, val_score: 0.414574:  40%|####      | 4/10 [00:01<00:02,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.414574:  50%|#####     | 5/10 [00:01<00:01,  2.72it/s]\u001b[32m[I 2020-12-26 22:03:00,675]\u001b[0m Trial 31 finished with value: 0.41791878236947294 and parameters: {'bagging_fraction': 0.8112512067962325, 'bagging_freq': 4}. Best is trial 28 with value: 0.41726349075557795.\u001b[0m\n",
      "bagging, val_score: 0.414574:  50%|#####     | 5/10 [00:01<00:01,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.414574:  60%|######    | 6/10 [00:02<00:01,  2.65it/s]\u001b[32m[I 2020-12-26 22:03:01,075]\u001b[0m Trial 32 finished with value: 0.42222796558122777 and parameters: {'bagging_fraction': 0.7004412456453508, 'bagging_freq': 4}. Best is trial 28 with value: 0.41726349075557795.\u001b[0m\n",
      "bagging, val_score: 0.414574:  70%|#######   | 7/10 [00:02<00:01,  2.85it/s]\u001b[32m[I 2020-12-26 22:03:01,365]\u001b[0m Trial 33 finished with value: 0.43040418565716215 and parameters: {'bagging_fraction': 0.4038868404671698, 'bagging_freq': 6}. Best is trial 28 with value: 0.41726349075557795.\u001b[0m\n",
      "bagging, val_score: 0.414574:  70%|#######   | 7/10 [00:02<00:01,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.414574:  80%|########  | 8/10 [00:02<00:00,  2.86it/s]\u001b[32m[I 2020-12-26 22:03:01,711]\u001b[0m Trial 34 finished with value: 0.4217524655511111 and parameters: {'bagging_fraction': 0.8247849769142318, 'bagging_freq': 2}. Best is trial 28 with value: 0.41726349075557795.\u001b[0m\n",
      "bagging, val_score: 0.414574:  80%|########  | 8/10 [00:02<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.414574:  90%|######### | 9/10 [00:03<00:00,  2.84it/s]\u001b[32m[I 2020-12-26 22:03:02,068]\u001b[0m Trial 35 finished with value: 0.42843541411166985 and parameters: {'bagging_fraction': 0.5329497004830501, 'bagging_freq': 5}. Best is trial 28 with value: 0.41726349075557795.\u001b[0m\n",
      "bagging, val_score: 0.414574:  90%|######### | 9/10 [00:03<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.414574: 100%|##########| 10/10 [00:03<00:00,  2.71it/s]\u001b[32m[I 2020-12-26 22:03:02,476]\u001b[0m Trial 36 finished with value: 0.418829291563613 and parameters: {'bagging_fraction': 0.6050859524256526, 'bagging_freq': 1}. Best is trial 28 with value: 0.41726349075557795.\u001b[0m\n",
      "bagging, val_score: 0.414574: 100%|##########| 10/10 [00:03<00:00,  2.70it/s]\n",
      "feature_fraction_stage2, val_score: 0.414574:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.414574:  33%|###3      | 1/3 [00:00<00:00,  2.62it/s]\u001b[32m[I 2020-12-26 22:03:02,865]\u001b[0m Trial 37 finished with value: 0.41977284716120467 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.41977284716120467.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.414574:  33%|###3      | 1/3 [00:00<00:00,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.414574:  67%|######6   | 2/3 [00:00<00:00,  2.72it/s]\u001b[32m[I 2020-12-26 22:03:03,200]\u001b[0m Trial 38 finished with value: 0.4236841220498389 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.41977284716120467.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.414574:  67%|######6   | 2/3 [00:00<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.414574: 100%|##########| 3/3 [00:01<00:00,  2.68it/s]\u001b[32m[I 2020-12-26 22:03:03,588]\u001b[0m Trial 39 finished with value: 0.41457398375229165 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 39 with value: 0.41457398375229165.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.414574: 100%|##########| 3/3 [00:01<00:00,  2.70it/s]\n",
      "regularization_factors, val_score: 0.414574:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:   5%|5         | 1/20 [00:00<00:07,  2.63it/s]\u001b[32m[I 2020-12-26 22:03:03,980]\u001b[0m Trial 40 finished with value: 0.41425734791385055 and parameters: {'lambda_l1': 1.268884395544608, 'lambda_l2': 1.5145494301400646e-08}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:   5%|5         | 1/20 [00:00<00:07,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  10%|#         | 2/20 [00:00<00:07,  2.55it/s]\u001b[32m[I 2020-12-26 22:03:04,398]\u001b[0m Trial 41 finished with value: 0.417669491128987 and parameters: {'lambda_l1': 7.207278050988015, 'lambda_l2': 1.2597503964194265e-08}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  10%|#         | 2/20 [00:00<00:07,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  15%|#5        | 3/20 [00:01<00:06,  2.43it/s]\u001b[32m[I 2020-12-26 22:03:04,855]\u001b[0m Trial 42 finished with value: 0.4188708499317431 and parameters: {'lambda_l1': 0.11033185332302343, 'lambda_l2': 1.2299448001307168e-06}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  15%|#5        | 3/20 [00:01<00:06,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  20%|##        | 4/20 [00:01<00:06,  2.42it/s]\u001b[32m[I 2020-12-26 22:03:05,273]\u001b[0m Trial 43 finished with value: 0.41824764379390994 and parameters: {'lambda_l1': 3.982122917697553e-08, 'lambda_l2': 1.1566366667938701}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  20%|##        | 4/20 [00:01<00:06,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  25%|##5       | 5/20 [00:02<00:06,  2.39it/s]\u001b[32m[I 2020-12-26 22:03:05,702]\u001b[0m Trial 44 finished with value: 0.4154848176160599 and parameters: {'lambda_l1': 0.00025999376005176645, 'lambda_l2': 0.0016948121815306368}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  25%|##5       | 5/20 [00:02<00:06,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  30%|###       | 6/20 [00:02<00:05,  2.49it/s]\u001b[32m[I 2020-12-26 22:03:06,066]\u001b[0m Trial 45 finished with value: 0.41631809175701057 and parameters: {'lambda_l1': 9.454435289419399e-05, 'lambda_l2': 0.006364295892632593}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  30%|###       | 6/20 [00:02<00:05,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  35%|###5      | 7/20 [00:02<00:05,  2.46it/s]\u001b[32m[I 2020-12-26 22:03:06,483]\u001b[0m Trial 46 finished with value: 0.41678211601447773 and parameters: {'lambda_l1': 0.00014907114392841907, 'lambda_l2': 0.0002829307801086439}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  35%|###5      | 7/20 [00:02<00:05,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  40%|####      | 8/20 [00:03<00:04,  2.46it/s]\u001b[32m[I 2020-12-26 22:03:06,890]\u001b[0m Trial 47 finished with value: 0.4190124928405485 and parameters: {'lambda_l1': 0.025629633735033946, 'lambda_l2': 0.0007909024877744907}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  40%|####      | 8/20 [00:03<00:04,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  45%|####5     | 9/20 [00:03<00:04,  2.43it/s]\u001b[32m[I 2020-12-26 22:03:07,313]\u001b[0m Trial 48 finished with value: 0.4145739876538607 and parameters: {'lambda_l1': 1.1510986979043226e-06, 'lambda_l2': 3.2179137144290587e-06}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  45%|####5     | 9/20 [00:03<00:04,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  50%|#####     | 10/20 [00:04<00:04,  2.46it/s]\u001b[32m[I 2020-12-26 22:03:07,710]\u001b[0m Trial 49 finished with value: 0.4145739838461335 and parameters: {'lambda_l1': 8.353293256956961e-08, 'lambda_l2': 1.0572896761262894e-08}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  50%|#####     | 10/20 [00:04<00:04,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  55%|#####5    | 11/20 [00:04<00:03,  2.47it/s]\u001b[32m[I 2020-12-26 22:03:08,111]\u001b[0m Trial 50 finished with value: 0.41457398381779637 and parameters: {'lambda_l1': 5.067972535905176e-08, 'lambda_l2': 1.0529423190694521e-08}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  55%|#####5    | 11/20 [00:04<00:03,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  60%|######    | 12/20 [00:04<00:03,  2.44it/s]\u001b[32m[I 2020-12-26 22:03:08,533]\u001b[0m Trial 51 finished with value: 0.4145739838128011 and parameters: {'lambda_l1': 4.0993989580188475e-08, 'lambda_l2': 1.5317279978616396e-08}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  60%|######    | 12/20 [00:04<00:03,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  65%|######5   | 13/20 [00:05<00:02,  2.48it/s]\u001b[32m[I 2020-12-26 22:03:08,923]\u001b[0m Trial 52 finished with value: 0.4145739837786602 and parameters: {'lambda_l1': 1.639306061340513e-08, 'lambda_l2': 1.1757204965509453e-08}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  65%|######5   | 13/20 [00:05<00:02,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  70%|#######   | 14/20 [00:05<00:02,  2.45it/s]\u001b[32m[I 2020-12-26 22:03:09,338]\u001b[0m Trial 53 finished with value: 0.41457398377353205 and parameters: {'lambda_l1': 1.2072026268791252e-08, 'lambda_l2': 1.2412116956571022e-08}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  70%|#######   | 14/20 [00:05<00:02,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  75%|#######5  | 15/20 [00:06<00:02,  2.48it/s]\u001b[32m[I 2020-12-26 22:03:09,729]\u001b[0m Trial 54 finished with value: 0.4145739857111785 and parameters: {'lambda_l1': 2.1292025306907655e-06, 'lambda_l2': 2.507547989132711e-07}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  75%|#######5  | 15/20 [00:06<00:02,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  80%|########  | 16/20 [00:06<00:01,  2.45it/s]\u001b[32m[I 2020-12-26 22:03:10,147]\u001b[0m Trial 55 finished with value: 0.4145739838904123 and parameters: {'lambda_l1': 1.129072234312278e-08, 'lambda_l2': 1.2159085342514062e-07}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  80%|########  | 16/20 [00:06<00:01,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  85%|########5 | 17/20 [00:06<00:01,  2.41it/s]\u001b[32m[I 2020-12-26 22:03:10,579]\u001b[0m Trial 56 finished with value: 0.41457398415777913 and parameters: {'lambda_l1': 4.883103648995985e-07, 'lambda_l2': 1.0607931371939853e-08}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  85%|########5 | 17/20 [00:06<00:01,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  90%|######### | 18/20 [00:07<00:00,  2.45it/s]\u001b[32m[I 2020-12-26 22:03:10,972]\u001b[0m Trial 57 finished with value: 0.4145739838732348 and parameters: {'lambda_l1': 1.1303050226050981e-08, 'lambda_l2': 9.637473762786096e-08}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  90%|######### | 18/20 [00:07<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257:  95%|#########5| 19/20 [00:07<00:00,  2.42it/s]\u001b[32m[I 2020-12-26 22:03:11,394]\u001b[0m Trial 58 finished with value: 0.41977119704207566 and parameters: {'lambda_l1': 2.934156280063585, 'lambda_l2': 6.72364487237382e-06}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257:  95%|#########5| 19/20 [00:07<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.414257: 100%|##########| 20/20 [00:08<00:00,  2.47it/s]\u001b[32m[I 2020-12-26 22:03:11,785]\u001b[0m Trial 59 finished with value: 0.4145739926651929 and parameters: {'lambda_l1': 1.0936384266608738e-05, 'lambda_l2': 6.966666561444557e-08}. Best is trial 40 with value: 0.41425734791385055.\u001b[0m\n",
      "regularization_factors, val_score: 0.414257: 100%|##########| 20/20 [00:08<00:00,  2.44it/s]\n",
      "min_data_in_leaf, val_score: 0.414257:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.414257:  20%|##        | 1/5 [00:00<00:01,  2.36it/s]\u001b[32m[I 2020-12-26 22:03:12,216]\u001b[0m Trial 60 finished with value: 0.41883662661204374 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.41883662661204374.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.414257:  20%|##        | 1/5 [00:00<00:01,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.414257:  40%|####      | 2/5 [00:00<00:01,  2.34it/s]\u001b[32m[I 2020-12-26 22:03:12,651]\u001b[0m Trial 61 finished with value: 0.41788344324947096 and parameters: {'min_child_samples': 25}. Best is trial 61 with value: 0.41788344324947096.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.414257:  40%|####      | 2/5 [00:00<00:01,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.414257:  60%|######    | 3/5 [00:01<00:00,  2.33it/s]\u001b[32m[I 2020-12-26 22:03:13,087]\u001b[0m Trial 62 finished with value: 0.41536310978543783 and parameters: {'min_child_samples': 50}. Best is trial 62 with value: 0.41536310978543783.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.414257:  60%|######    | 3/5 [00:01<00:00,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.414257:  80%|########  | 4/5 [00:01<00:00,  2.40it/s]\u001b[32m[I 2020-12-26 22:03:13,477]\u001b[0m Trial 63 finished with value: 0.417995575714835 and parameters: {'min_child_samples': 5}. Best is trial 62 with value: 0.41536310978543783.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.414257:  80%|########  | 4/5 [00:01<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4274, number of negative: 4162\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4010\n",
      "[LightGBM] [Info] Number of data points in the train set: 8436, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506638 -> initscore=0.026554\n",
      "[LightGBM] [Info] Start training from score 0.026554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.414257: 100%|##########| 5/5 [00:02<00:00,  2.36it/s]\u001b[32m[I 2020-12-26 22:03:13,914]\u001b[0m Trial 64 finished with value: 0.41673351851524437 and parameters: {'min_child_samples': 10}. Best is trial 62 with value: 0.41536310978543783.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.414257: 100%|##########| 5/5 [00:02<00:00,  2.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category1</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goal_min</th>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_figure</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_paragraph</th>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length_of_text</th>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importance\n",
       "country                      74\n",
       "category1                    98\n",
       "duration                    128\n",
       "goal_min                    177\n",
       "number_of_figure            147\n",
       "number_of_paragraph         122\n",
       "length_of_text              226\n",
       "0                           100\n",
       "1                            94\n",
       "2                           118\n",
       "3                            90\n",
       "4                            67\n",
       "5                           101\n",
       "6                            62\n",
       "7                            69\n",
       "8                            70\n",
       "9                            63\n",
       "10                           67\n",
       "11                           71\n",
       "12                           54\n",
       "13                           64\n",
       "14                           73\n",
       "15                           55\n",
       "16                           65\n",
       "17                           65\n",
       "18                           78\n",
       "19                           74\n",
       "20                           72\n",
       "21                           83\n",
       "22                           93\n",
       "23                           54\n",
       "24                           61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run optuna lgbm with region, category1(vectorized)\n",
    "test_set = all_new[all_new[\"data_type\"] == \"test\"]\n",
    "train_set = all_new[all_new[\"data_type\"] == \"train\"]\n",
    "_oof2, _preds2 = run_optuna_lgbm(test_set, train_set, target_cols, feature_cols, categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_accuracy(oof, y_train):\n",
    "    best_score = 0\n",
    "    scores = []\n",
    "    ratios = []\n",
    "    for thr in np.arange(0, 1.0, 0.025):\n",
    "        oof_ = np.where(oof<thr, 0, 1)\n",
    "        ratio = np.count_nonzero(oof_>0)/len(oof_)\n",
    "        ratios.append(ratio)\n",
    "        accuracyscore = accuracy_score(y_true=y_train, y_pred=oof_)\n",
    "        scores.append(accuracyscore)\n",
    "        best_score = max(best_score, accuracyscore)\n",
    "        if accuracyscore == best_score:\n",
    "            best_threshold = thr\n",
    "    plt.figure()\n",
    "    plt.title(\"accuracy_score\")\n",
    "    plt.scatter(np.arange(0, 1.0, 0.025), scores)\n",
    "    plt.scatter(np.arange(0, 1.0, 0.025), ratios)\n",
    "    return best_score, best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7834044570886676 0.47500000000000003\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_score2, best_threshold2 = optimize_accuracy(_oof2, list(train_set[\"state\"]))\n",
    "print(best_score2, best_threshold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_threshold(oof, y_train):\n",
    "    best_score = 0\n",
    "    scores = []\n",
    "    ratios = []\n",
    "    for thr in np.arange(0, 1.0, 0.025):\n",
    "        oof_ = np.where(oof<thr, 0, 1)\n",
    "        ratio = np.count_nonzero(oof_>0)/len(oof_)\n",
    "        ratios.append(ratio)\n",
    "        f1score = f1_score(y_true=y_train, y_pred=oof_,average='binary', sample_weight=None, zero_division='warn')\n",
    "        scores.append(f1score)\n",
    "        best_score = max(best_score, f1score)\n",
    "        if f1score == best_score:\n",
    "            best_threshold = thr\n",
    "    plt.figure()\n",
    "    plt.title('f1_score')\n",
    "    plt.scatter(np.arange(0, 1.0, 0.025), scores)\n",
    "    plt.scatter(np.arange(0, 1.0, 0.025), ratios)\n",
    "    return best_score, best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7923434893318114 0.4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_score2, best_threshold2 = optimize_threshold(_oof2, list(train_set[\"state\"]))\n",
    "print(best_score2, best_threshold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_sub(preds, threshold):\n",
    "    preds = np.where(preds<threshold, 0, 1)\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\"id\", \"state\"])\n",
    "    df[\"state\"] = preds\n",
    "    df[\"id\"] = range(10545, 21089)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb01c6855e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD1CAYAAAC87SVQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPIklEQVR4nO3dcaid913H8fdnydaVzbCW3oR4b2oqRmdS2GYvMTKQacVEJ6b/FDLQxlG4UDrZQHCp/4h/BOo/ogUbCHM2xbkSpqNho9MQLSKGZreuLkuzmMvaJZfE5m4qdv7RmezrH/cnHm5Ock/am3PX/N4veHie5/v8fs/5PXD5nIffec65qSokSX14x2oPQJI0Poa+JHXE0Jekjhj6ktQRQ1+SOmLoS1JH1q72AJZz11131ebNm1d7GJL0tvLiiy9+p6omltZ/6EN/8+bNzM7OrvYwJOltJcm3h9Wd3pGkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdGSn0k7wvyReSfDPJ6SQ/l+TOJEeTnG3rOwbaP5ZkLsmZJDsH6vclOdmOPZEkN+OiJEnDjXqn/yfAV6rq/cAHgNPAPuBYVW0BjrV9kmwF9gDbgF3Ak0nWtPMcAGaALW3ZtULXIUkawbJfzkqyDvh54LcAqur7wPeT7AY+0podAp4HPg3sBp6pqjeAV5LMAduTvAqsq6rj7bxPAw8Az63c5ayezfu+vNpDuGW8+vhHV3sI0i1rlDv9HwcWgD9P8rUkn0nyHmBDVV0EaOv1rf0kcH6g/3yrTbbtpXVJ0piMEvprgZ8BDlTVh4D/pk3lXMOwefq6Tv3qEyQzSWaTzC4sLIwwREnSKEYJ/XlgvqpeaPtfYPFN4LUkGwHa+tJA+00D/aeAC60+NaR+lao6WFXTVTU9MXHV7wVJkt6kZUO/qv4NOJ/kp1rpfuBl4Aiwt9X2As+27SPAniS3JbmHxQ9sT7QpoNeT7GhP7Tw00EeSNAaj/srmbwOfS/Iu4FvAx1l8wzic5GHgHPAgQFWdSnKYxTeGy8CjVXWlnecR4CngdhY/wL0lPsSVpLeLkUK/ql4Cpoccuv8a7fcD+4fUZ4F7b2SAkqSV4zdyJakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0JakjI4V+kleTnEzyUpLZVrszydEkZ9v6joH2jyWZS3Imyc6B+n3tPHNJnkiSlb8kSdK13Mid/i9U1Qerarrt7wOOVdUW4FjbJ8lWYA+wDdgFPJlkTetzAJgBtrRl11u/BEnSqN7K9M5u4FDbPgQ8MFB/pqreqKpXgDlge5KNwLqqOl5VBTw90EeSNAajhn4Bf5vkxSQzrbahqi4CtPX6Vp8Ezg/0nW+1yba9tC5JGpO1I7b7cFVdSLIeOJrkm9dpO2yevq5Tv/oEi28sMwB33333iEOUJC1npDv9qrrQ1peALwLbgdfalA1tfak1nwc2DXSfAi60+tSQ+rDXO1hV01U1PTExMfrVSJKua9nQT/KeJD/yf9vALwPfAI4Ae1uzvcCzbfsIsCfJbUnuYfED2xNtCuj1JDvaUzsPDfSRJI3BKNM7G4Avtqcr1wJ/WVVfSfJV4HCSh4FzwIMAVXUqyWHgZeAy8GhVXWnnegR4CrgdeK4tkqQxWTb0q+pbwAeG1L8L3H+NPvuB/UPqs8C9Nz5MSdJK8Bu5ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerIqP9ERdLb1OZ9X17tIdxSXn38o6s9hLfEO31J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOjBz6SdYk+VqSL7X9O5McTXK2re8YaPtYkrkkZ5LsHKjfl+RkO/ZEkqzs5UiSrudG7vQ/CZwe2N8HHKuqLcCxtk+SrcAeYBuwC3gyyZrW5wAwA2xpy663NHpJ0g0ZKfSTTAEfBT4zUN4NHGrbh4AHBurPVNUbVfUKMAdsT7IRWFdVx6uqgKcH+kiSxmDUO/0/Bn4X+MFAbUNVXQRo6/WtPgmcH2g332qTbXtp/SpJZpLMJpldWFgYcYiSpOUsG/pJfg24VFUvjnjOYfP0dZ361cWqg1U1XVXTExMTI76sJGk5o/y7xA8Dv57kV4F3A+uS/AXwWpKNVXWxTd1cau3ngU0D/aeAC60+NaQuSRqTZe/0q+qxqpqqqs0sfkD7d1X1G8ARYG9rthd4tm0fAfYkuS3JPSx+YHuiTQG9nmRHe2rnoYE+kqQxeCv/GP1x4HCSh4FzwIMAVXUqyWHgZeAy8GhVXWl9HgGeAm4HnmuLJGlMbij0q+p54Pm2/V3g/mu02w/sH1KfBe690UFKklaG38iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4sG/pJ3p3kRJJ/SXIqyR+0+p1JjiY529Z3DPR5LMlckjNJdg7U70tysh17IkluzmVJkoYZ5U7/DeAXq+oDwAeBXUl2APuAY1W1BTjW9kmyFdgDbAN2AU8mWdPOdQCYAba0ZdcKXoskaRnLhn4t+l7bfWdbCtgNHGr1Q8ADbXs38ExVvVFVrwBzwPYkG4F1VXW8qgp4eqCPJGkMRprTT7ImyUvAJeBoVb0AbKiqiwBtvb41nwTOD3Sfb7XJtr20Lkkak5FCv6quVNUHgSkW79rvvU7zYfP0dZ361SdIZpLMJpldWFgYZYiSpBHc0NM7VfWfwPMszsW/1qZsaOtLrdk8sGmg2xRwodWnhtSHvc7BqpququmJiYkbGaIk6TpGeXpnIsn72vbtwC8B3wSOAHtbs73As237CLAnyW1J7mHxA9sTbQro9SQ72lM7Dw30kSSNwdoR2mwEDrUncN4BHK6qLyU5DhxO8jBwDngQoKpOJTkMvAxcBh6tqivtXI8ATwG3A8+1RZI0JsuGflV9HfjQkPp3gfuv0Wc/sH9IfRa43ucBkqSbyG/kSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHlg39JJuS/H2S00lOJflkq9+Z5GiSs219x0Cfx5LMJTmTZOdA/b4kJ9uxJ5Lk5lyWJGmYUe70LwO/U1U/DewAHk2yFdgHHKuqLcCxtk87tgfYBuwCnkyypp3rADADbGnLrhW8FknSMpYN/aq6WFX/3LZfB04Dk8Bu4FBrdgh4oG3vBp6pqjeq6hVgDtieZCOwrqqOV1UBTw/0kSSNwQ3N6SfZDHwIeAHYUFUXYfGNAVjfmk0C5we6zbfaZNteWpckjcnIoZ/kvcBfAZ+qqv+6XtMhtbpOfdhrzSSZTTK7sLAw6hAlScsYKfSTvJPFwP9cVf11K7/Wpmxo60utPg9sGug+BVxo9akh9atU1cGqmq6q6YmJiVGvRZK0jFGe3gnwZ8DpqvqjgUNHgL1tey/w7EB9T5LbktzD4ge2J9oU0OtJdrRzPjTQR5I0BmtHaPNh4DeBk0learXfAx4HDid5GDgHPAhQVaeSHAZeZvHJn0er6krr9wjwFHA78FxbJEljsmzoV9U/Mnw+HuD+a/TZD+wfUp8F7r2RAUqSVo7fyJWkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjiwb+kk+m+RSkm8M1O5McjTJ2ba+Y+DYY0nmkpxJsnOgfl+Sk+3YE0my8pcjSbqeUe70nwJ2LantA45V1RbgWNsnyVZgD7Ct9XkyyZrW5wAwA2xpy9JzSpJusmVDv6r+Afj3JeXdwKG2fQh4YKD+TFW9UVWvAHPA9iQbgXVVdbyqCnh6oI8kaUze7Jz+hqq6CNDW61t9Ejg/0G6+1Sbb9tK6JGmMVvqD3GHz9HWd+vCTJDNJZpPMLiwsrNjgJKl3bzb0X2tTNrT1pVafBzYNtJsCLrT61JD6UFV1sKqmq2p6YmLiTQ5RkrTUmw39I8Detr0XeHagvifJbUnuYfED2xNtCuj1JDvaUzsPDfSRJI3J2uUaJPk88BHgriTzwO8DjwOHkzwMnAMeBKiqU0kOAy8Dl4FHq+pKO9UjLD4JdDvwXFskSWO0bOhX1ceucej+a7TfD+wfUp8F7r2h0UmSVpTfyJWkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSRsYd+kl1JziSZS7Jv3K8vST0ba+gnWQP8KfArwFbgY0m2jnMMktSzcd/pbwfmqupbVfV94Blg95jHIEndWjvm15sEzg/szwM/u7RRkhlgpu1+L8mZMYytB3cB31ntQSwnf7jaI9Aq8e9zZf3YsOK4Qz9DanVVoeogcPDmD6cvSWaranq1xyEN49/neIx7emce2DSwPwVcGPMYJKlb4w79rwJbktyT5F3AHuDImMcgSd0a6/ROVV1O8gngb4A1wGer6tQ4x9A5p8z0w8y/zzFI1VVT6pKkW5TfyJWkjhj6ktQRQ1+SOjLu5/QliSTvZ/Hb+JMsflfnAnCkqk6v6sA64J1+p5J8fLXHoD4l+TSLP8ES4ASLj3IH+Lw/wnjz+fROp5Kcq6q7V3sc6k+SfwW2VdX/LKm/CzhVVVtWZ2R9cHrnFpbk69c6BGwY51ikAT8AfhT49pL6xnZMN5Ghf2vbAOwE/mNJPcA/jX84EgCfAo4lOcv//wDj3cBPAJ9YtVF1wtC/tX0JeG9VvbT0QJLnxz8cCarqK0l+ksWfWp9k8SZkHvhqVV1Z1cF1wDl9SeqIT+9IUkcMfUnqiKEvSR0x9CWpI4a+JHXkfwEIyN76s2ysPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_file = making_sub(_preds2, 0.4)\n",
    "sub_file.to_csv(f\"sub_files/optuna_lgbm_sub_{10}.csv\", index=False, header=False)\n",
    "plt.figure()\n",
    "sub_file[\"state\"].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
